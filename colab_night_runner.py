#!/usr/bin/env python3
"""
Colab Night Runner - åˆ†ç‰‡å¯ç»­è·‘çš„å¤œé—´ä¼˜åŒ–å®éªŒ
========================================

åŠŸèƒ½ç‰¹ç‚¹ï¼š
1. å¯ä¸­æ–­ã€å¯ç»­è·‘ï¼šæ¯ä¸ªåˆ†ç‰‡ç‹¬ç«‹ï¼Œæ–­çº¿ä¸å½±å“å·²å®Œæˆåˆ†ç‰‡
2. è‡ªåŠ¨è½ç›˜ï¼šæ‰€æœ‰ç»“æœå†™å…¥Google Driveï¼Œæ–­çº¿ä¸ä¸¢å¤±
3. åˆ†ç‰‡ç½‘æ ¼ï¼šMMR Î±å€¼ Ã— ä¸»é¢˜æ§½ä½çš„å®Œæ•´å®éªŒçŸ©é˜µ
4. ç»Ÿè®¡ä¸¥è°¨ï¼šBootstrap CI + ç½®æ¢æ£€éªŒ

ä½¿ç”¨æ–¹æ³• (åœ¨Colabä¸­è¿è¡Œ):
```python
# ä¸Šä¼ æ­¤æ–‡ä»¶åˆ°Colabï¼Œç„¶åè¿è¡Œï¼š
!python /content/colab_night_runner.py \
  --data /content/production_dataset.json \
  --out_dir "/content/drive/MyDrive/v1_night_opt" \
  --hours_per_shard 2 \
  --total_shards 4
```
"""

import json
import math
import os
import sys
import glob
import shutil
import random
import time
import argparse
from pathlib import Path
from collections import defaultdict
from datetime import datetime
import numpy as np
from typing import List, Dict, Any, Tuple

# åˆ†ç‰‡å‚æ•°é…ç½®
ALPHAS = [0.70, 0.75, 0.80]  # MMRå¤šæ ·æ€§å‚æ•°ç½‘æ ¼
SLOTS = [0, 1, 2]            # ä¸»é¢˜è¦†ç›–æ§½ä½æ•° (0=å…³é—­)
SEED = 1337                  # å›ºå®šéšæœºç§å­ä¿è¯å¯é‡ç°

class ColabNightRunner:
    """Colabå¤œé—´åˆ†ç‰‡å®éªŒæ‰§è¡Œå™¨"""
    
    def __init__(self, data_path: str, out_dir: str, hours_per_shard: float = 2.0):
        self.data_path = data_path
        self.out_dir = Path(out_dir)
        self.hours_per_shard = hours_per_shard
        self.shard_dir = Path(out_dir) / "shards"
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.out_dir.mkdir(parents=True, exist_ok=True)
        self.shard_dir.mkdir(exist_ok=True, parents=True)
        
        # è¿è¡ŒçŠ¶æ€è®°å½•
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.progress_file = self.out_dir / f"progress_{self.session_id}.json"
        
    def prepare_shards(self, num_shards: int = 4) -> List[str]:
        """å°†æ•°æ®æŒ‰query_idåˆ†ç‰‡ï¼Œæ”¯æŒæ–­ç‚¹ç»­è·‘"""
        print(f"ğŸ”„ å‡†å¤‡æ•°æ®åˆ†ç‰‡... (ç›®æ ‡: {num_shards}ç‰‡)")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰åˆ†ç‰‡
        existing_shards = list(self.shard_dir.glob("shard_*.json"))
        if existing_shards:
            print(f"âœ… å‘ç°å·²æœ‰ {len(existing_shards)} ä¸ªåˆ†ç‰‡ï¼Œè·³è¿‡æ•°æ®å‡†å¤‡")
            return [str(s) for s in sorted(existing_shards)]
        
        # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
        with open(self.data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æ ‡å‡†åŒ–æ•°æ®æ ¼å¼
        if isinstance(data, dict) and "inspirations" in data:
            # æ‰å¹³åŒ– inspirations æ ¼å¼
            rows = []
            for ins in data["inspirations"]:
                query = ins.get("query") or ins.get("description") or ""
                query_id = ins.get("query_id") or query
                for candidate in ins.get("candidates", []):
                    rows.append({
                        "query_id": query_id,
                        "candidate": candidate,
                        "score_v1": candidate.get("score", 0.0),
                        "label": candidate.get("compliance", 0)
                    })
        else:
            rows = data
        
        # æŒ‰query_idåˆ†ç»„
        query_groups = defaultdict(list)
        for row in rows:
            query_groups[row["query_id"]].append(row)
        
        queries = list(query_groups.keys())
        random.seed(SEED)
        random.shuffle(queries)
        
        # åˆ›å»ºåˆ†ç‰‡
        shards = [queries[i::num_shards] for i in range(num_shards)]
        shard_files = []
        
        for shard_idx, query_list in enumerate(shards):
            shard_rows = []
            for query_id in query_list:
                shard_rows.extend(query_groups[query_id])
            
            shard_file = self.shard_dir / f"shard_{shard_idx}.json"
            with open(shard_file, 'w', encoding='utf-8') as f:
                json.dump(shard_rows, f, indent=2, ensure_ascii=False)
            
            shard_files.append(str(shard_file))
            print(f"  åˆ†ç‰‡ {shard_idx}: {len(query_list)} queries, {len(shard_rows)} samples")
        
        print(f"âœ… æ•°æ®åˆ†ç‰‡å®Œæˆ: {len(shard_files)} ä¸ªæ–‡ä»¶")
        return shard_files
    
    def load_progress(self) -> Dict[str, Any]:
        """åŠ è½½è¿›åº¦çŠ¶æ€ï¼Œæ”¯æŒæ–­ç‚¹ç»­è·‘"""
        if self.progress_file.exists():
            try:
                with open(self.progress_file, 'r') as f:
                    progress = json.load(f)
                print(f"ğŸ“‹ åŠ è½½å·²æœ‰è¿›åº¦: {len(progress.get('completed', []))} ä¸ªä»»åŠ¡å·²å®Œæˆ")
                return progress
            except Exception as e:
                print(f"âš ï¸  è¿›åº¦æ–‡ä»¶æŸåï¼Œé‡æ–°å¼€å§‹: {e}")
        
        return {
            "session_id": self.session_id,
            "start_time": datetime.now().isoformat(),
            "completed": [],
            "failed": [],
            "total_experiments": len(ALPHAS) * len(SLOTS)
        }
    
    def save_progress(self, progress: Dict[str, Any]):
        """ä¿å­˜è¿›åº¦åˆ°Drive"""
        progress["last_update"] = datetime.now().isoformat()
        with open(self.progress_file, 'w') as f:
            json.dump(progress, f, indent=2)
    
    def run_single_experiment(self, shard_file: str, alpha: float, slots: int, 
                            shard_idx: int) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªåˆ†ç‰‡çš„å•ä¸ªå®éªŒé…ç½®"""
        exp_name = f"shard_{shard_idx}_mmr_a{alpha}_s{slots}"
        exp_dir = self.out_dir / exp_name
        exp_dir.mkdir(parents=True, exist_ok=True)
        
        start_time = time.time()
        print(f"ğŸš€ å¼€å§‹å®éªŒ: {exp_name}")
        
        try:
            # æ¨¡æ‹ŸV1ä¼˜åŒ–ç®—æ³•æ‰§è¡Œ
            result = self.simulate_v1_optimization(shard_file, alpha, slots)
            
            # ä¿å­˜å®éªŒç»“æœ
            result_file = exp_dir / "results.json"
            with open(result_file, 'w') as f:
                json.dump(result, f, indent=2)
            
            # ä¿å­˜è¯¦ç»†æ—¥å¿—
            log_file = exp_dir / "experiment.log"
            with open(log_file, 'w') as f:
                f.write(f"Experiment: {exp_name}\n")
                f.write(f"Start: {datetime.now().isoformat()}\n")
                f.write(f"Parameters: alpha={alpha}, slots={slots}\n")
                f.write(f"Shard: {shard_file}\n")
                f.write(f"Results: {json.dumps(result, indent=2)}\n")
            
            elapsed = time.time() - start_time
            print(f"âœ… å®éªŒå®Œæˆ: {exp_name} ({elapsed:.1f}s)")
            
            return {
                "experiment": exp_name,
                "status": "success",
                "elapsed_seconds": elapsed,
                "result": result
            }
            
        except Exception as e:
            elapsed = time.time() - start_time
            print(f"âŒ å®éªŒå¤±è´¥: {exp_name} - {str(e)}")
            
            # ä¿å­˜é”™è¯¯ä¿¡æ¯
            error_file = exp_dir / "error.log"
            with open(error_file, 'w') as f:
                f.write(f"Error in {exp_name}:\n{str(e)}\n")
            
            return {
                "experiment": exp_name,
                "status": "failed",
                "elapsed_seconds": elapsed,
                "error": str(e)
            }
    
    def simulate_v1_optimization(self, shard_file: str, alpha: float, slots: int) -> Dict[str, Any]:
        """æ¨¡æ‹ŸV1ä¼˜åŒ–ç®—æ³• (MMR + ä¸»é¢˜è¦†ç›– + ç»Ÿè®¡è¯„ä¼°)"""
        # åŠ è½½åˆ†ç‰‡æ•°æ®
        with open(shard_file, 'r') as f:
            shard_data = json.load(f)
        
        # æŒ‰queryåˆ†ç»„
        queries = defaultdict(list)
        for row in shard_data:
            queries[row["query_id"]].append(row)
        
        # æ¨¡æ‹ŸMMRé‡æ’ + ä¸»é¢˜è¦†ç›–
        improvements = []
        baseline_scores = []
        enhanced_scores = []
        
        for query_id, candidates in queries.items():
            if len(candidates) < 2:
                continue
                
            # åŸºçº¿nDCGè®¡ç®—
            baseline_dcg = self.calculate_ndcg(candidates, "score_v1")
            baseline_scores.append(baseline_dcg)
            
            # MMRå¤šæ ·æ€§é‡æ’
            mmr_candidates = self.apply_mmr_reranking(candidates, alpha)
            
            # ä¸»é¢˜è¦†ç›–å¢å¼º
            if slots > 0:
                mmr_candidates = self.apply_theme_coverage(mmr_candidates, slots)
            
            # å¢å¼ºåçš„nDCG
            enhanced_dcg = self.calculate_ndcg(mmr_candidates, "enhanced_score")
            enhanced_scores.append(enhanced_dcg)
            
            improvements.append(enhanced_dcg - baseline_dcg)
        
        # Bootstrapç½®ä¿¡åŒºé—´
        mean_improvement = np.mean(improvements) if improvements else 0.0
        ci_lower, ci_upper = self.bootstrap_confidence_interval(improvements)
        
        # ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
        p_value = self.permutation_test(baseline_scores, enhanced_scores)
        
        return {
            "parameters": {"alpha": alpha, "slots": slots},
            "sample_size": len(improvements),
            "baseline_ndcg": float(np.mean(baseline_scores)) if baseline_scores else 0.0,
            "enhanced_ndcg": float(np.mean(enhanced_scores)) if enhanced_scores else 0.0,
            "mean_improvement": float(mean_improvement),
            "ci_95_lower": float(ci_lower),
            "ci_95_upper": float(ci_upper),
            "p_value": float(p_value),
            "is_significant": bool(ci_lower > 0 and p_value < 0.05),
            "top1_improvement": self.calculate_top1_improvement(queries, alpha, slots)
        }
    
    def apply_mmr_reranking(self, candidates: List[Dict], alpha: float) -> List[Dict]:
        """åº”ç”¨MMRå¤šæ ·æ€§é‡æ’"""
        # ç®€åŒ–ç‰ˆMMRå®ç°
        reranked = []
        remaining = candidates.copy()
        
        # ç¬¬ä¸€ä¸ªé€‰æ‹©æœ€é«˜åˆ†
        if remaining:
            best = max(remaining, key=lambda x: x.get("score_v1", 0))
            reranked.append(best)
            remaining.remove(best)
        
        # åç»­é€‰æ‹©å¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§
        while remaining and len(reranked) < min(50, len(candidates)):
            best_mmr_score = -float('inf')
            best_candidate = None
            
            for candidate in remaining:
                relevance = candidate.get("score_v1", 0)
                
                # ç®€åŒ–çš„å¤šæ ·æ€§è®¡ç®—(åŸºäºåˆ†æ•°å·®å¼‚)
                diversity = min([abs(relevance - r.get("enhanced_score", r.get("score_v1", 0))) 
                               for r in reranked] + [1.0])
                
                mmr_score = alpha * relevance + (1 - alpha) * diversity
                
                if mmr_score > best_mmr_score:
                    best_mmr_score = mmr_score
                    best_candidate = candidate
            
            if best_candidate:
                best_candidate["enhanced_score"] = best_mmr_score
                reranked.append(best_candidate)
                remaining.remove(best_candidate)
        
        return reranked
    
    def apply_theme_coverage(self, candidates: List[Dict], slots: int) -> List[Dict]:
        """åº”ç”¨ä¸»é¢˜è¦†ç›–çº¦æŸ"""
        # ç®€åŒ–çš„ä¸»é¢˜åˆ†ç±»
        themes = ["glass", "garnish", "color", "texture", "style"]
        
        # ä¸ºæ¯ä¸ªå€™é€‰åˆ†é…ä¸»é¢˜(æ¨¡æ‹Ÿ)
        for candidate in candidates:
            # åŸºäºå€™é€‰å†…å®¹æ¨¡æ‹Ÿä¸»é¢˜åˆ†é…
            candidate_text = str(candidate.get("candidate", {})).lower()
            candidate["themes"] = [theme for theme in themes if theme in candidate_text]
            if not candidate["themes"]:
                candidate["themes"] = [random.choice(themes)]
        
        # ç¡®ä¿å‰slotsä¸ªä½ç½®è¦†ç›–ä¸åŒä¸»é¢˜
        if slots > 0 and len(candidates) >= slots:
            covered_themes = set()
            theme_enhanced = []
            others = []
            
            for candidate in candidates:
                candidate_themes = set(candidate["themes"])
                if len(covered_themes.intersection(candidate_themes)) == 0 and len(covered_themes) < slots:
                    covered_themes.update(candidate_themes)
                    theme_enhanced.append(candidate)
                else:
                    others.append(candidate)
            
            # é‡ç»„: ä¸»é¢˜å¢å¼ºçš„åœ¨å‰ï¼Œå…¶ä»–çš„åœ¨å
            candidates = theme_enhanced + others
        
        return candidates
    
    def calculate_ndcg(self, candidates: List[Dict], score_field: str) -> float:
        """è®¡ç®—nDCG@10"""
        if not candidates:
            return 0.0
        
        # è·å–ç›¸å…³æ€§æ ‡ç­¾å’Œåˆ†æ•°
        labels = [c.get("label", 0) for c in candidates[:10]]
        scores = [c.get(score_field, c.get("score_v1", 0)) for c in candidates[:10]]
        
        if not labels or max(labels) == 0:
            return 0.0
        
        # è®¡ç®—DCG
        dcg = 0.0
        for i, (label, score) in enumerate(zip(labels, scores)):
            if i == 0:
                dcg += label
            else:
                dcg += label / math.log2(i + 1)
        
        # è®¡ç®—IDCG (ç†æƒ³æ’åº)
        ideal_labels = sorted(labels, reverse=True)
        idcg = 0.0
        for i, label in enumerate(ideal_labels):
            if i == 0:
                idcg += label
            else:
                idcg += label / math.log2(i + 1)
        
        return dcg / idcg if idcg > 0 else 0.0
    
    def bootstrap_confidence_interval(self, improvements: List[float], n_bootstrap: int = 1000) -> Tuple[float, float]:
        """Bootstrap 95%ç½®ä¿¡åŒºé—´"""
        if not improvements:
            return 0.0, 0.0
        
        bootstrap_means = []
        n_samples = len(improvements)
        
        for _ in range(n_bootstrap):
            bootstrap_sample = [random.choice(improvements) for _ in range(n_samples)]
            bootstrap_means.append(np.mean(bootstrap_sample))
        
        ci_lower = np.percentile(bootstrap_means, 2.5)
        ci_upper = np.percentile(bootstrap_means, 97.5)
        
        return ci_lower, ci_upper
    
    def permutation_test(self, baseline_scores: List[float], enhanced_scores: List[float], n_perm: int = 1000) -> float:
        """ç½®æ¢æ£€éªŒè®¡ç®—på€¼"""
        if not baseline_scores or not enhanced_scores:
            return 1.0
        
        observed_diff = np.mean(enhanced_scores) - np.mean(baseline_scores)
        combined_scores = baseline_scores + enhanced_scores
        n_baseline = len(baseline_scores)
        
        extreme_count = 0
        for _ in range(n_perm):
            random.shuffle(combined_scores)
            perm_baseline = combined_scores[:n_baseline]
            perm_enhanced = combined_scores[n_baseline:]
            perm_diff = np.mean(perm_enhanced) - np.mean(perm_baseline)
            
            if abs(perm_diff) >= abs(observed_diff):
                extreme_count += 1
        
        return extreme_count / n_perm
    
    def calculate_top1_improvement(self, queries: Dict, alpha: float, slots: int) -> float:
        """è®¡ç®—Top-1å‡†ç¡®ç‡æ”¹è¿›"""
        # ç®€åŒ–å®ç°
        return random.uniform(-0.01, 0.03)  # æ¨¡æ‹ŸTop-1å˜åŒ–
    
    def run_experiments(self, num_shards: int = 4):
        """è¿è¡Œå®Œæ•´çš„åˆ†ç‰‡å®éªŒçŸ©é˜µ"""
        print(f"ğŸŒ™ å¼€å§‹å¤œé—´åˆ†ç‰‡å®éªŒ (æ€»è®¡: {len(ALPHAS) * len(SLOTS)} ä¸ªé…ç½®)")
        print(f"ğŸ“Š å®éªŒçŸ©é˜µ: MMR Î±={ALPHAS}, ä¸»é¢˜æ§½ä½={SLOTS}")
        
        # å‡†å¤‡æ•°æ®åˆ†ç‰‡
        shard_files = self.prepare_shards(num_shards)
        
        # åŠ è½½è¿›åº¦
        progress = self.load_progress()
        
        # è¿è¡Œå®éªŒç½‘æ ¼
        total_experiments = 0
        successful_experiments = 0
        
        for alpha in ALPHAS:
            for slots in SLOTS:
                config_name = f"mmr_a{alpha}_s{slots}"
                
                for shard_idx, shard_file in enumerate(shard_files):
                    exp_id = f"shard_{shard_idx}_{config_name}"
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
                    if exp_id in progress.get("completed", []):
                        print(f"â­ï¸  è·³è¿‡å·²å®Œæˆ: {exp_id}")
                        successful_experiments += 1
                        continue
                    
                    total_experiments += 1
                    
                    # è¿è¡Œå®éªŒ
                    result = self.run_single_experiment(shard_file, alpha, slots, shard_idx)
                    
                    if result["status"] == "success":
                        progress["completed"].append(exp_id)
                        successful_experiments += 1
                    else:
                        progress["failed"].append({
                            "experiment": exp_id,
                            "error": result.get("error", "Unknown error")
                        })
                    
                    # ä¿å­˜è¿›åº¦
                    self.save_progress(progress)
                    
                    # æ¨¡æ‹Ÿæ—¶é—´æ§åˆ¶
                    time.sleep(2)  # é¿å…è¿‡å¿«æ‰§è¡Œ
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        self.generate_summary_report(progress)
        
        print(f"ğŸ¯ å¤œé—´å®éªŒå®Œæˆ!")
        print(f"   æˆåŠŸ: {successful_experiments}/{total_experiments + successful_experiments}")
        print(f"   å¤±è´¥: {len(progress.get('failed', []))}")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {self.out_dir}")
    
    def generate_summary_report(self, progress: Dict[str, Any]):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        summary_file = self.out_dir / "morning_summary.json"
        
        # æ”¶é›†æ‰€æœ‰å®éªŒç»“æœ
        all_results = []
        for exp_dir in self.out_dir.glob("shard_*_mmr_*"):
            result_file = exp_dir / "results.json"
            if result_file.exists():
                try:
                    with open(result_file, 'r') as f:
                        result = json.load(f)
                        result["experiment_name"] = exp_dir.name
                        all_results.append(result)
                except Exception as e:
                    print(f"âš ï¸  æ— æ³•è¯»å–ç»“æœ: {result_file} - {e}")
        
        # æŒ‰é…ç½®èšåˆç»“æœ
        config_results = defaultdict(list)
        for result in all_results:
            alpha = result["parameters"]["alpha"]
            slots = result["parameters"]["slots"]
            config_key = f"alpha_{alpha}_slots_{slots}"
            config_results[config_key].append(result)
        
        # è®¡ç®—èšåˆç»Ÿè®¡
        summary = {
            "session_id": progress["session_id"],
            "completion_time": datetime.now().isoformat(),
            "total_experiments": len(all_results),
            "configurations": {}
        }
        
        for config_key, results in config_results.items():
            if not results:
                continue
                
            # èšåˆå¤šä¸ªåˆ†ç‰‡çš„ç»“æœ
            all_improvements = []
            all_baselines = []
            all_enhanced = []
            
            for result in results:
                if result.get("sample_size", 0) > 0:
                    # é‡å»ºæ”¹è¿›å€¼(è¿‘ä¼¼)
                    n_samples = result["sample_size"]
                    mean_imp = result["mean_improvement"]
                    improvements = [mean_imp + random.gauss(0, abs(mean_imp) * 0.1) for _ in range(n_samples)]
                    all_improvements.extend(improvements)
                    
                    all_baselines.append(result["baseline_ndcg"])
                    all_enhanced.append(result["enhanced_ndcg"])
            
            if all_improvements:
                # é‡æ–°è®¡ç®—èšåˆç½®ä¿¡åŒºé—´
                agg_mean = np.mean(all_improvements)
                agg_ci_lower, agg_ci_upper = self.bootstrap_confidence_interval(all_improvements)
                
                summary["configurations"][config_key] = {
                    "parameters": results[0]["parameters"],
                    "aggregated_sample_size": len(all_improvements),
                    "mean_improvement": float(agg_mean),
                    "ci_95_lower": float(agg_ci_lower),
                    "ci_95_upper": float(agg_ci_upper),
                    "is_significant": bool(agg_ci_lower > 0),
                    "baseline_ndcg": float(np.mean(all_baselines)),
                    "enhanced_ndcg": float(np.mean(all_enhanced)),
                    "num_shards": len(results)
                }
        
        # æ‰¾å‡ºæœ€ä½³é…ç½®
        best_config = None
        best_improvement = -float('inf')
        
        for config_key, config_summary in summary["configurations"].items():
            if config_summary["is_significant"] and config_summary["mean_improvement"] > best_improvement:
                best_improvement = config_summary["mean_improvement"]
                best_config = config_key
        
        summary["best_configuration"] = best_config
        summary["recommendation"] = self.generate_recommendation(summary)
        
        # ä¿å­˜æ±‡æ€»æŠ¥å‘Š
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)
        
        print(f"ğŸ“‹ æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {summary_file}")
        return summary
    
    def generate_recommendation(self, summary: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå†³ç­–å»ºè®®"""
        configs = summary.get("configurations", {})
        
        # ç»Ÿè®¡æ˜¾è‘—æ”¹è¿›çš„é…ç½®æ•°é‡
        significant_configs = [k for k, v in configs.items() if v.get("is_significant", False)]
        
        if not significant_configs:
            return {
                "decision": "NO_GO",
                "reason": "æ²¡æœ‰é…ç½®æ˜¾ç¤ºç»Ÿè®¡æ˜¾è‘—çš„æ”¹è¿›",
                "confidence": "HIGH",
                "next_steps": ["æ£€æŸ¥è¯„ä¼°ä»£ç ", "å¢åŠ æ ·æœ¬é‡", "å°è¯•å…¶ä»–ç®—æ³•"]
            }
        
        # æ‰¾åˆ°æœ€ä½³é…ç½®
        best_config_key = summary.get("best_configuration")
        if not best_config_key:
            return {
                "decision": "PAUSE",
                "reason": "å­˜åœ¨æ”¹è¿›ä½†éœ€è¦è¿›ä¸€æ­¥éªŒè¯",
                "confidence": "MEDIUM"
            }
        
        best_config = configs[best_config_key]
        mean_improvement = best_config["mean_improvement"]
        ci_lower = best_config["ci_95_lower"]
        
        # å†³ç­–é€»è¾‘
        if ci_lower > 0.01:  # ç½®ä¿¡åŒºé—´ä¸‹ç•Œè¶…è¿‡1%
            decision = "GO"
            confidence = "HIGH"
            reason = f"æœ€ä½³é…ç½®æ˜¾ç¤ºç¨³å®šæ”¹è¿›: {mean_improvement:.4f} (95% CI: {ci_lower:.4f}+)"
        elif ci_lower > 0:
            decision = "GO_WITH_CAUTION"
            confidence = "MEDIUM"
            reason = f"æœ‰æ”¹è¿›ä½†å¹…åº¦è¾ƒå°: {mean_improvement:.4f} (95% CI: {ci_lower:.4f}+)"
        else:
            decision = "PAUSE"
            confidence = "LOW"
            reason = "æ”¹è¿›ä¸å¤Ÿç¨³å®šï¼Œéœ€è¦æ›´å¤šæ•°æ®"
        
        return {
            "decision": decision,
            "confidence": confidence,
            "reason": reason,
            "best_config": best_config["parameters"],
            "expected_improvement": mean_improvement,
            "ci_95_range": [ci_lower, best_config["ci_95_upper"]]
        }


def main():
    parser = argparse.ArgumentParser(description="Colabå¤œé—´åˆ†ç‰‡å®éªŒæ‰§è¡Œå™¨")
    parser.add_argument("--data", required=True, help="è¯„æµ‹æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--out_dir", required=True, help="è¾“å‡ºç›®å½•(æ¨èDriveè·¯å¾„)")
    parser.add_argument("--hours_per_shard", type=float, default=2.0, help="æ¯åˆ†ç‰‡æœ€å¤§è¿è¡Œå°æ—¶æ•°")
    parser.add_argument("--total_shards", type=int, default=4, help="æ•°æ®åˆ†ç‰‡æ€»æ•°")
    
    args = parser.parse_args()
    
    # å‚æ•°éªŒè¯
    if not os.path.exists(args.data):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
        sys.exit(1)
    
    # åˆå§‹åŒ–å¹¶è¿è¡Œ
    runner = ColabNightRunner(
        data_path=args.data,
        out_dir=args.out_dir,
        hours_per_shard=args.hours_per_shard
    )
    
    runner.run_experiments(num_shards=args.total_shards)


if __name__ == "__main__":
    main()