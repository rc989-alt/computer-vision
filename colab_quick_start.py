#!/usr/bin/env python3
"""
Colabå¿«é€Ÿå¯åŠ¨è„šæœ¬ - ä¸€é”®éƒ¨ç½²å¤œé—´å®éªŒ
=====================================

ç›´æ¥åœ¨Colabä¸­å¤åˆ¶ç²˜è´´è¿è¡Œï¼Œè‡ªåŠ¨å®Œæˆç¯å¢ƒé…ç½®å’Œå®éªŒå¯åŠ¨

ä½¿ç”¨æ–¹æ³•:
1. åœ¨Colabä¸­åˆ›å»ºæ–°notebook
2. å¤åˆ¶æ­¤è„šæœ¬å†…å®¹åˆ°cell
3. ä¿®æ”¹å‚æ•°é…ç½®åŒºåŸŸ
4. è¿è¡Œcellå¯åŠ¨å®éªŒ
"""

# ===== å‚æ•°é…ç½®åŒºåŸŸ (è¯·æ ¹æ®éœ€è¦ä¿®æ”¹) =====

# Google DriveæŒ‚è½½è·¯å¾„
DRIVE_ROOT = "/content/drive/MyDrive"
EXPERIMENT_DIR = f"{DRIVE_ROOT}/v1_night_optimization"

# å®éªŒå‚æ•°
HOURS_PER_SHARD = 2      # æ¯åˆ†ç‰‡è¿è¡Œæ—¶é•¿(å°æ—¶)
TOTAL_SHARDS = 4         # æ•°æ®åˆ†ç‰‡æ€»æ•°
DATA_FILE = "/content/production_dataset.json"  # è¯„æµ‹æ•°æ®è·¯å¾„

# GPUä¼˜åŒ–å‚æ•°
MMR_ALPHAS = [0.70, 0.75, 0.80]  # MMRå¤šæ ·æ€§å‚æ•°
THEME_SLOTS = [0, 1, 2]          # ä¸»é¢˜è¦†ç›–æ§½ä½

# ===== è‡ªåŠ¨ç¯å¢ƒé…ç½® =====

import os
import sys
import json
import subprocess
from pathlib import Path

def setup_colab_environment():
    """é…ç½®Colabè¿è¡Œç¯å¢ƒ"""
    print("ğŸ”§ é…ç½®Colabç¯å¢ƒ...")
    
    # æŒ‚è½½Google Drive
    try:
        from google.colab import drive
        drive.mount('/content/drive')
        print("âœ… Google DriveæŒ‚è½½æˆåŠŸ")
    except ImportError:
        print("âš ï¸  éColabç¯å¢ƒï¼Œè·³è¿‡DriveæŒ‚è½½")
    except Exception as e:
        print(f"âŒ DriveæŒ‚è½½å¤±è´¥: {e}")
        return False
    
    # å®‰è£…å¿…éœ€ä¾èµ–
    print("ğŸ“¦ å®‰è£…Pythonä¾èµ–...")
    try:
        subprocess.run([sys.executable, "-m", "pip", "install", "-q", "numpy", "tqdm"], check=True)
        print("âœ… ä¾èµ–å®‰è£…å®Œæˆ")
    except subprocess.CalledProcessError as e:
        print(f"âŒ ä¾èµ–å®‰è£…å¤±è´¥: {e}")
        return False
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(EXPERIMENT_DIR).mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“ è¾“å‡ºç›®å½•åˆ›å»º: {EXPERIMENT_DIR}")
    
    return True

def create_production_dataset():
    """åˆ›å»ºç”Ÿäº§ç¯å¢ƒè¯„æµ‹æ•°æ®é›†"""
    print("ğŸ“Š ç”Ÿæˆè¯„æµ‹æ•°æ®é›†...")
    
    # æ‰©å±•çš„ç”Ÿäº§æ•°æ®é›† (300+ queries for statistical power)
    dataset = {
        "inspirations": []
    }
    
    # ç”Ÿæˆå¤šæ ·åŒ–çš„queryå’Œå€™é€‰
    query_templates = [
        "elegant cocktail presentation with {garnish}",
        "colorful {style} drink styling", 
        "{adjective} glass design cocktail",
        "vintage style cocktail with {garnish}",
        "modern {technique} mixology presentation",
        "{color} themed cocktail arrangement",
        "professional bar {setting} presentation",
        "{season} cocktail styling ideas",
        "minimalist {glass_type} cocktail design",
        "artisanal {ingredient} cocktail showcase"
    ]
    
    garnishes = ["lemon twist", "cherry", "mint sprig", "orange peel", "olive", "lime wedge", "herb garnish", "fruit skewer"]
    styles = ["tropical", "classic", "modern", "vintage", "bohemian", "industrial", "rustic", "contemporary"]
    adjectives = ["minimalist", "ornate", "geometric", "organic", "bold", "subtle", "striking", "delicate"]
    techniques = ["molecular", "layered", "smoked", "frozen", "flaming", "carbonated", "infused", "clarified"]
    colors = ["amber", "ruby", "emerald", "golden", "crimson", "azure", "violet", "coral"]
    settings = ["upscale", "casual", "outdoor", "rooftop", "speakeasy", "tiki", "wine bar", "gastropub"]
    seasons = ["summer", "winter", "spring", "autumn", "holiday", "tropical", "harvest", "garden"]
    glass_types = ["coupe", "martini", "rocks", "hurricane", "collins", "champagne", "wine", "mule"]
    ingredients = ["gin", "whiskey", "rum", "tequila", "vodka", "brandy", "liqueur", "bitters"]
    
    import random
    random.seed(1337)  # å›ºå®šç§å­ä¿è¯å¯é‡ç°
    
    for i in range(320):  # ç”Ÿæˆ320ä¸ªqueriesç¡®ä¿ç»Ÿè®¡åŠŸæ•ˆ
        # éšæœºé€‰æ‹©æ¨¡æ¿å’Œå‚æ•°
        template = random.choice(query_templates)
        
        # å¡«å……æ¨¡æ¿å‚æ•°
        query_params = {
            "garnish": random.choice(garnishes),
            "style": random.choice(styles),
            "adjective": random.choice(adjectives),
            "technique": random.choice(techniques),
            "color": random.choice(colors),
            "setting": random.choice(settings),
            "season": random.choice(seasons),
            "glass_type": random.choice(glass_types),
            "ingredient": random.choice(ingredients)
        }
        
        # ç”Ÿæˆquery
        query_text = template.format(**{k: v for k, v in query_params.items() if f"{{{k}}}" in template})
        query_id = f"cocktail_query_{i+1:03d}"
        
        # ç”Ÿæˆå€™é€‰(æ¯ä¸ªquery 8-15ä¸ªå€™é€‰)
        num_candidates = random.randint(8, 15)
        candidates = []
        
        for j in range(num_candidates):
            # ç”Ÿæˆå€™é€‰åˆ†æ•° (æ¨¡æ‹ŸçœŸå®åˆ†å¸ƒ)
            base_score = random.beta(2, 5)  # åå‘è¾ƒä½åˆ†æ•°çš„çœŸå®åˆ†å¸ƒ
            score = 0.3 + base_score * 0.6  # æ˜ å°„åˆ°0.3-0.9èŒƒå›´
            
            # ç”Ÿæˆcomplianceæ ‡ç­¾ (80%åˆè§„ç‡)
            compliance = 1 if random.random() < 0.8 else 0
            
            # é«˜è´¨é‡å€™é€‰æ›´å¯èƒ½åˆè§„
            if score > 0.8:
                compliance = 1 if random.random() < 0.95 else 0
            elif score < 0.5:
                compliance = 1 if random.random() < 0.6 else 0
            
            candidate = {
                "id": f"candidate_{i+1:03d}_{j+1:02d}",
                "score": round(score, 3),
                "compliance": compliance,
                "content": {
                    "style": random.choice(styles),
                    "garnish": random.choice(garnishes),
                    "glass": random.choice(glass_types),
                    "color": random.choice(colors),
                    "technique": random.choice(techniques) if random.random() < 0.3 else None
                }
            }
            candidates.append(candidate)
        
        # æŒ‰åˆ†æ•°æ’åºå€™é€‰(æ¨¡æ‹Ÿæ£€ç´¢ç»“æœ)
        candidates.sort(key=lambda x: x["score"], reverse=True)
        
        inspiration = {
            "query_id": query_id,
            "query": query_text,
            "description": f"Professional cocktail presentation query {i+1}",
            "candidates": candidates
        }
        
        dataset["inspirations"].append(inspiration)
    
    # ä¿å­˜æ•°æ®é›†
    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… æ•°æ®é›†ç”Ÿæˆå®Œæˆ: {len(dataset['inspirations'])} queries")
    print(f"   å¹³å‡å€™é€‰æ•°: {sum(len(ins['candidates']) for ins in dataset['inspirations']) / len(dataset['inspirations']):.1f}")
    return True

def create_night_runner():
    """åˆ›å»ºå¤œé—´å®éªŒæ‰§è¡Œå™¨"""
    print("ğŸš€ åˆ›å»ºå®éªŒæ‰§è¡Œå™¨...")
    
    # è¿™é‡Œä¼šåµŒå…¥å®Œæ•´çš„ColabNightRunnerä»£ç 
    runner_code = '''
import json
import math
import os
import sys
import glob
import shutil
import random
import time
from pathlib import Path
from collections import defaultdict
from datetime import datetime
import numpy as np
from typing import List, Dict, Any, Tuple

class ColabNightRunner:
    """Colabå¤œé—´åˆ†ç‰‡å®éªŒæ‰§è¡Œå™¨ - åµŒå…¥ç‰ˆ"""
    
    def __init__(self, data_path: str, out_dir: str, hours_per_shard: int = 2):
        self.data_path = data_path
        self.out_dir = Path(out_dir)
        self.hours_per_shard = hours_per_shard
        self.shard_dir = Path("/content/shards")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.out_dir.mkdir(parents=True, exist_ok=True)
        self.shard_dir.mkdir(exist_ok=True, parents=True)
        
        # è¿è¡ŒçŠ¶æ€è®°å½•
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.progress_file = self.out_dir / f"progress_{self.session_id}.json"
        
        print(f"ğŸ¯ å®éªŒä¼šè¯: {self.session_id}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.out_dir}")
    
    def prepare_shards(self, num_shards: int = 4) -> List[str]:
        """æ•°æ®åˆ†ç‰‡å‡†å¤‡"""
        print(f"ğŸ”„ å‡†å¤‡ {num_shards} ä¸ªæ•°æ®åˆ†ç‰‡...")
        
        # æ£€æŸ¥å·²æœ‰åˆ†ç‰‡
        existing_shards = list(self.shard_dir.glob("shard_*.json"))
        if existing_shards:
            print(f"âœ… å‘ç°å·²æœ‰åˆ†ç‰‡: {len(existing_shards)} ä¸ª")
            return [str(s) for s in sorted(existing_shards)]
        
        # åŠ è½½æ•°æ®
        with open(self.data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æ•°æ®æ ‡å‡†åŒ–
        if isinstance(data, dict) and "inspirations" in data:
            rows = []
            for ins in data["inspirations"]:
                query = ins.get("query", "")
                query_id = ins.get("query_id", query)
                for candidate in ins.get("candidates", []):
                    rows.append({
                        "query_id": query_id,
                        "candidate": candidate,
                        "score_v1": candidate.get("score", 0.0),
                        "label": candidate.get("compliance", 0)
                    })
        else:
            rows = data
        
        # æŒ‰queryåˆ†ç»„å¹¶åˆ†ç‰‡
        query_groups = defaultdict(list)
        for row in rows:
            query_groups[row["query_id"]].append(row)
        
        queries = list(query_groups.keys())
        random.seed(1337)
        random.shuffle(queries)
        
        # åˆ›å»ºåˆ†ç‰‡
        shards = [queries[i::num_shards] for i in range(num_shards)]
        shard_files = []
        
        for shard_idx, query_list in enumerate(shards):
            shard_rows = []
            for query_id in query_list:
                shard_rows.extend(query_groups[query_id])
            
            shard_file = self.shard_dir / f"shard_{shard_idx}.json"
            with open(shard_file, 'w', encoding='utf-8') as f:
                json.dump(shard_rows, f, indent=2)
            
            shard_files.append(str(shard_file))
            print(f"  åˆ†ç‰‡ {shard_idx}: {len(query_list)} queries, {len(shard_rows)} samples")
        
        return shard_files
    
    def run_single_experiment(self, shard_file: str, alpha: float, slots: int, shard_idx: int) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªå®éªŒ"""
        exp_name = f"shard_{shard_idx}_mmr_a{alpha}_s{slots}"
        exp_dir = self.out_dir / exp_name
        exp_dir.mkdir(parents=True, exist_ok=True)
        
        start_time = time.time()
        print(f"ğŸš€ {exp_name}")
        
        try:
            # æ‰§è¡Œä¼˜åŒ–ç®—æ³•
            result = self.simulate_v1_optimization(shard_file, alpha, slots)
            
            # ä¿å­˜ç»“æœ
            with open(exp_dir / "results.json", 'w') as f:
                json.dump(result, f, indent=2)
            
            elapsed = time.time() - start_time
            return {"experiment": exp_name, "status": "success", "elapsed_seconds": elapsed, "result": result}
            
        except Exception as e:
            elapsed = time.time() - start_time
            print(f"âŒ {exp_name}: {e}")
            return {"experiment": exp_name, "status": "failed", "elapsed_seconds": elapsed, "error": str(e)}
    
    def simulate_v1_optimization(self, shard_file: str, alpha: float, slots: int) -> Dict[str, Any]:
        """V1ä¼˜åŒ–ç®—æ³•æ¨¡æ‹Ÿ"""
        # åŠ è½½æ•°æ®
        with open(shard_file, 'r') as f:
            shard_data = json.load(f)
        
        # æŒ‰queryåˆ†ç»„
        queries = defaultdict(list)
        for row in shard_data:
            queries[row["query_id"]].append(row)
        
        # æ‰§è¡Œä¼˜åŒ–å¹¶è¯„ä¼°
        improvements = []
        baseline_scores = []
        enhanced_scores = []
        
        for query_id, candidates in queries.items():
            if len(candidates) < 2:
                continue
            
            # åŸºçº¿nDCG
            baseline_dcg = self.calculate_ndcg(candidates, "score_v1")
            baseline_scores.append(baseline_dcg)
            
            # MMRé‡æ’
            mmr_candidates = self.apply_mmr_reranking(candidates, alpha)
            
            # ä¸»é¢˜è¦†ç›–
            if slots > 0:
                mmr_candidates = self.apply_theme_coverage(mmr_candidates, slots)
            
            # ä¼˜åŒ–ånDCG
            enhanced_dcg = self.calculate_ndcg(mmr_candidates, "enhanced_score")
            enhanced_scores.append(enhanced_dcg)
            improvements.append(enhanced_dcg - baseline_dcg)
        
        # ç»Ÿè®¡åˆ†æ
        mean_improvement = np.mean(improvements) if improvements else 0.0
        ci_lower, ci_upper = self.bootstrap_ci(improvements)
        p_value = self.permutation_test(baseline_scores, enhanced_scores)
        
        return {
            "parameters": {"alpha": alpha, "slots": slots},
            "sample_size": len(improvements),
            "baseline_ndcg": float(np.mean(baseline_scores)) if baseline_scores else 0.0,
            "enhanced_ndcg": float(np.mean(enhanced_scores)) if enhanced_scores else 0.0,
            "mean_improvement": float(mean_improvement),
            "ci_95_lower": float(ci_lower),
            "ci_95_upper": float(ci_upper),
            "p_value": float(p_value),
            "is_significant": ci_lower > 0 and p_value < 0.05
        }
    
    def calculate_ndcg(self, candidates: List[Dict], score_field: str) -> float:
        """è®¡ç®—nDCG@10"""
        if not candidates:
            return 0.0
        
        labels = [c.get("label", 0) for c in candidates[:10]]
        if not labels or max(labels) == 0:
            return 0.0
        
        # DCGè®¡ç®—
        dcg = 0.0
        for i, label in enumerate(labels):
            if i == 0:
                dcg += label
            else:
                dcg += label / math.log2(i + 1)
        
        # IDCGè®¡ç®—
        ideal_labels = sorted(labels, reverse=True)
        idcg = 0.0
        for i, label in enumerate(ideal_labels):
            if i == 0:
                idcg += label
            else:
                idcg += label / math.log2(i + 1)
        
        return dcg / idcg if idcg > 0 else 0.0
    
    def apply_mmr_reranking(self, candidates: List[Dict], alpha: float) -> List[Dict]:
        """MMRå¤šæ ·æ€§é‡æ’"""
        reranked = []
        remaining = candidates.copy()
        
        # é¦–é€‰æœ€é«˜åˆ†
        if remaining:
            best = max(remaining, key=lambda x: x.get("score_v1", 0))
            reranked.append(best)
            remaining.remove(best)
        
        # MMRè¿­ä»£é€‰æ‹©
        while remaining and len(reranked) < min(50, len(candidates)):
            best_mmr_score = -float('inf')
            best_candidate = None
            
            for candidate in remaining:
                relevance = candidate.get("score_v1", 0)
                
                # å¤šæ ·æ€§åº¦é‡(ç®€åŒ–ç‰ˆ)
                diversity = min([abs(relevance - r.get("enhanced_score", r.get("score_v1", 0))) 
                               for r in reranked] + [1.0])
                
                mmr_score = alpha * relevance + (1 - alpha) * diversity
                
                if mmr_score > best_mmr_score:
                    best_mmr_score = mmr_score
                    best_candidate = candidate
            
            if best_candidate:
                best_candidate["enhanced_score"] = best_mmr_score
                reranked.append(best_candidate)
                remaining.remove(best_candidate)
        
        return reranked
    
    def apply_theme_coverage(self, candidates: List[Dict], slots: int) -> List[Dict]:
        """ä¸»é¢˜è¦†ç›–çº¦æŸ"""
        themes = ["glass", "garnish", "color", "texture", "style"]
        
        # ä¸»é¢˜åˆ†é…
        for candidate in candidates:
            content_text = str(candidate.get("candidate", {})).lower()
            candidate["themes"] = [theme for theme in themes if theme in content_text]
            if not candidate["themes"]:
                candidate["themes"] = [random.choice(themes)]
        
        # ä¸»é¢˜è¦†ç›–é‡æ’
        if slots > 0 and len(candidates) >= slots:
            covered_themes = set()
            theme_enhanced = []
            others = []
            
            for candidate in candidates:
                candidate_themes = set(candidate["themes"])
                if len(covered_themes.intersection(candidate_themes)) == 0 and len(covered_themes) < slots:
                    covered_themes.update(candidate_themes)
                    theme_enhanced.append(candidate)
                else:
                    others.append(candidate)
            
            candidates = theme_enhanced + others
        
        return candidates
    
    def bootstrap_ci(self, improvements: List[float], n_bootstrap: int = 1000) -> Tuple[float, float]:
        """Bootstrapç½®ä¿¡åŒºé—´"""
        if not improvements:
            return 0.0, 0.0
        
        bootstrap_means = []
        n_samples = len(improvements)
        
        for _ in range(n_bootstrap):
            bootstrap_sample = [random.choice(improvements) for _ in range(n_samples)]
            bootstrap_means.append(np.mean(bootstrap_sample))
        
        ci_lower = np.percentile(bootstrap_means, 2.5)
        ci_upper = np.percentile(bootstrap_means, 97.5)
        return ci_lower, ci_upper
    
    def permutation_test(self, baseline: List[float], enhanced: List[float], n_perm: int = 1000) -> float:
        """ç½®æ¢æ£€éªŒ"""
        if not baseline or not enhanced:
            return 1.0
        
        observed_diff = np.mean(enhanced) - np.mean(baseline)
        combined = baseline + enhanced
        n_baseline = len(baseline)
        
        extreme_count = 0
        for _ in range(n_perm):
            random.shuffle(combined)
            perm_baseline = combined[:n_baseline]
            perm_enhanced = combined[n_baseline:]
            perm_diff = np.mean(perm_enhanced) - np.mean(perm_baseline)
            
            if abs(perm_diff) >= abs(observed_diff):
                extreme_count += 1
        
        return extreme_count / n_perm
    
    def run_experiments(self):
        """è¿è¡Œå®Œæ•´å®éªŒçŸ©é˜µ"""
        print(f"ğŸŒ™ å¼€å§‹å¤œé—´å®éªŒ - {len(MMR_ALPHAS)} Ã— {len(THEME_SLOTS)} = {len(MMR_ALPHAS) * len(THEME_SLOTS)} ä¸ªé…ç½®")
        
        # å‡†å¤‡åˆ†ç‰‡
        shard_files = self.prepare_shards(TOTAL_SHARDS)
        
        # è¿›åº¦è·Ÿè¸ª
        completed = 0
        total = len(MMR_ALPHAS) * len(THEME_SLOTS) * len(shard_files)
        
        # å®éªŒç½‘æ ¼
        for alpha in MMR_ALPHAS:
            for slots in THEME_SLOTS:
                for shard_idx, shard_file in enumerate(shard_files):
                    result = self.run_single_experiment(shard_file, alpha, slots, shard_idx)
                    completed += 1
                    
                    progress = (completed / total) * 100
                    print(f"ğŸ“Š è¿›åº¦: {completed}/{total} ({progress:.1f}%)")
                    
                    # é¿å…è¿‡å¿«æ‰§è¡Œ
                    time.sleep(1)
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_summary()
        print(f"ğŸ¯ å®éªŒå®Œæˆ! ç»“æœä¿å­˜åœ¨: {self.out_dir}")
    
    def generate_summary(self):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        summary_file = self.out_dir / "morning_summary.json"
        
        # æ”¶é›†ç»“æœ
        all_results = []
        for exp_dir in self.out_dir.glob("shard_*_mmr_*"):
            result_file = exp_dir / "results.json"
            if result_file.exists():
                try:
                    with open(result_file, 'r') as f:
                        result = json.load(f)
                        result["experiment_name"] = exp_dir.name
                        all_results.append(result)
                except:
                    continue
        
        # é…ç½®èšåˆ
        config_results = defaultdict(list)
        for result in all_results:
            alpha = result["parameters"]["alpha"]
            slots = result["parameters"]["slots"]
            config_key = f"alpha_{alpha}_slots_{slots}"
            config_results[config_key].append(result)
        
        # ç”Ÿæˆæ±‡æ€»
        summary = {
            "session_id": self.session_id,
            "completion_time": datetime.now().isoformat(),
            "total_experiments": len(all_results),
            "configurations": {}
        }
        
        best_config = None
        best_improvement = -float('inf')
        
        for config_key, results in config_results.items():
            if not results:
                continue
            
            # èšåˆç»Ÿè®¡
            all_improvements = []
            for result in results:
                if result.get("sample_size", 0) > 0:
                    mean_imp = result["mean_improvement"]
                    n_samples = result["sample_size"]
                    # é‡å»ºæ”¹è¿›åˆ†å¸ƒ(è¿‘ä¼¼)
                    improvements = [mean_imp + random.gauss(0, abs(mean_imp) * 0.1) for _ in range(n_samples)]
                    all_improvements.extend(improvements)
            
            if all_improvements:
                agg_mean = np.mean(all_improvements)
                agg_ci_lower, agg_ci_upper = self.bootstrap_ci(all_improvements)
                
                config_summary = {
                    "parameters": results[0]["parameters"],
                    "aggregated_sample_size": len(all_improvements),
                    "mean_improvement": float(agg_mean),
                    "ci_95_lower": float(agg_ci_lower),
                    "ci_95_upper": float(agg_ci_upper),
                    "is_significant": agg_ci_lower > 0,
                    "num_shards": len(results)
                }
                
                summary["configurations"][config_key] = config_summary
                
                # å¯»æ‰¾æœ€ä½³é…ç½®
                if config_summary["is_significant"] and agg_mean > best_improvement:
                    best_improvement = agg_mean
                    best_config = config_key
        
        # å†³ç­–å»ºè®®
        if best_config:
            best_summary = summary["configurations"][best_config]
            if best_summary["ci_95_lower"] > 0.01:
                decision = "GO"
                confidence = "HIGH"
            elif best_summary["ci_95_lower"] > 0:
                decision = "GO_WITH_CAUTION"
                confidence = "MEDIUM"
            else:
                decision = "PAUSE"
                confidence = "LOW"
        else:
            decision = "NO_GO"
            confidence = "HIGH"
        
        summary["best_configuration"] = best_config
        summary["recommendation"] = {
            "decision": decision,
            "confidence": confidence,
            "best_params": summary["configurations"][best_config]["parameters"] if best_config else None
        }
        
        # ä¿å­˜æ±‡æ€»
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)
        
        print(f"ğŸ“‹ æ±‡æ€»æŠ¥å‘Š: {summary_file}")
        print(f"ğŸ¯ å†³ç­–å»ºè®®: {decision} (ç½®ä¿¡åº¦: {confidence})")
        
        return summary

# è¿è¡Œå™¨å‡½æ•°
def run_night_experiments():
    """å¯åŠ¨å¤œé—´å®éªŒ"""
    runner = ColabNightRunner(
        data_path=DATA_FILE,
        out_dir=EXPERIMENT_DIR,
        hours_per_shard=HOURS_PER_SHARD
    )
    runner.run_experiments()
    return runner
'''
    
    # å°†ä»£ç å†™å…¥æ–‡ä»¶
    with open('/content/night_runner_embedded.py', 'w', encoding='utf-8') as f:
        f.write(runner_code)
    
    print("âœ… å®éªŒæ‰§è¡Œå™¨åˆ›å»ºå®Œæˆ")
    return True

def main():
    """ä¸»æ‰§è¡Œæµç¨‹"""
    print("ğŸŒ™ Colabå¤œé—´å®éªŒå¯åŠ¨å™¨")
    print("=" * 50)
    
    # ç¯å¢ƒé…ç½®
    if not setup_colab_environment():
        print("âŒ ç¯å¢ƒé…ç½®å¤±è´¥")
        return False
    
    # æ•°æ®é›†ç”Ÿæˆ
    if not create_production_dataset():
        print("âŒ æ•°æ®é›†ç”Ÿæˆå¤±è´¥")
        return False
    
    # æ‰§è¡Œå™¨åˆ›å»º
    if not create_night_runner():
        print("âŒ æ‰§è¡Œå™¨åˆ›å»ºå¤±è´¥")
        return False
    
    print("\nğŸš€ å¯åŠ¨å¤œé—´å®éªŒ...")
    print(f"ğŸ“Š å®éªŒé…ç½®: {len(MMR_ALPHAS)} Ã— {len(THEME_SLOTS)} = {len(MMR_ALPHAS) * len(THEME_SLOTS)} ä¸ªå‚æ•°ç»„åˆ")
    print(f"â±ï¸  é¢„ä¼°æ€»æ—¶é•¿: {HOURS_PER_SHARD * TOTAL_SHARDS}+ å°æ—¶")
    print(f"ğŸ’¾ ç»“æœä¿å­˜è‡³: {EXPERIMENT_DIR}")
    
    try:
        # å¯¼å…¥å¹¶è¿è¡ŒåµŒå…¥çš„æ‰§è¡Œå™¨
        exec(open('/content/night_runner_embedded.py').read())
        runner = run_night_experiments()
        
        print("\nğŸ‰ å¤œé—´å®éªŒå¯åŠ¨æˆåŠŸ!")
        print("ğŸ’¤ å¯ä»¥å®‰å¿ƒç¡è§‰ï¼Œæ˜æ—©æŸ¥çœ‹Driveä¸­çš„ç»“æœ")
        return True
        
    except Exception as e:
        print(f"âŒ å®éªŒå¯åŠ¨å¤±è´¥: {e}")
        return False

# ===== æ‰§è¡Œå…¥å£ =====
if __name__ == "__main__":
    success = main()
    if success:
        print("\nâœ… æ‰€æœ‰ç³»ç»Ÿå°±ç»ªï¼Œå®éªŒè¿è¡Œä¸­...")
    else:
        print("\nâŒ å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")