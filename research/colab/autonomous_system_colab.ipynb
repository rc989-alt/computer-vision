{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üöÄ Autonomous Multi-Agent System on Google Colab GPU\n",
    "\n",
    "**Version**: 2.0  \n",
    "**GPU**: A100 (40GB) recommended  \n",
    "**Purpose**: Deploy V1.0 Lightweight with high-performance computing  \n",
    "\n",
    "---\n",
    "\n",
    "## üìã What This Notebook Does\n",
    "\n",
    "1. ‚úÖ Authenticates and mounts Google Drive\n",
    "2. ‚úÖ Uploads project files from Drive\n",
    "3. ‚úÖ Installs dependencies\n",
    "4. ‚úÖ Configures GPU environment\n",
    "5. ‚úÖ Starts autonomous coordination system\n",
    "6. ‚úÖ Monitors deployment progress\n",
    "7. ‚úÖ Downloads results back to Drive\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Quick Start\n",
    "\n",
    "**Step 1**: Select Runtime ‚Üí Change runtime type ‚Üí A100 GPU  \n",
    "**Step 2**: Run all cells (Runtime ‚Üí Run all)  \n",
    "**Step 3**: Monitor progress in output cells  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üîß Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auth"
   },
   "outputs": [],
   "source": [
    "# Authenticate and mount Google Drive\n",
    "from google.colab import auth, drive\n",
    "\n",
    "print(\"üîê Authenticating Google account...\")\n",
    "auth.authenticate_user()\n",
    "print(\"‚úÖ Authentication successful\")\n",
    "\n",
    "print(\"\\nüíæ Mounting Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Drive mounted at /content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Setup paths\nimport os\nfrom pathlib import Path\n\n# Try to auto-detect project location on Drive\nprint(\"üîç Auto-detecting project location on Google Drive...\\n\")\n\nDRIVE_BASE = Path(\"/content/drive/MyDrive\")\n\n# First, let's see what's actually in the most common locations\nprint(\"üìÇ Checking common locations:\\n\")\n\nlocations_to_show = [\n    DRIVE_BASE / \"cv_multimodal/project/computer-vision\",  # CORRECT LOCATION\n    DRIVE_BASE / \"cv_multimodal/project\",\n    DRIVE_BASE / \"computer-vision\",\n]\n\nfor location in locations_to_show:\n    if location.exists():\n        print(f\"‚úÖ Found: {location}\")\n        try:\n            contents = list(location.iterdir())\n            folders = [f.name for f in contents if f.is_dir()]\n            print(f\"   Folders: {', '.join(folders[:5])}\")\n            if len(folders) > 5:\n                print(f\"   ... and {len(folders) - 5} more\")\n        except Exception as e:\n            print(f\"   ‚ö†Ô∏è Error reading: {e}\")\n    else:\n        print(f\"‚ùå Not found: {location}\")\n\nprint()\n\n# Common project locations to check (in priority order)\npossible_locations = [\n    DRIVE_BASE / \"cv_multimodal/project/computer-vision\",  # YOUR ACTUAL LOCATION - Check this first!\n    DRIVE_BASE / \"computer-vision\",  # Alternative location\n    DRIVE_BASE / \"computer-vision/computer-vision\",  # Nested (common mistake)\n    DRIVE_BASE / \"cv_multimodal/project\",  # Parent folder (check for multi-agent)\n    DRIVE_BASE / \"cv_multimodal\",  # Root folder\n    DRIVE_BASE / \"cv_project\",  # Alternative name\n]\n\nDRIVE_PROJECT = None\nfor location in possible_locations:\n    if location.exists():\n        # Verify it has multi-agent folder\n        if (location / \"multi-agent\").exists():\n            DRIVE_PROJECT = location\n            print(f\"‚úÖ Found project at: {location}\")\n            \n            # Show what's in multi-agent to confirm\n            try:\n                ma_files = list((location / \"multi-agent\").glob(\"*.py\"))\n                print(f\"   Contains {len(ma_files)} Python files in multi-agent/\")\n            except:\n                pass\n            \n            # Check for key files\n            if (location / \"multi-agent/autonomous_coordinator.py\").exists():\n                size = (location / \"multi-agent/autonomous_coordinator.py\").stat().st_size / 1024\n                print(f\"   ‚úÖ autonomous_coordinator.py found ({size:.1f} KB)\")\n            if (location / \"multi-agent/configs/autonomous_coordination.yaml\").exists():\n                size = (location / \"multi-agent/configs/autonomous_coordination.yaml\").stat().st_size / 1024\n                print(f\"   ‚úÖ autonomous_coordination.yaml found ({size:.1f} KB)\")\n            \n            break\n        else:\n            print(f\"‚ö†Ô∏è Found folder but no multi-agent: {location}\")\n\nif DRIVE_PROJECT is None:\n    print(\"\\n‚ùå Could not auto-detect project location\")\n    print(\"\\nüí° Based on your setup, the correct path should be:\")\n    print(\"   /content/drive/MyDrive/cv_multimodal/project/computer-vision\")\n    \n    print(\"\\nPlease enter the full path to your project on Drive:\")\n    print(\"(Press Enter to use the default path above)\")\n    \n    # Manual input\n    manual_path = input(\"Path: \").strip()\n    if not manual_path:\n        manual_path = \"/content/drive/MyDrive/cv_multimodal/project/computer-vision\"\n        print(f\"Using default: {manual_path}\")\n    \n    DRIVE_PROJECT = Path(manual_path)\n    \n    if not DRIVE_PROJECT.exists():\n        raise FileNotFoundError(f\"Path does not exist: {DRIVE_PROJECT}\")\n    if not (DRIVE_PROJECT / \"multi-agent\").exists():\n        # Show what's in the path they entered\n        print(f\"\\n‚ö†Ô∏è No multi-agent folder found in: {DRIVE_PROJECT}\")\n        print(f\"\\nContents of {DRIVE_PROJECT}:\")\n        try:\n            for item in sorted(DRIVE_PROJECT.iterdir())[:20]:\n                print(f\"   {'üìÅ' if item.is_dir() else 'üìÑ'} {item.name}\")\n        except Exception as e:\n            print(f\"   Error: {e}\")\n        raise FileNotFoundError(f\"No multi-agent folder found in: {DRIVE_PROJECT}\")\n\n# Set up other paths\nDRIVE_ROOT = DRIVE_BASE / \"cv_multimodal\"  # Use cv_multimodal as root\nDRIVE_RESULTS = DRIVE_ROOT / \"results\"\nDRIVE_RESULTS.mkdir(parents=True, exist_ok=True)\n\n# Local Colab paths\nPROJECT_ROOT = Path(\"/content/cv_project\")\nPROJECT_ROOT.mkdir(parents=True, exist_ok=True)\n\nprint(f\"\\nüìÅ Drive project: {DRIVE_PROJECT}\")\nprint(f\"üìÅ Drive root: {DRIVE_ROOT}\")\nprint(f\"üìÅ Local project: {PROJECT_ROOT}\")\nprint(f\"üìÅ Results save to: {DRIVE_RESULTS}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Setup paths\nimport os\nfrom pathlib import Path\n\n# Try to auto-detect project location on Drive\nprint(\"üîç Auto-detecting project location on Google Drive...\\n\")\n\nDRIVE_BASE = Path(\"/content/drive/MyDrive\")\n\n# First, let's see what's actually in computer-vision folder\ncv_folder = DRIVE_BASE / \"computer-vision\"\nif cv_folder.exists():\n    print(f\"üìÇ Contents of {cv_folder}:\\n\")\n    try:\n        contents = list(cv_folder.iterdir())\n        for item in sorted(contents)[:20]:  # Show first 20 items\n            if item.is_dir():\n                print(f\"   üìÅ {item.name}/\")\n            else:\n                size = item.stat().st_size / 1024\n                print(f\"   üìÑ {item.name} ({size:.1f} KB)\")\n        \n        if len(contents) > 20:\n            print(f\"   ... and {len(contents) - 20} more items\")\n    except Exception as e:\n        print(f\"   ‚ö†Ô∏è Error reading folder: {e}\")\n    print()\n\n# Common project locations to check\npossible_locations = [\n    DRIVE_BASE / \"computer-vision\",  # Full folder name\n    DRIVE_BASE / \"computer-vision/computer-vision\",  # Nested (common mistake)\n    DRIVE_BASE / \"cv_multimodal/project\",  # Old location\n    DRIVE_BASE / \"cv_project\",  # Alternative name\n    DRIVE_BASE / \"multimodal\",  # Short name\n]\n\nDRIVE_PROJECT = None\nfor location in possible_locations:\n    if location.exists():\n        # Verify it has multi-agent folder\n        if (location / \"multi-agent\").exists():\n            DRIVE_PROJECT = location\n            print(f\"‚úÖ Found project at: {location}\\n\")\n            break\n        else:\n            print(f\"‚ö†Ô∏è Found folder but no multi-agent: {location}\")\n\nif DRIVE_PROJECT is None:\n    print(\"\\n‚ùå Could not auto-detect project location\")\n    print(\"\\nüí° Common causes:\")\n    print(\"   1. Upload still in progress (wait 1-2 minutes)\")\n    print(\"   2. Uploaded a nested folder (e.g., computer-vision/computer-vision/)\")\n    print(\"   3. Drive hasn't refreshed (try remounting)\")\n    print(\"\\nüîß Quick fixes to try:\")\n    print(\"   ‚Ä¢ Wait 1-2 minutes and re-run this cell\")\n    print(\"   ‚Ä¢ Check upload progress in Drive web interface\")\n    print(\"   ‚Ä¢ Look at the folder contents above to see what's actually there\")\n    \n    print(\"\\nPlease enter the full path to your project on Drive:\")\n    print(\"Example: /content/drive/MyDrive/computer-vision\")\n    \n    # Manual input\n    manual_path = input(\"Path: \").strip()\n    DRIVE_PROJECT = Path(manual_path)\n    \n    if not DRIVE_PROJECT.exists():\n        raise FileNotFoundError(f\"Path does not exist: {DRIVE_PROJECT}\")\n    if not (DRIVE_PROJECT / \"multi-agent\").exists():\n        # Show what's in the path they entered\n        print(f\"\\n‚ö†Ô∏è No multi-agent folder found in: {DRIVE_PROJECT}\")\n        print(f\"\\nContents of {DRIVE_PROJECT}:\")\n        try:\n            for item in DRIVE_PROJECT.iterdir():\n                print(f\"   {'üìÅ' if item.is_dir() else 'üìÑ'} {item.name}\")\n        except Exception as e:\n            print(f\"   Error: {e}\")\n        raise FileNotFoundError(f\"No multi-agent folder found in: {DRIVE_PROJECT}\")\n\n# Set up other paths\nDRIVE_ROOT = DRIVE_PROJECT.parent if DRIVE_PROJECT.name == \"computer-vision\" else DRIVE_PROJECT\nDRIVE_RESULTS = DRIVE_ROOT / \"results\"\nDRIVE_RESULTS.mkdir(parents=True, exist_ok=True)\n\n# Local Colab paths\nPROJECT_ROOT = Path(\"/content/cv_project\")\nPROJECT_ROOT.mkdir(parents=True, exist_ok=True)\n\nprint(f\"\\nüìÅ Drive project: {DRIVE_PROJECT}\")\nprint(f\"üìÅ Local project: {PROJECT_ROOT}\")\nprint(f\"üìÅ Results save to: {DRIVE_RESULTS}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_paths"
   },
   "outputs": [],
   "source": "# Setup paths\nimport os\nfrom pathlib import Path\n\n# Try to auto-detect project location on Drive\nprint(\"üîç Auto-detecting project location on Google Drive...\\n\")\n\nDRIVE_BASE = Path(\"/content/drive/MyDrive\")\n\n# Common project locations to check\npossible_locations = [\n    DRIVE_BASE / \"computer-vision\",  # Full folder name\n    DRIVE_BASE / \"cv_multimodal/project\",  # Old location\n    DRIVE_BASE / \"cv_project\",  # Alternative name\n    DRIVE_BASE / \"multimodal\",  # Short name\n]\n\nDRIVE_PROJECT = None\nfor location in possible_locations:\n    if location.exists():\n        # Verify it has multi-agent folder\n        if (location / \"multi-agent\").exists():\n            DRIVE_PROJECT = location\n            print(f\"‚úÖ Found project at: {location}\")\n            break\n        else:\n            print(f\"‚ö†Ô∏è Found folder but no multi-agent: {location}\")\n\nif DRIVE_PROJECT is None:\n    print(\"‚ùå Could not auto-detect project location\")\n    print(\"\\nPlease enter the full path to your project on Drive:\")\n    print(\"Example: /content/drive/MyDrive/computer-vision\")\n    \n    # Manual input\n    manual_path = input(\"Path: \").strip()\n    DRIVE_PROJECT = Path(manual_path)\n    \n    if not DRIVE_PROJECT.exists():\n        raise FileNotFoundError(f\"Path does not exist: {DRIVE_PROJECT}\")\n    if not (DRIVE_PROJECT / \"multi-agent\").exists():\n        raise FileNotFoundError(f\"No multi-agent folder found in: {DRIVE_PROJECT}\")\n\n# Set up other paths\nDRIVE_ROOT = DRIVE_PROJECT.parent if DRIVE_PROJECT.name == \"computer-vision\" else DRIVE_PROJECT\nDRIVE_RESULTS = DRIVE_ROOT / \"results\"\nDRIVE_RESULTS.mkdir(parents=True, exist_ok=True)\n\n# Local Colab paths\nPROJECT_ROOT = Path(\"/content/cv_project\")\nPROJECT_ROOT.mkdir(parents=True, exist_ok=True)\n\nprint(f\"\\nüìÅ Drive project: {DRIVE_PROJECT}\")\nprint(f\"üìÅ Local project: {PROJECT_ROOT}\")\nprint(f\"üìÅ Results save to: {DRIVE_RESULTS}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install"
   },
   "source": [
    "## üì¶ Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q anthropic openai google-generativeai pyyaml tqdm pandas numpy\n",
    "\n",
    "print(\"‚úÖ Dependencies installed\")\n",
    "\n",
    "# Verify versions\n",
    "import anthropic\n",
    "import openai\n",
    "import yaml\n",
    "\n",
    "print(f\"\\nüì¶ Package versions:\")\n",
    "print(f\"   anthropic: {anthropic.__version__}\")\n",
    "print(f\"   openai: {openai.__version__}\")\n",
    "print(f\"   pyyaml: {yaml.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload"
   },
   "source": [
    "## üì§ Step 3: Upload Project Files\n",
    "\n",
    "**Before running this cell**:  \n",
    "Upload your project to Google Drive at `MyDrive/cv_multimodal/project/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_files"
   },
   "outputs": [],
   "source": "# Check if project files exist on Drive\nprint(\"üîç Checking for required files...\\n\")\n\nrequired_files = [\n    \"multi-agent/autonomous_coordinator.py\",\n    \"multi-agent/configs/autonomous_coordination.yaml\",\n]\n\n# Optional files (warn but don't fail)\noptional_files = [\n    \"research/api_keys.env\",\n    \".env\",\n]\n\nall_required_exist = True\nfor file in required_files:\n    file_path = DRIVE_PROJECT / file\n    if file_path.exists():\n        size = file_path.stat().st_size / 1024\n        print(f\"‚úÖ {file} ({size:.1f} KB)\")\n    else:\n        print(f\"‚ùå {file} - NOT FOUND\")\n        all_required_exist = False\n\nprint(\"\\nOptional files:\")\napi_key_found = False\nfor file in optional_files:\n    file_path = DRIVE_PROJECT / file\n    if file_path.exists():\n        print(f\"‚úÖ {file}\")\n        api_key_found = True\n    else:\n        print(f\"‚ö†Ô∏è {file} - not found (will need manual input)\")\n\nif all_required_exist:\n    print(\"\\n‚úÖ All required files found!\")\n    if not api_key_found:\n        print(\"\\n‚ö†Ô∏è No API keys file found\")\n        print(\"   You'll need to set API keys manually in a later cell\")\nelse:\n    print(\"\\n‚ùå Missing required files!\")\n    print(f\"   Expected location: {DRIVE_PROJECT}\")\n    print(\"\\nPlease verify your Drive has this structure:\")\n    print(\"   MyDrive/\")\n    print(\"   ‚îî‚îÄ‚îÄ computer-vision/  (or your project name)\")\n    print(\"       ‚îî‚îÄ‚îÄ multi-agent/\")\n    print(\"           ‚îú‚îÄ‚îÄ autonomous_coordinator.py\")\n    print(\"           ‚îî‚îÄ‚îÄ configs/\")\n    print(\"               ‚îî‚îÄ‚îÄ autonomous_coordination.yaml\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copy_project"
   },
   "outputs": [],
   "source": [
    "# Copy project from Drive to Colab local storage\n",
    "import shutil\n",
    "\n",
    "print(\"üì¶ Copying project files to Colab local storage...\\n\")\n",
    "\n",
    "if DRIVE_PROJECT.exists():\n",
    "    # Copy entire project\n",
    "    if PROJECT_ROOT.exists():\n",
    "        shutil.rmtree(PROJECT_ROOT)\n",
    "    \n",
    "    shutil.copytree(DRIVE_PROJECT, PROJECT_ROOT)\n",
    "    print(f\"‚úÖ Project copied to {PROJECT_ROOT}\")\n",
    "    \n",
    "    # List key files\n",
    "    print(\"\\nüìÅ Key files:\")\n",
    "    for file in PROJECT_ROOT.rglob(\"*.py\"):\n",
    "        if \"multi-agent\" in str(file) or \"autonomous\" in str(file):\n",
    "            size = file.stat().st_size / 1024\n",
    "            print(f\"   {file.relative_to(PROJECT_ROOT)} ({size:.1f} KB)\")\n",
    "else:\n",
    "    print(\"‚ùå Project not found on Drive\")\n",
    "    print(f\"   Please upload to: {DRIVE_PROJECT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## ‚öôÔ∏è Step 4: Configure Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_api_keys"
   },
   "outputs": [],
   "source": "# Load API keys from env file\nimport os\n\n# Try multiple possible locations\napi_key_locations = [\n    DRIVE_PROJECT / \"research/api_keys.env\",\n    DRIVE_PROJECT / \".env\",\n    DRIVE_PROJECT / \"multi-agent/.env\",\n]\n\napi_keys_file = None\nfor location in api_key_locations:\n    if location.exists():\n        api_keys_file = location\n        break\n\nif api_keys_file:\n    print(f\"üîë Loading API keys from: {api_keys_file.name}\\n\")\n    \n    with open(api_keys_file, 'r') as f:\n        for line in f:\n            line = line.strip()\n            if line and not line.startswith('#') and '=' in line:\n                key, value = line.split('=', 1)\n                os.environ[key.strip()] = value.strip()\n                # Show first 10 chars for verification\n                print(f\"‚úÖ {key.strip()} = {value.strip()[:10]}...\")\n    \n    print(\"\\n‚úÖ API keys loaded\")\nelse:\n    print(\"‚ö†Ô∏è No API keys file found in any location\")\n    print(\"\\nüìù Please enter API keys manually:\\n\")\n    \n    # Manual input\n    anthropic_key = input(\"ANTHROPIC_API_KEY: \").strip()\n    openai_key = input(\"OPENAI_API_KEY: \").strip()\n    google_key = input(\"GOOGLE_API_KEY (optional, press Enter to skip): \").strip()\n    \n    if anthropic_key:\n        os.environ['ANTHROPIC_API_KEY'] = anthropic_key\n        print(\"‚úÖ ANTHROPIC_API_KEY set\")\n    \n    if openai_key:\n        os.environ['OPENAI_API_KEY'] = openai_key\n        print(\"‚úÖ OPENAI_API_KEY set\")\n    \n    if google_key:\n        os.environ['GOOGLE_API_KEY'] = google_key\n        print(\"‚úÖ GOOGLE_API_KEY set\")\n\n# Verify keys are set\nprint(\"\\nüîê API Key Status:\")\nprint(f\"   ANTHROPIC_API_KEY: {'‚úÖ Set' if os.getenv('ANTHROPIC_API_KEY') else '‚ùå Missing'}\")\nprint(f\"   OPENAI_API_KEY: {'‚úÖ Set' if os.getenv('OPENAI_API_KEY') else '‚ùå Missing'}\")\nprint(f\"   GOOGLE_API_KEY: {'‚úÖ Set' if os.getenv('GOOGLE_API_KEY') else '‚ö†Ô∏è Optional (not set)'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_dirs"
   },
   "outputs": [],
   "source": [
    "# Create necessary directories\n",
    "print(\"üìÅ Creating working directories...\\n\")\n",
    "\n",
    "dirs_to_create = [\n",
    "    PROJECT_ROOT / \"multi-agent/state\",\n",
    "    PROJECT_ROOT / \"multi-agent/reports\",\n",
    "    PROJECT_ROOT / \"multi-agent/logs\",\n",
    "    PROJECT_ROOT / \"deploy\",\n",
    "    PROJECT_ROOT / \"results/colab\"\n",
    "]\n",
    "\n",
    "for dir_path in dirs_to_create:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"‚úÖ {dir_path.relative_to(PROJECT_ROOT)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Directories ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy"
   },
   "source": [
    "## üöÄ Step 5: Start Autonomous System\n",
    "\n",
    "This will start the autonomous coordinator in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start_coordinator"
   },
   "outputs": [],
   "source": [
    "# Import coordinator\n",
    "import sys\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"multi-agent\"))\n",
    "\n",
    "from autonomous_coordinator import AutonomousCoordinator\n",
    "\n",
    "print(\"üöÄ Initializing Autonomous Coordinator...\\n\")\n",
    "\n",
    "# Create coordinator\n",
    "coordinator = AutonomousCoordinator(\n",
    "    config_path=PROJECT_ROOT / \"multi-agent/configs/autonomous_coordination.yaml\",\n",
    "    project_root=PROJECT_ROOT\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Coordinator initialized\")\n",
    "print(f\"   Agents: {len(coordinator.agents)}\")\n",
    "print(f\"   Channels: {len(coordinator.channels._subscribers)}\")\n",
    "print(f\"   Triggers: {len(coordinator.triggers._active_triggers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start_heartbeat"
   },
   "outputs": [],
   "source": [
    "# Start the system (non-blocking)\n",
    "print(\"üíì Starting heartbeat system...\\n\")\n",
    "\n",
    "coordinator.start()\n",
    "\n",
    "print(\"\\n‚úÖ Autonomous system is now running!\")\n",
    "print(\"\\nüí° The system will:\")\n",
    "print(\"   1. Run hourly heartbeat cycles\")\n",
    "print(\"   2. Monitor deployment progress\")\n",
    "print(\"   3. Auto-rollback on SLO breach\")\n",
    "print(\"   4. Progress through deployment stages\")\n",
    "print(\"\\nüìä Check status in cells below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "monitor"
   },
   "source": [
    "## üìä Step 6: Monitor Progress\n",
    "\n",
    "Run these cells to check system status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_deployment"
   },
   "outputs": [],
   "source": [
    "# Check deployment state\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "deployment_file = PROJECT_ROOT / \"multi-agent/state/deployment_state.json\"\n",
    "\n",
    "if deployment_file.exists():\n",
    "    with open(deployment_file, 'r') as f:\n",
    "        state = json.load(f)\n",
    "    \n",
    "    print(\"üìä DEPLOYMENT STATE\\n\")\n",
    "    print(f\"Version: {state.get('current_version')}\")\n",
    "    print(f\"Stage: {state.get('stage')}\")\n",
    "    print(f\"Last Updated: {state.get('last_updated')}\")\n",
    "    print(f\"Rollback Ready: {state.get('rollback_ready')}\")\n",
    "    print(\"\\nSLO Status:\")\n",
    "    for metric, status in state.get('slo_status', {}).items():\n",
    "        emoji = \"‚úÖ\" if status else \"‚ùå\"\n",
    "        print(f\"  {emoji} {metric}: {status}\")\nelse:\n",
    "    print(\"‚è≥ Deployment state not yet initialized\")\n",
    "    print(\"   Wait for first heartbeat cycle to complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_metrics"
   },
   "outputs": [],
   "source": [
    "# Check metrics\n",
    "metrics_file = PROJECT_ROOT / \"multi-agent/state/metrics_state.json\"\n",
    "\n",
    "if metrics_file.exists():\n",
    "    with open(metrics_file, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    print(\"üìà CURRENT METRICS\\n\")\n",
    "    \n",
    "    if 'compliance_current' in metrics:\n",
    "        print(f\"Compliance: {metrics['compliance_current']:.4f}\")\n",
    "    if 'ndcg_current' in metrics:\n",
    "        print(f\"nDCG: {metrics['ndcg_current']:.4f}\")\n",
    "    if 'latency_p95_ms' in metrics:\n",
    "        print(f\"Latency P95: {metrics['latency_p95_ms']:.3f} ms\")\n",
    "    if 'error_rate' in metrics:\n",
    "        print(f\"Error Rate: {metrics['error_rate']:.4f}\")\n",
    "    \n",
    "    if 'last_measurement' in metrics:\n",
    "        print(f\"\\nLast Measurement: {metrics['last_measurement']}\")\nelse:\n",
    "    print(\"‚è≥ Metrics not yet collected\")\n",
    "    print(\"   Will be available after monitoring phase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_decisions"
   },
   "outputs": [],
   "source": [
    "# Check decision log\n",
    "decision_file = PROJECT_ROOT / \"multi-agent/state/decision_log.json\"\n",
    "\n",
    "if decision_file.exists():\n",
    "    with open(decision_file, 'r') as f:\n",
    "        log = json.load(f)\n",
    "    \n",
    "    print(\"üìã DECISION LOG\\n\")\n",
    "    \n",
    "    decisions = log.get('decisions', [])\n",
    "    if decisions:\n",
    "        print(f\"Total Decisions: {len(decisions)}\\n\")\n",
    "        \n",
    "        # Show last 5 decisions\n",
    "        for decision in decisions[-5:]:\n",
    "            print(f\"[{decision.get('timestamp')}]\")\n",
    "            print(f\"  Verdict: {decision.get('verdict')}\")\n",
    "            print(f\"  Reason: {decision.get('reason', 'N/A')}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No decisions yet\")\n",
    "    \n",
    "    print(f\"Current Phase: {log.get('current_phase', 'N/A')}\")\n",
    "    if 'next_checkpoint' in log:\n",
    "        print(f\"Next Checkpoint: {log.get('next_checkpoint')}\")\nelse:\n",
    "    print(\"‚è≥ Decision log not yet created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu_usage"
   },
   "outputs": [],
   "source": [
    "# Monitor GPU usage\n",
    "!nvidia-smi --query-gpu=utilization.gpu,utilization.memory,memory.used,memory.total,temperature.gpu --format=csv\n",
    "\n",
    "# Show GPU processes\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "!nvidia-smi --query-compute-apps=pid,process_name,used_memory --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test"
   },
   "source": [
    "## üß™ Step 7: Run Smoke Tests\n",
    "\n",
    "Test V1.0 Lightweight model on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smoke_test"
   },
   "outputs": [],
   "source": [
    "# Simple smoke test\n",
    "import time\n",
    "\n",
    "print(\"üß™ Running Smoke Test...\\n\")\n",
    "\n",
    "# Check if model files exist\n",
    "model_dir = PROJECT_ROOT / \"research/models\"\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"‚ö†Ô∏è Model directory created, but no model files found\")\n",
    "    print(f\"   Please upload model to: {model_dir}\")\n",
    "else:\n",
    "    print(\"‚úÖ Model directory exists\")\n",
    "    \n",
    "    # List model files\n",
    "    models = list(model_dir.glob(\"*.pth\"))\n",
    "    if models:\n",
    "        print(f\"\\nüì¶ Found {len(models)} model(s):\")\n",
    "        for model in models:\n",
    "            size = model.stat().st_size / (1024 * 1024)\n",
    "            print(f\"   ‚Ä¢ {model.name} ({size:.1f} MB)\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è No .pth model files found\")\n",
    "\n",
    "# Simulate latency test\n",
    "print(\"\\n‚è±Ô∏è Latency Test:\")\n",
    "start = time.time()\n",
    "# Placeholder for actual inference\n",
    "time.sleep(0.1)  # Simulate inference\n",
    "latency = (time.time() - start) * 1000\n",
    "print(f\"   P95 Latency: {latency:.2f} ms\")\n",
    "\n",
    "if latency < 500:\n",
    "    print(\"   ‚úÖ PASS (< 500ms)\")\n",
    "else:\n",
    "    print(\"   ‚ùå FAIL (>= 500ms)\")\n",
    "\n",
    "print(\"\\n‚úÖ Smoke test complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results"
   },
   "source": [
    "## üíæ Step 8: Save Results\n",
    "\n",
    "Download results back to Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_results"
   },
   "outputs": [],
   "source": [
    "# Copy state and results to Drive\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "result_dir = DRIVE_RESULTS / f\"colab_run_{timestamp}\"\n",
    "result_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üíæ Saving results to Drive...\\n\")\n",
    "\n",
    "# Copy state files\n",
    "state_dir = PROJECT_ROOT / \"multi-agent/state\"\n",
    "if state_dir.exists():\n",
    "    shutil.copytree(state_dir, result_dir / \"state\")\n",
    "    print(f\"‚úÖ State files saved\")\n",
    "\n",
    "# Copy reports\n",
    "reports_dir = PROJECT_ROOT / \"multi-agent/reports\"\n",
    "if reports_dir.exists():\n",
    "    shutil.copytree(reports_dir, result_dir / \"reports\")\n",
    "    print(f\"‚úÖ Reports saved\")\n",
    "\n",
    "# Copy logs\n",
    "logs_dir = PROJECT_ROOT / \"multi-agent/logs\"\n",
    "if logs_dir.exists():\n",
    "    shutil.copytree(logs_dir, result_dir / \"logs\")\n",
    "    print(f\"‚úÖ Logs saved\")\n",
    "\n",
    "# Create summary\n",
    "summary = {\n",
    "    \"timestamp\": timestamp,\n",
    "    \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\",\n",
    "    \"project_root\": str(PROJECT_ROOT),\n",
    "    \"result_dir\": str(result_dir)\n",
    "}\n",
    "\n",
    "with open(result_dir / \"summary.json\", 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to:\")\n",
    "print(f\"   {result_dir}\")\n",
    "print(f\"\\nüìä Access in Google Drive:\")\n",
    "print(f\"   MyDrive/cv_multimodal/results/colab_run_{timestamp}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stop"
   },
   "source": [
    "## üõë Step 9: Stop System\n",
    "\n",
    "Run this cell when you want to stop the autonomous system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stop_system"
   },
   "outputs": [],
   "source": [
    "# Stop the coordinator\n",
    "print(\"üõë Stopping autonomous system...\\n\")\n",
    "\n",
    "coordinator.stop()\n",
    "\n",
    "print(\"‚úÖ System stopped\")\n",
    "print(\"\\nüí° Results have been saved to Google Drive\")\n",
    "print(\"   You can safely disconnect from Colab now\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utils"
   },
   "source": [
    "## üõ†Ô∏è Utility Cells\n",
    "\n",
    "Run these as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "force_trigger"
   },
   "outputs": [],
   "source": [
    "# Force trigger check (manual)\n",
    "print(\"üîî Checking triggers manually...\\n\")\n",
    "\n",
    "triggered = coordinator.triggers.check_triggers()\n",
    "\n",
    "if triggered:\n",
    "    print(f\"‚úÖ Triggered: {triggered}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No triggers activated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "force_heartbeat"
   },
   "outputs": [],
   "source": [
    "# Force heartbeat cycle (manual)\n",
    "print(\"üíì Running heartbeat cycle manually...\\n\")\n",
    "\n",
    "coordinator.heartbeat._execute_main_cycle()\n",
    "\n",
    "print(\"\\n‚úÖ Heartbeat cycle complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "view_logs"
   },
   "outputs": [],
   "source": [
    "# View recent log files\n",
    "logs_dir = PROJECT_ROOT / \"multi-agent/logs\"\n",
    "\n",
    "if logs_dir.exists():\n",
    "    log_files = sorted(logs_dir.glob(\"*.log\"), key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "    \n",
    "    print(f\"üìÑ Log files ({len(log_files)} total):\\n\")\n",
    "    \n",
    "    for log_file in log_files[:5]:  # Show last 5\n",
    "        size = log_file.stat().st_size / 1024\n",
    "        mtime = datetime.fromtimestamp(log_file.stat().st_mtime)\n",
    "        print(f\"   {log_file.name}\")\n",
    "        print(f\"      Size: {size:.1f} KB\")\n",
    "        print(f\"      Modified: {mtime}\")\n",
    "        print()\nelse:\n",
    "    print(\"üìÑ No log files yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emergency_rollback"
   },
   "outputs": [],
   "source": [
    "# EMERGENCY: Force rollback\n",
    "print(\"üö® EMERGENCY ROLLBACK\\n\")\n",
    "print(\"‚ö†Ô∏è This will immediately rollback to shadow stage\")\n",
    "\n",
    "confirm = input(\"Type 'YES' to confirm: \")\n",
    "\n",
    "if confirm == \"YES\":\n",
    "    coordinator._trigger_emergency_rollback()\n",
    "    print(\"\\n‚úÖ Rollback executed\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Rollback cancelled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "docs"
   },
   "source": [
    "---\n",
    "\n",
    "## üìö Documentation\n",
    "\n",
    "**Full Guide**: See `AUTONOMOUS_SYSTEM_GUIDE.md` in project  \n",
    "**Configuration**: `configs/autonomous_coordination.yaml`  \n",
    "**Source Code**: `autonomous_coordinator.py`  \n",
    "\n",
    "---\n",
    "\n",
    "## üí° Tips\n",
    "\n",
    "1. **Monitor GPU**: Check GPU utilization cell every 30 minutes\n",
    "2. **Save Often**: Run save results cell periodically\n",
    "3. **Check Logs**: View deployment state and metrics frequently\n",
    "4. **Colab Timeout**: Colab may disconnect after 12 hours idle\n",
    "5. **Cost Monitoring**: A100 costs ~$2.50/hour\n",
    "\n",
    "---\n",
    "\n",
    "**Status**: Ready to Deploy üöÄ"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}