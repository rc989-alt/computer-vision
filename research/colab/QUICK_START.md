# Quick Start - Updated Autonomous System

## Copy-Paste This Into Colab

### Cell 1: Verify Everything is Ready
```python
# Verification check
exec(open('/content/drive/MyDrive/cv_multimodal/project/computer-vision-clean/research/colab/verify_deployment.py').read())
```

**Expected output:** All checks passed âœ…

---

### Cell 1.5: Test Gemini Connection (OPTIONAL)
```python
# Test Gemini API - ensures CoTRR Team agent works
exec(open('/content/drive/MyDrive/cv_multimodal/project/computer-vision-clean/research/colab/test_gemini_connection.py').read())
```

**Expected output:**
- API key found âœ…
- Connection successful âœ…
- Models listed âœ…
- Test generation works âœ…

**Note:** If this fails, the system will still work with 5 agents instead of 6 (Gemini agent will be skipped)

---

### Cell 2: Deploy Updated System
```python
# Deploy with new architecture
exec(open('/content/drive/MyDrive/cv_multimodal/project/computer-vision-clean/research/colab/deploy_updated_system.py').read())
```

**Expected output:**
- Files copied âœ…
- Directories created âœ…
- Coordinator started âœ…
- System running âœ…

---

### Cell 3: Monitor Progress
```python
# Quick status check
import subprocess

print("ğŸ“Š SYSTEM STATUS")
print("="*60)

# Show recent logs
print("\nğŸ” Recent Activity:")
result = subprocess.run(['tail', '-30', '/content/executive.log'],
                       capture_output=True, text=True)
print(result.stdout)

print("\nğŸ“ Planning Reports:")
result = subprocess.run(['ls', '-lh', '/content/cv_project/multi-agent/reports/planning/'],
                       capture_output=True, text=True)
print(result.stdout)

print("\nğŸ“ Execution Reports:")
result = subprocess.run(['ls', '-lh', '/content/cv_project/multi-agent/reports/execution/'],
                       capture_output=True, text=True)
print(result.stdout)

print("\nğŸ¤ Handoff File:")
try:
    with open('/content/cv_project/multi-agent/reports/handoff/pending_actions.json', 'r') as f:
        import json
        data = json.load(f)
        print(f"   Actions: {data.get('count', 0)}")
        print(f"   Timestamp: {data.get('timestamp', 'N/A')}")
except FileNotFoundError:
    print("   â³ Waiting for first planning meeting...")
```

---

## Then: Open Monitoring Notebooks

**In Colab file browser, open these in separate tabs:**

1. `research/colab/monitor_planning.ipynb`
   - Run all cells
   - Watch planning meetings and strategic decisions

2. `research/colab/monitor_execution.ipynb`
   - Run all cells
   - Watch executive team execute actions

---

## Timeline

**Minutes 0-5:** System initialization
- Coordinator starts
- Agents load
- Heartbeat begins

**Minutes 5-30:** First planning meeting
- Planning Team discusses V1.0 goals
- Creates strategic recommendations
- Saves handoff file with actions

**Minutes 30+:** Continuous execution
- Executive Team reads actions
- Agents deploy models, run evaluations
- Metrics collected
- Results reported

**Minutes 60:** Second planning meeting
- Reviews execution results
- Adjusts strategy
- New actions issued

**Repeats every 30 minutes** â†’ Progressive deployment toward V1.0

---

## What You'll See

### In monitor_planning.ipynb:
```
ğŸ“‹ Latest Meeting: summary_2025-10-13_23-45
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

## Meeting Summary

**Participants:** 5 agents
**Topic:** V1.0 Lightweight Enhancer Deployment
**Duration:** 15 minutes

### Key Decisions:
1. Deploy to shadow environment first
2. Run evaluation on test set
3. Collect baseline metrics
...

ğŸ¯ Actions Recommended: 16

1. Deploy V1.0 model to shadow environment...
   Owner: ops_commander
   Priority: high

2. Run comprehensive evaluation suite...
   Owner: latency_analysis
   Priority: high
...
```

### In monitor_execution.ipynb:
```
ğŸ¤– Recent Agent Activity:

[23:47:12] ğŸ¤– ops_commander: Deploying V1.0 to shadow
[23:47:45] [TOOL] deploy_model(source=models/v1.0.pth, stage=shadow)
[23:48:01] âœ… Deployment successful: deployment/shadow/v1.0.pth
[23:48:15] ğŸ¤– latency_analysis: Starting evaluation
[23:48:20] [TOOL] run_evaluation(eval_script=research/evaluate_v1.py)
[23:50:33] âœ… Evaluation complete: NDCG@10=0.7234
...

ğŸš€ Deployments:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   shadow: âœ… 3 files
   5_percent: âŒ Not deployed
   20_percent: âŒ Not deployed
   production: âŒ Not deployed
```

---

## Troubleshooting

### If verification fails:
1. Wait 60 seconds for Drive sync
2. Check API keys loaded: `print(os.getenv('ANTHROPIC_API_KEY')[:20])`
3. Rerun verification

### If deployment hangs:
1. Check logs: `!tail -50 /content/executive.log`
2. Look for errors
3. Restart: `coordinator.stop()` then `coordinator.start()`

### If no planning meeting:
- First meeting takes ~30 minutes
- Check heartbeat: `!grep "HEARTBEAT" /content/executive.log`
- Check meeting schedule: `!grep "meeting" /content/executive.log`

### If no execution:
- Check handoff file exists: `!cat reports/handoff/pending_actions.json`
- Check tools loaded: `!grep "ExecutionTools" /content/executive.log`
- Check agent activity: `!grep "ğŸ¤–" /content/executive.log`

---

## Success Indicators

You'll know it's working when:

âœ… Verification passes all checks
âœ… Deployment completes without errors
âœ… Logs show heartbeat cycles every 5 minutes
âœ… Planning meeting completes after ~30 minutes
âœ… Handoff file appears with actions
âœ… Executive agents start executing
âœ… Tool usage logged: `[TOOL]` entries
âœ… Deployment artifacts created
âœ… Metrics collected and reported

---

**Ready?** Start with Cell 1 above! ğŸš€
