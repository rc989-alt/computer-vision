{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning Team Review Meeting - Post-Execution Cycle\n",
    "\n",
    "**Purpose:** Review Executive Team execution results and plan next cycle\n",
    "\n",
    "**Flow:**\n",
    "1. üì• Read execution results from Executive Team\n",
    "2. ü§ñ Initialize Planning Team (4 agents)\n",
    "3. üìä Analyze results and assess progress\n",
    "4. üéØ Generate new `pending_actions.json` for next cycle\n",
    "5. üíæ Save to Google Drive\n",
    "\n",
    "**Timeline:** After each Executive Team execution cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup: Mount Google Drive & Load API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set project paths\n",
    "GDRIVE_ROOT = '/content/drive/MyDrive/cv_multimodal/project'\n",
    "PROJECT_ROOT = f'{GDRIVE_ROOT}/computer-vision-clean'\n",
    "MULTI_AGENT_ROOT = f'{PROJECT_ROOT}/multi-agent'\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.insert(0, MULTI_AGENT_ROOT)\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(f\"‚úÖ Google Drive mounted\")\n",
    "print(f\"üìÅ Project root: {PROJECT_ROOT}\")\n",
    "print(f\"ü§ñ Multi-agent root: {MULTI_AGENT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üîç FINDING AND LOADING API KEYS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Search for .env file in multiple locations\n",
    "search_paths = [\n",
    "    f'{GDRIVE_ROOT}/.env',\n",
    "    f'{GDRIVE_ROOT}/computer-vision-clean/.env',\n",
    "    '/content/drive/MyDrive/cv_multimodal/.env',\n",
    "    '/content/drive/My Drive/cv_multimodal/project/.env',\n",
    "    f'{PROJECT_ROOT}/.env'\n",
    "]\n",
    "\n",
    "env_file = None\n",
    "for path in search_paths:\n",
    "    if Path(path).exists():\n",
    "        env_file = Path(path)\n",
    "        print(f\"\\n‚úÖ Found .env file: {path}\")\n",
    "        print(f\"   Size: {env_file.stat().st_size} bytes\\n\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"   Checking: {path}... not found\")\n",
    "\n",
    "if not env_file:\n",
    "    print(\"\\nüîç Searching entire cv_multimodal directory...\")\n",
    "    base = Path('/content/drive/MyDrive/cv_multimodal')\n",
    "    if base.exists():\n",
    "        all_env = list(base.rglob('*.env')) + list(base.rglob('.env*'))\n",
    "        if all_env:\n",
    "            print(f\"\\n‚úÖ Found .env files:\")\n",
    "            for f in all_env:\n",
    "                print(f\"   üìÑ {f}\")\n",
    "            env_file = all_env[0]\n",
    "    \n",
    "    if not env_file:\n",
    "        print(\"\\n‚ùå No .env file found!\")\n",
    "        raise FileNotFoundError(\"No .env file found - check Google Drive\")\n",
    "\n",
    "# Load all API keys\n",
    "loaded_keys = []\n",
    "with open(env_file, 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line and not line.startswith('#') and '=' in line:\n",
    "            key, value = line.split('=', 1)\n",
    "            key = key.strip()\n",
    "            value = value.strip().strip('\"').strip(\"'\")  # Remove quotes\n",
    "            os.environ[key] = value\n",
    "            loaded_keys.append(key)\n",
    "\n",
    "# Verify required keys for Planning Team\n",
    "required = {\n",
    "    'ANTHROPIC_API_KEY': 'Claude Opus 4 (Strategic Leader), Sonnet 4 (Empirical Lead)',\n",
    "    'OPENAI_API_KEY': 'GPT-4 (Critical Evaluator)',\n",
    "    'GOOGLE_API_KEY': 'Gemini (Research Advisor)'\n",
    "}\n",
    "\n",
    "print(\"Verifying required API keys:\\n\")\n",
    "all_loaded = True\n",
    "\n",
    "for key, usage in required.items():\n",
    "    value = os.environ.get(key)\n",
    "    if value and len(value) > 10:\n",
    "        masked = f\"{value[:8]}...{value[-4:]}\"\n",
    "        print(f\"‚úÖ {key}\")\n",
    "        print(f\"   Value: {masked}\")\n",
    "        print(f\"   Used by: {usage}\\n\")\n",
    "    else:\n",
    "        print(f\"‚ùå {key} - NOT FOUND OR INVALID\")\n",
    "        print(f\"   Needed by: {usage}\\n\")\n",
    "        all_loaded = False\n",
    "\n",
    "print(\"=\"*80)\n",
    "if all_loaded:\n",
    "    print(\"‚úÖ ALL API KEYS LOADED SUCCESSFULLY\")\n",
    "    print(f\"‚úÖ Loaded {len(loaded_keys)} total keys from: {env_file}\")\n",
    "    print(\"‚úÖ Ready to initialize Planning Team\")\n",
    "else:\n",
    "    print(\"‚ùå SOME API KEYS MISSING OR INVALID\")\n",
    "    print(\"‚ö†Ô∏è Planning Team execution will fail without all 3 keys\")\n",
    "    raise ValueError(\"Missing required API keys\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "!pip install -q anthropic openai google-generativeai python-dotenv pyyaml tiktoken\n",
    "\n",
    "print(\"‚úÖ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 1: Read Execution Results from Executive Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üì• READING EXECUTIVE TEAM EXECUTION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Read progress update (main handoff file)\n",
    "progress_file = Path(MULTI_AGENT_ROOT) / 'reports/handoff/execution_progress_update.md'\n",
    "\n",
    "if not progress_file.exists():\n",
    "    print(f\"‚ùå No execution results found at {progress_file}\")\n",
    "    print(\"‚ö†Ô∏è Executive Team must complete execution first\")\n",
    "    raise FileNotFoundError(f\"Missing: {progress_file}\")\n",
    "\n",
    "with open(progress_file, 'r') as f:\n",
    "    progress_text = f.read()\n",
    "\n",
    "print(f\"\\n‚úÖ Found execution progress report\")\n",
    "print(f\"   File: {progress_file}\")\n",
    "print(f\"   Size: {len(progress_text)} characters\\n\")\n",
    "\n",
    "# Find most recent JSON results\n",
    "results_dir = Path(MULTI_AGENT_ROOT) / 'reports/execution/results'\n",
    "json_files = list(results_dir.glob('execution_results_*.json'))\n",
    "\n",
    "if json_files:\n",
    "    # Get most recent by modification time\n",
    "    latest_json = max(json_files, key=lambda p: p.stat().st_mtime)\n",
    "    with open(latest_json, 'r') as f:\n",
    "        results_data = json.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Found execution results JSON\")\n",
    "    print(f\"   File: {latest_json.name}\")\n",
    "    print(f\"   Tasks: {results_data.get('total_tasks', 'N/A')}\")\n",
    "    print(f\"   Completed: {results_data.get('completed', 'N/A')} ‚úÖ\")\n",
    "    print(f\"   Failed: {results_data.get('failed', 'N/A')} ‚ùå\")\n",
    "else:\n",
    "    results_data = {}\n",
    "    latest_json = None\n",
    "    print(\"‚ö†Ô∏è No JSON results found, using markdown only\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä EXECUTION SUMMARY FOR PLANNING TEAM REVIEW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if results_data:\n",
    "    print(f\"\\nüìã Executive Team Results:\")\n",
    "    print(f\"   Total tasks: {results_data.get('total_tasks', 'N/A')}\")\n",
    "    print(f\"   Completed: {results_data.get('completed', 'N/A')} ‚úÖ\")\n",
    "    print(f\"   Failed: {results_data.get('failed', 'N/A')} ‚ùå\")\n",
    "    print(f\"   Duration: {results_data.get('total_duration_seconds', 0):.1f}s\")\n",
    "\n",
    "print(f\"\\nüìÑ Progress Report Preview:\")\n",
    "print(progress_text[:500] + \"...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 2: Initialize Planning Team (4 Agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import multi-agent system components\n",
    "os.chdir(MULTI_AGENT_ROOT)\n",
    "\n",
    "from agents.roles import Agent, AgentConfig, AgentTeam\n",
    "from agents.router import AgentRouter, RoutingStrategy, Message\n",
    "\n",
    "print(\"‚úÖ Multi-agent system imported\")\n",
    "\n",
    "# Initialize Planning Team (4 agents)\n",
    "planning_team_agents = {}\n",
    "prompt_dir = Path(MULTI_AGENT_ROOT) / 'agents/prompts/planning_team'\n",
    "\n",
    "# Define Planning Team configuration\n",
    "planning_config = {\n",
    "    'strategic_leader': {\n",
    "        'name': 'Strategic Leader',\n",
    "        'model': 'claude-opus-4-20250514',  # Using Opus for strategic decisions\n",
    "        'provider': 'anthropic',\n",
    "        'role': 'Lead strategic planning and make GO/PAUSE/PIVOT decisions',\n",
    "        'prompt_file': '01_strategic_leader.md'\n",
    "    },\n",
    "    'empirical_validation': {\n",
    "        'name': 'Empirical Validation Lead',\n",
    "        'model': 'claude-sonnet-4-20250514',\n",
    "        'provider': 'anthropic',\n",
    "        'role': 'Validate statistical rigor and experimental methodology',\n",
    "        'prompt_file': '02_empirical_validation_lead.md'\n",
    "    },\n",
    "    'critical_evaluator': {\n",
    "        'name': 'Critical Evaluator',\n",
    "        'model': 'gpt-4-turbo-2024-04-09',\n",
    "        'provider': 'openai',\n",
    "        'role': 'Challenge claims and identify methodological risks',\n",
    "        'prompt_file': '03_critical_evaluator.md'\n",
    "    },\n",
    "    'research_advisor': {\n",
    "        'name': 'Gemini Research Advisor',\n",
    "        'model': 'gemini-2.0-flash-exp',\n",
    "        'provider': 'google',\n",
    "        'role': 'Provide literature context and alternative approaches',\n",
    "        'prompt_file': '04_gemini_research_advisor.md'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nü§ñ Initializing Planning Team:\")\n",
    "for agent_id, config in planning_config.items():\n",
    "    agent_cfg = AgentConfig(\n",
    "        name=config['name'],\n",
    "        model=config['model'],\n",
    "        provider=config['provider'],\n",
    "        role=config['role'],\n",
    "        prompt_file=config['prompt_file'],\n",
    "        temperature=0.7,\n",
    "        max_tokens=4000  # More tokens for strategic planning\n",
    "    )\n",
    "    planning_team_agents[agent_id] = Agent(agent_cfg, prompt_dir)\n",
    "    print(f\"   ‚úÖ {config['name']} ({config['model']})\")\n",
    "\n",
    "# Create agent team and router\n",
    "planning_team = AgentTeam(planning_team_agents)\n",
    "planning_router = AgentRouter(planning_team)\n",
    "\n",
    "print(\"\\n‚úÖ Planning Team initialized (4 agents)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 3: Planning Team Reviews Results and Plans Next Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üìã PLANNING TEAM REVIEW MEETING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comprehensive review context for Planning Team\n",
    "review_context = f\"\"\"# PLANNING TEAM REVIEW MEETING\n",
    "\n",
    "## üì• Executive Team Execution Results\n",
    "\n",
    "{progress_text}\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Your Task: Review Results and Plan Next Cycle\n",
    "\n",
    "As the Planning Team, analyze the Executive Team's execution results and plan the next research cycle.\n",
    "\n",
    "### 1. **Review Execution Results**\n",
    "\n",
    "**Key Questions:**\n",
    "- Which tasks completed successfully?\n",
    "- Which tasks failed or were blocked? Why?\n",
    "- What outputs and evidence were generated?\n",
    "- Are the results statistically significant and reproducible?\n",
    "\n",
    "**For this cycle:**\n",
    "- Total tasks: {results_data.get('total_tasks', 'N/A')}\n",
    "- Completed: {results_data.get('completed', 'N/A')}\n",
    "- Failed: {results_data.get('failed', 'N/A')}\n",
    "\n",
    "### 2. **Assess Progress Toward Week 1 GO/NO-GO Decision**\n",
    "\n",
    "**Timeline:** Week 1 GO/NO-GO deadline is October 20, 2025\n",
    "**Today:** {datetime.now().strftime('%Y-%m-%d')}\n",
    "\n",
    "**Week 1 Validation Goals:**\n",
    "- Diagnostic tools work on ‚â•3 external models (CLIP, ALIGN, Flamingo)\n",
    "- Statistical evidence collected (p<0.05 threshold)\n",
    "- CLIP diagnostic completed\n",
    "- Results logged to MLflow\n",
    "\n",
    "**Decision Criteria:**\n",
    "- **GO (Field-wide paper):** ‚â•2 models show >80% attention imbalance ‚Üí High-impact paper (72% acceptance)\n",
    "- **PIVOT (Focused study):** Only V2 shows collapse ‚Üí Focused case study (65% acceptance)\n",
    "- **DIAGNOSTIC (Framework):** Tools work on all models ‚Üí Methodology paper (85% acceptance - RECOMMENDED)\n",
    "\n",
    "**Status Assessment:**\n",
    "- Are we on track for Week 1 GO/NO-GO decision?\n",
    "- Do we have sufficient statistical evidence?\n",
    "- Have we tested enough models?\n",
    "- What blockers or risks exist?\n",
    "\n",
    "### 3. **Identify Next Cycle Priorities**\n",
    "\n",
    "Based on execution results:\n",
    "\n",
    "**If HIGH priority tasks completed successfully:**\n",
    "- Move to next phase of validation\n",
    "- Expand to additional models\n",
    "- Begin paper writing\n",
    "\n",
    "**If HIGH priority tasks failed:**\n",
    "- Debug failures and re-run\n",
    "- Adjust experimental approach\n",
    "- Address blockers\n",
    "\n",
    "**If blockers identified (e.g., ALIGN model access):**\n",
    "- Evaluate alternative approaches\n",
    "- Update timeline\n",
    "- Adjust research scope\n",
    "\n",
    "### 4. **Generate New `pending_actions.json` for Next Cycle**\n",
    "\n",
    "Create a detailed action plan with:\n",
    "\n",
    "**Required Format:**\n",
    "```json\n",
    "{{\n",
    "  \"meeting_id\": \"cvpr_planning_cycle2_{{timestamp}}\",\n",
    "  \"generated_at\": \"{{ISO timestamp}}\",\n",
    "  \"context\": \"Week 1 Cycle 2: [Brief description based on Cycle 1 results]\",\n",
    "  \"decisions\": [\n",
    "    {{\n",
    "      \"priority\": \"HIGH\",\n",
    "      \"action\": \"[Specific task based on execution results]\",\n",
    "      \"owner\": \"ops_commander\",\n",
    "      \"rationale\": \"[Why this task is needed based on Cycle 1 results]\",\n",
    "      \"deadline\": \"{{ISO timestamp}}\",\n",
    "      \"acceptance_criteria\": [\n",
    "        \"[Specific, measurable criterion]\"\n",
    "      ],\n",
    "      \"dependencies\": [\"[task_ids if applicable]\"],\n",
    "      \"evidence_paths\": [\"[File paths for verification]\"]\n",
    "    }}\n",
    "  ],\n",
    "  \"acceptance_gates\": {{\n",
    "    \"week1_validation\": {{\n",
    "      \"min_models_tested\": 3,\n",
    "      \"min_models_with_collapse\": 2,\n",
    "      \"statistical_threshold\": \"p<0.05\"\n",
    "    }}\n",
    "  }}\n",
    "}}\n",
    "```\n",
    "\n",
    "**Task Prioritization Guidelines:**\n",
    "- **HIGH:** Critical path items needed for Week 1 GO/NO-GO decision\n",
    "- **MEDIUM:** Important but not blocking the decision\n",
    "- **LOW:** Nice to have, can be deferred\n",
    "\n",
    "**Typical next cycle tasks might include:**\n",
    "- Run diagnostic on additional models (BLIP, Flamingo, LLaVA)\n",
    "- Cross-model statistical comparison\n",
    "- Update paper draft with new experimental results\n",
    "- Address any blockers from previous cycle\n",
    "- Prepare GO/NO-GO decision framework\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ñ Planning Team Roles\n",
    "\n",
    "**Strategic Leader (Claude Opus 4):**\n",
    "- Lead this meeting and synthesize team input\n",
    "- Make final GO/PAUSE/PIVOT decisions\n",
    "- Create the pending_actions.json structure\n",
    "- Ensure timeline alignment\n",
    "\n",
    "**Empirical Validation Lead (Claude Sonnet 4):**\n",
    "- Assess statistical validity of execution results\n",
    "- Verify experimental rigor\n",
    "- Recommend next experiments based on evidence\n",
    "- Validate that acceptance criteria are measurable\n",
    "\n",
    "**Critical Evaluator (GPT-4):**\n",
    "- Challenge claims (is the evidence sufficient?)\n",
    "- Identify methodological risks\n",
    "- Flag reproducibility issues\n",
    "- Question optimistic assumptions\n",
    "\n",
    "**Gemini Research Advisor (Gemini Flash):**\n",
    "- Provide context from literature\n",
    "- Suggest alternative approaches if blocked\n",
    "- Assess feasibility of proposed next steps\n",
    "- Connect findings to broader research landscape\n",
    "\n",
    "---\n",
    "\n",
    "## üì§ Required Output\n",
    "\n",
    "Each agent should provide:\n",
    "\n",
    "1. **Assessment of Cycle 1 Results:**\n",
    "   - What worked?\n",
    "   - What failed?\n",
    "   - What did we learn?\n",
    "   - Statistical validity?\n",
    "\n",
    "2. **Progress Toward Week 1 GO/NO-GO:**\n",
    "   - Are we on track?\n",
    "   - What evidence do we have?\n",
    "   - What gaps remain?\n",
    "   - Risk assessment?\n",
    "\n",
    "3. **Recommended Next Cycle Tasks:**\n",
    "   - What should be HIGH priority?\n",
    "   - What can wait?\n",
    "   - What blockers need addressing?\n",
    "   - Timeline implications?\n",
    "\n",
    "**Strategic Leader will then synthesize all input and generate the final `pending_actions.json`.**\n",
    "\n",
    "---\n",
    "\n",
    "## üö® Critical Thinking Required\n",
    "\n",
    "**Don't just continue blindly:**\n",
    "- If results show attention collapse, verify statistical significance\n",
    "- If results show no collapse, investigate why (is it V2-specific?)\n",
    "- If blockers emerged (like ALIGN access), evaluate alternatives\n",
    "- If we're behind schedule, what can be cut or parallelized?\n",
    "- If we're ahead, what stretch goals can strengthen the paper?\n",
    "\n",
    "**Evidence-based decisions:**\n",
    "- Every priority must be justified by execution results\n",
    "- Every new task must reference what previous cycle showed\n",
    "- Every deadline must account for remaining time to Nov 6 abstract deadline\n",
    "\n",
    "---\n",
    "\n",
    "**Begin your review now. Provide your analysis and recommendations.**\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù Sending review context to Planning Team...\\n\")\n",
    "\n",
    "# Collect responses from all Planning Team agents\n",
    "planning_responses = {}\n",
    "\n",
    "message = Message(\n",
    "    sender=\"cycle_coordinator\",\n",
    "    recipients=list(planning_team_agents.keys()),\n",
    "    content=review_context,\n",
    "    message_type=\"planning_review\"\n",
    ")\n",
    "\n",
    "print(\"ü§ñ Planning Team agents reviewing results...\\n\")\n",
    "\n",
    "responses = planning_router.route_message(message)\n",
    "\n",
    "# Display each agent's response\n",
    "for agent_name, response in responses.items():\n",
    "    planning_responses[agent_name] = response\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìù {planning_config[agent_name]['name']} Response\")\n",
    "    print(\"=\"*80)\n",
    "    print(response)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"‚úÖ All Planning Team agents have provided their analysis\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 4: Strategic Leader Generates Next Cycle Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üéØ STRATEGIC LEADER: GENERATE NEXT CYCLE TASKS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Strategic Leader synthesizes all input and creates pending_actions.json\n",
    "synthesis_prompt = f\"\"\"# STRATEGIC LEADER: SYNTHESIZE AND GENERATE NEXT CYCLE PLAN\n",
    "\n",
    "## Team Input Received:\n",
    "\n",
    "### Empirical Validation Lead:\n",
    "{planning_responses.get('empirical_validation', 'No response')}\n",
    "\n",
    "### Critical Evaluator:\n",
    "{planning_responses.get('critical_evaluator', 'No response')}\n",
    "\n",
    "### Gemini Research Advisor:\n",
    "{planning_responses.get('research_advisor', 'No response')}\n",
    "\n",
    "---\n",
    "\n",
    "## Your Task:\n",
    "\n",
    "As Strategic Leader, synthesize all team input and create the final `pending_actions.json` for Cycle 2.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "1. **Incorporate team feedback:**\n",
    "   - Statistical rigor concerns from Empirical Lead\n",
    "   - Risk flags from Critical Evaluator\n",
    "   - Alternative approaches from Research Advisor\n",
    "\n",
    "2. **Create actionable tasks:**\n",
    "   - Based on Cycle 1 execution results\n",
    "   - Prioritized by impact on Week 1 GO/NO-GO decision\n",
    "   - With clear acceptance criteria\n",
    "   - Realistic deadlines\n",
    "\n",
    "3. **Format as valid JSON:**\n",
    "   - Must be parseable JSON (no markdown formatting inside JSON)\n",
    "   - Include meeting_id, generated_at, context, decisions array\n",
    "   - Each decision must have: priority, action, owner, rationale, deadline, acceptance_criteria, evidence_paths\n",
    "\n",
    "**Output ONLY the JSON structure, no additional commentary.**\n",
    "\n",
    "**Example format:**\n",
    "```json\n",
    "{{\n",
    "  \"meeting_id\": \"cvpr_planning_cycle2_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "  \"generated_at\": \"{datetime.now().isoformat()}\",\n",
    "  \"context\": \"Week 1 Cycle 2: [Your strategic summary based on team input]\",\n",
    "  \"decisions\": [\n",
    "    {{\n",
    "      \"priority\": \"HIGH\",\n",
    "      \"action\": \"[Task based on Cycle 1 results]\",\n",
    "      \"owner\": \"ops_commander\",\n",
    "      \"rationale\": \"[Why this task, referencing Cycle 1 findings]\",\n",
    "      \"deadline\": \"{(datetime.now() + timedelta(days=2)).isoformat()}\",\n",
    "      \"acceptance_criteria\": [\n",
    "        \"[Criterion 1]\",\n",
    "        \"[Criterion 2]\"\n",
    "      ],\n",
    "      \"dependencies\": [],\n",
    "      \"evidence_paths\": [\"[Path to verify completion]\"]\n",
    "    }}\n",
    "  ],\n",
    "  \"acceptance_gates\": {{\n",
    "    \"week1_validation\": {{\n",
    "      \"min_models_tested\": 3,\n",
    "      \"min_models_with_collapse\": 2,\n",
    "      \"statistical_threshold\": \"p<0.05\"\n",
    "    }}\n",
    "  }}\n",
    "}}\n",
    "```\n",
    "\n",
    "Generate the complete pending_actions.json now.\n",
    "\"\"\"\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "# Get Strategic Leader to generate final plan\n",
    "strategic_leader = planning_team_agents['strategic_leader']\n",
    "\n",
    "print(\"\\nü§ñ Strategic Leader generating next cycle plan...\\n\")\n",
    "\n",
    "next_cycle_json = strategic_leader.respond(synthesis_prompt)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìã NEXT CYCLE PENDING ACTIONS\")\n",
    "print(\"=\"*80)\n",
    "print(next_cycle_json)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 5: Save New pending_actions.json to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üíæ SAVING NEXT CYCLE PENDING ACTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract JSON from response (in case it's wrapped in markdown)\n",
    "json_match = re.search(r'```json\\s*({.*?})\\s*```', next_cycle_json, re.DOTALL)\n",
    "if json_match:\n",
    "    json_str = json_match.group(1)\n",
    "else:\n",
    "    # Try to find raw JSON\n",
    "    json_match = re.search(r'({\\s*\"meeting_id\".*})', next_cycle_json, re.DOTALL)\n",
    "    if json_match:\n",
    "        json_str = json_match.group(1)\n",
    "    else:\n",
    "        json_str = next_cycle_json\n",
    "\n",
    "try:\n",
    "    # Parse JSON to validate\n",
    "    pending_actions = json.loads(json_str)\n",
    "    \n",
    "    # Save to handoff directory\n",
    "    output_file = Path(MULTI_AGENT_ROOT) / 'reports/handoff/pending_actions.json'\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(pending_actions, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n‚úÖ New pending_actions.json saved\")\n",
    "    print(f\"   File: {output_file}\")\n",
    "    print(f\"   Meeting ID: {pending_actions.get('meeting_id', 'N/A')}\")\n",
    "    print(f\"   Context: {pending_actions.get('context', 'N/A')}\")\n",
    "    print(f\"   Total tasks: {len(pending_actions.get('decisions', []))}\")\n",
    "    \n",
    "    # Count by priority\n",
    "    decisions = pending_actions.get('decisions', [])\n",
    "    high = len([d for d in decisions if d.get('priority') == 'HIGH'])\n",
    "    medium = len([d for d in decisions if d.get('priority') == 'MEDIUM'])\n",
    "    low = len([d for d in decisions if d.get('priority') == 'LOW'])\n",
    "    \n",
    "    print(f\"\\nüìä Task Breakdown:\")\n",
    "    print(f\"   ‚≠ê HIGH: {high}\")\n",
    "    print(f\"   üü† MEDIUM: {medium}\")\n",
    "    print(f\"   üîµ LOW: {low}\")\n",
    "    \n",
    "    # Also save timestamped backup\n",
    "    backup_dir = Path(MULTI_AGENT_ROOT) / 'reports/planning/pending_actions_history'\n",
    "    backup_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    backup_file = backup_dir / f'pending_actions_{timestamp}.json'\n",
    "    \n",
    "    with open(backup_file, 'w') as f:\n",
    "        json.dump(pending_actions, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Backup saved: {backup_file.name}\")\n",
    "    \n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"\\n‚ùå Error: Could not parse JSON from Strategic Leader response\")\n",
    "    print(f\"   Error: {e}\")\n",
    "    print(f\"\\nüìÑ Raw response:\")\n",
    "    print(next_cycle_json)\n",
    "    print(f\"\\n‚ö†Ô∏è You may need to manually create pending_actions.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: Planning Team Review Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"=\"*80)\n",
    "print(\"‚úÖ PLANNING TEAM REVIEW MEETING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìã Meeting Summary:\")\n",
    "print(f\"   ‚úÖ Reviewed Cycle 1 execution results\")\n",
    "print(f\"   ‚úÖ All 4 Planning Team agents provided analysis\")\n",
    "print(f\"   ‚úÖ Strategic Leader synthesized input\")\n",
    "print(f\"   ‚úÖ New pending_actions.json generated for Cycle 2\")\n",
    "\n",
    "print(\"\\nüìÇ Output Files:\")\n",
    "print(f\"   üìÑ reports/handoff/pending_actions.json (new cycle tasks)\")\n",
    "print(f\"   üìÑ reports/planning/pending_actions_history/pending_actions_{timestamp}.json (backup)\")\n",
    "\n",
    "print(\"\\nüîÑ Next Steps:\")\n",
    "print(f\"   1. Review the new pending_actions.json\")\n",
    "print(f\"   2. Run Executive Team execution cycle (Colab notebook)\")\n",
    "print(f\"   3. Execute Cycle 2 tasks\")\n",
    "print(f\"   4. Return here for next Planning Team review\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ READY FOR CYCLE 2 EXECUTION\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
