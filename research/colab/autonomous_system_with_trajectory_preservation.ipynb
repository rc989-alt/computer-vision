{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100",
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Autonomous System with Trajectory Preservation\n",
    "\n",
    "**Version:** 3.0 - Enhanced with Auto-Sync & Meeting Trajectories  \n",
    "**GPU:** A100 (40GB) recommended  \n",
    "**Purpose:** Deploy autonomous system with complete meeting history preservation  \n",
    "\n",
    "---\n",
    "\n",
    "## ✨ New Features\n",
    "\n",
    "1. **🔄 Real-time Drive Sync** - Reports saved directly to Google Drive during execution\n",
    "2. **📊 Trajectory Preservation** - Complete meeting conversation history preserved\n",
    "3. **👁️ Live Monitoring** - Real-time dashboard showing meeting progress\n",
    "4. **💾 Crash Recovery** - Even if Colab disconnects, all data is safe on Drive\n",
    "5. **📈 Progress Tracking** - Visual timeline of system evolution\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 What This Solves\n",
    "\n",
    "**Problem:** Meeting artifacts lost when Colab disconnects (like your Oct 13 meeting)\n",
    "\n",
    "**Solution:**\n",
    "- Every meeting round → Instant save to Drive\n",
    "- Trajectory file shows complete conversation flow\n",
    "- Monitor dashboard streams live updates\n",
    "- No data loss even on crash\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check GPU\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv\n",
    "\n",
    "import torch\n",
    "print(f\"\\n✅ PyTorch: {torch.__version__}\")\n",
    "print(f\"✅ CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✅ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"✅ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Authenticate & Mount Drive\n",
    "from google.colab import auth, drive\n",
    "import os\n",
    "\n",
    "print(\"🔐 Authenticating...\")\n",
    "auth.authenticate_user()\n",
    "print(\"✅ Authenticated\")\n",
    "\n",
    "print(\"\\n💾 Mounting Google Drive...\")\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "print(\"✅ Drive mounted\")\n",
    "\n",
    "# Verify mount\n",
    "if os.path.exists('/content/drive/MyDrive'):\n",
    "    print(\"✅ Drive access confirmed\")\n",
    "else:\n",
    "    raise Exception(\"❌ Drive mount failed\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install -q anthropic openai google-generativeai pyyaml tqdm pandas numpy\n",
    "\n",
    "print(\"✅ Packages installed\")\n",
    "\n",
    "import anthropic\n",
    "import openai\n",
    "import yaml\n",
    "\n",
    "print(f\"\\n📦 Versions:\")\n",
    "print(f\"   anthropic: {anthropic.__version__}\")\n",
    "print(f\"   openai: {openai.__version__}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🗂️ Step 3: Configure Paths with Auto-Sync"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Google Drive paths (where permanent storage lives)\n",
    "DRIVE_BASE = Path(\"/content/drive/MyDrive\")\n",
    "DRIVE_PROJECT = DRIVE_BASE / \"cv_multimodal/project/computer-vision-clean\"\n",
    "\n",
    "# Session-specific directory for this run\n",
    "SESSION_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "DRIVE_SESSION = DRIVE_PROJECT / f\"sessions/session_{SESSION_ID}\"\n",
    "DRIVE_SESSION.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Real-time report directories on Drive (auto-synced)\n",
    "DRIVE_REPORTS = DRIVE_PROJECT / \"multi-agent/reports\"\n",
    "DRIVE_REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Trajectory preservation on Drive\n",
    "DRIVE_TRAJECTORIES = DRIVE_SESSION / \"trajectories\"\n",
    "DRIVE_TRAJECTORIES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Local Colab temp workspace\n",
    "PROJECT_ROOT = Path(\"/content/cv_project\")\n",
    "PROJECT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"📁 Path Configuration:\")\n",
    "print(f\"   Drive Project: {DRIVE_PROJECT}\")\n",
    "print(f\"   Session: {DRIVE_SESSION}\")\n",
    "print(f\"   Reports (live): {DRIVE_REPORTS}\")\n",
    "print(f\"   Trajectories: {DRIVE_TRAJECTORIES}\")\n",
    "print(f\"   Local Temp: {PROJECT_ROOT}\")\n",
    "print(f\"\\n✅ Session ID: {SESSION_ID}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Verify required files exist\n",
    "print(\"🔍 Verifying project files...\\n\")\n",
    "\n",
    "required_files = [\n",
    "    \"multi-agent/autonomous_coordinator.py\",\n",
    "    \"multi-agent/configs/autonomous_coordination.yaml\",\n",
    "    \"multi-agent/tools/progress_sync_hook.py\",\n",
    "]\n",
    "\n",
    "all_exist = True\n",
    "for file in required_files:\n",
    "    file_path = DRIVE_PROJECT / file\n",
    "    if file_path.exists():\n",
    "        size = file_path.stat().st_size / 1024\n",
    "        print(f\"✅ {file} ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"❌ {file} - MISSING\")\n",
    "        all_exist = False\n",
    "\n",
    "if all_exist:\n",
    "    print(\"\\n✅ All files present\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Missing required files. Check Drive path.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔐 Step 4: Load API Keys"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load API keys from .env file\n",
    "import os\n",
    "\n",
    "env_locations = [\n",
    "    DRIVE_PROJECT / \".env\",\n",
    "    DRIVE_PROJECT / \"research/api_keys.env\",\n",
    "]\n",
    "\n",
    "env_file = None\n",
    "for location in env_locations:\n",
    "    if location.exists():\n",
    "        env_file = location\n",
    "        break\n",
    "\n",
    "if env_file:\n",
    "    print(f\"🔑 Loading from: {env_file.name}\\n\")\n",
    "    with open(env_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith('#') and '=' in line:\n",
    "                key, value = line.split('=', 1)\n",
    "                os.environ[key.strip()] = value.strip()\n",
    "                print(f\"✅ {key.strip()} loaded\")\n",
    "    print(\"\\n✅ API keys loaded\")\n",
    "else:\n",
    "    print(\"⚠️ No .env file found. Enter keys manually:\\n\")\n",
    "    anthropic_key = input(\"ANTHROPIC_API_KEY: \").strip()\n",
    "    openai_key = input(\"OPENAI_API_KEY: \").strip()\n",
    "    google_key = input(\"GOOGLE_API_KEY: \").strip()\n",
    "    \n",
    "    if anthropic_key:\n",
    "        os.environ['ANTHROPIC_API_KEY'] = anthropic_key\n",
    "    if openai_key:\n",
    "        os.environ['OPENAI_API_KEY'] = openai_key\n",
    "    if google_key:\n",
    "        os.environ['GOOGLE_API_KEY'] = google_key\n",
    "    print(\"✅ Keys set manually\")\n",
    "\n",
    "print(\"\\n🔐 Status:\")\n",
    "print(f\"   ANTHROPIC: {'✅' if os.getenv('ANTHROPIC_API_KEY') else '❌'}\")\n",
    "print(f\"   OPENAI: {'✅' if os.getenv('OPENAI_API_KEY') else '❌'}\")\n",
    "print(f\"   GOOGLE: {'✅' if os.getenv('GOOGLE_API_KEY') else '⚠️ Optional'}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📤 Step 5: Copy Project Files"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import shutil\nimport os\n\nprint(\"📦 Copying project to local workspace...\\n\")\n\nif PROJECT_ROOT.exists():\n    shutil.rmtree(PROJECT_ROOT)\n\n# Smart copy that skips Google Docs files\ndef ignore_gdocs(dir, files):\n    \"\"\"Ignore Google Docs files (.gdoc, .gsheet, .gslides)\"\"\"\n    return [f for f in files if f.endswith(('.gdoc', '.gsheet', '.gslides'))]\n\ntry:\n    shutil.copytree(DRIVE_PROJECT, PROJECT_ROOT, ignore=ignore_gdocs)\n    print(f\"✅ Copied to {PROJECT_ROOT}\")\nexcept Exception as e:\n    print(f\"⚠️ Copy warning: {e}\")\n    print(\"Retrying with dirs_exist_ok=True...\")\n    shutil.copytree(DRIVE_PROJECT, PROJECT_ROOT, ignore=ignore_gdocs, dirs_exist_ok=True)\n    print(f\"✅ Copied to {PROJECT_ROOT}\")\n\n# List key files\nprint(\"\\n📁 Key files copied:\")\npy_files = list(PROJECT_ROOT.glob(\"multi-agent/**/*.py\"))\nfor file in sorted(py_files)[:10]:\n    size = file.stat().st_size / 1024\n    print(f\"   {file.relative_to(PROJECT_ROOT)} ({size:.1f} KB)\")\n\nif len(py_files) > 10:\n    print(f\"   ... and {len(py_files) - 10} more files\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔄 Step 6: Create Auto-Sync System"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "import threading\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class TrajectoryPreserver:\n",
    "    \"\"\"Preserves complete meeting trajectories with auto-sync to Drive\"\"\"\n",
    "    \n",
    "    def __init__(self, local_reports_dir: Path, drive_reports_dir: Path, drive_trajectory_dir: Path):\n",
    "        self.local_reports = Path(local_reports_dir)\n",
    "        self.drive_reports = Path(drive_reports_dir)\n",
    "        self.drive_trajectories = Path(drive_trajectory_dir)\n",
    "        \n",
    "        # Create directories\n",
    "        self.local_reports.mkdir(parents=True, exist_ok=True)\n",
    "        self.drive_reports.mkdir(parents=True, exist_ok=True)\n",
    "        self.drive_trajectories.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Tracking\n",
    "        self.synced_files = set()\n",
    "        self.trajectory_log = []\n",
    "        self.running = False\n",
    "        self.sync_thread = None\n",
    "        \n",
    "        print(\"✅ Trajectory Preserver initialized\")\n",
    "        print(f\"   Local: {self.local_reports}\")\n",
    "        print(f\"   Drive Reports: {self.drive_reports}\")\n",
    "        print(f\"   Drive Trajectories: {self.drive_trajectories}\")\n",
    "    \n",
    "    def start_auto_sync(self, interval_seconds: int = 10):\n",
    "        \"\"\"Start background sync thread\"\"\"\n",
    "        if self.running:\n",
    "            print(\"⚠️ Auto-sync already running\")\n",
    "            return\n",
    "        \n",
    "        self.running = True\n",
    "        self.sync_thread = threading.Thread(\n",
    "            target=self._sync_loop,\n",
    "            args=(interval_seconds,),\n",
    "            daemon=True\n",
    "        )\n",
    "        self.sync_thread.start()\n",
    "        print(f\"✅ Auto-sync started (every {interval_seconds}s)\")\n",
    "    \n",
    "    def stop_auto_sync(self):\n",
    "        \"\"\"Stop background sync\"\"\"\n",
    "        self.running = False\n",
    "        if self.sync_thread:\n",
    "            self.sync_thread.join(timeout=5)\n",
    "        print(\"✅ Auto-sync stopped\")\n",
    "    \n",
    "    def _sync_loop(self, interval: int):\n",
    "        \"\"\"Background sync loop\"\"\"\n",
    "        while self.running:\n",
    "            try:\n",
    "                self.sync_now()\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Sync error: {e}\")\n",
    "            time.sleep(interval)\n",
    "    \n",
    "    def sync_now(self, verbose: bool = False) -> Dict[str, int]:\n",
    "        \"\"\"Immediate sync of all new files\"\"\"\n",
    "        stats = {'new': 0, 'updated': 0, 'skipped': 0}\n",
    "        \n",
    "        if not self.local_reports.exists():\n",
    "            return stats\n",
    "        \n",
    "        # Find all report files\n",
    "        report_files = list(self.local_reports.glob(\"**/*.md\")) + \\\n",
    "                      list(self.local_reports.glob(\"**/*.json\"))\n",
    "        \n",
    "        for local_file in report_files:\n",
    "            rel_path = local_file.relative_to(self.local_reports)\n",
    "            drive_file = self.drive_reports / rel_path\n",
    "            \n",
    "            # Check if new or modified\n",
    "            file_id = str(rel_path)\n",
    "            \n",
    "            if file_id not in self.synced_files:\n",
    "                # New file\n",
    "                drive_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.copy2(local_file, drive_file)\n",
    "                self.synced_files.add(file_id)\n",
    "                stats['new'] += 1\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"   📤 New: {rel_path}\")\n",
    "                \n",
    "                # Log to trajectory\n",
    "                self._log_artifact(local_file, 'created')\n",
    "            else:\n",
    "                # Check if modified\n",
    "                if drive_file.exists():\n",
    "                    local_mtime = local_file.stat().st_mtime\n",
    "                    drive_mtime = drive_file.stat().st_mtime\n",
    "                    \n",
    "                    if local_mtime > drive_mtime:\n",
    "                        shutil.copy2(local_file, drive_file)\n",
    "                        stats['updated'] += 1\n",
    "                        if verbose:\n",
    "                            print(f\"   🔄 Updated: {rel_path}\")\n",
    "                        self._log_artifact(local_file, 'updated')\n",
    "                    else:\n",
    "                        stats['skipped'] += 1\n",
    "        \n",
    "        # Save trajectory log\n",
    "        if stats['new'] > 0 or stats['updated'] > 0:\n",
    "            self._save_trajectory()\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def _log_artifact(self, file_path: Path, action: str):\n",
    "        \"\"\"Log artifact to trajectory\"\"\"\n",
    "        entry = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'file': file_path.name,\n",
    "            'action': action,\n",
    "            'size': file_path.stat().st_size\n",
    "        }\n",
    "        self.trajectory_log.append(entry)\n",
    "    \n",
    "    def _save_trajectory(self):\n",
    "        \"\"\"Save trajectory log to Drive\"\"\"\n",
    "        trajectory_file = self.drive_trajectories / \"trajectory_log.json\"\n",
    "        \n",
    "        with open(trajectory_file, 'w') as f:\n",
    "            json.dump({\n",
    "                'session_id': SESSION_ID,\n",
    "                'start_time': self.trajectory_log[0]['timestamp'] if self.trajectory_log else None,\n",
    "                'last_update': datetime.now().isoformat(),\n",
    "                'total_artifacts': len(self.trajectory_log),\n",
    "                'artifacts': self.trajectory_log\n",
    "            }, f, indent=2)\n",
    "    \n",
    "    def create_trajectory_summary(self) -> str:\n",
    "        \"\"\"Create human-readable trajectory summary\"\"\"\n",
    "        if not self.trajectory_log:\n",
    "            return \"No trajectory data yet\"\n",
    "        \n",
    "        lines = [\n",
    "            \"# Meeting Trajectory Summary\",\n",
    "            f\"\\n**Session**: {SESSION_ID}\",\n",
    "            f\"**Start**: {self.trajectory_log[0]['timestamp']}\",\n",
    "            f\"**Last Update**: {datetime.now().isoformat()}\",\n",
    "            f\"**Artifacts**: {len(self.trajectory_log)}\",\n",
    "            \"\\n## Timeline\\n\"\n",
    "        ]\n",
    "        \n",
    "        for entry in self.trajectory_log:\n",
    "            time_str = entry['timestamp'].split('T')[1][:8]\n",
    "            lines.append(f\"- `{time_str}` - {entry['action'].upper()}: {entry['file']}\")\n",
    "        \n",
    "        summary = \"\\n\".join(lines)\n",
    "        \n",
    "        # Save to Drive\n",
    "        summary_file = self.drive_trajectories / \"trajectory_summary.md\"\n",
    "        with open(summary_file, 'w') as f:\n",
    "            f.write(summary)\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Initialize preserver\n",
    "preserver = TrajectoryPreserver(\n",
    "    local_reports_dir=PROJECT_ROOT / \"multi-agent/reports\",\n",
    "    drive_reports_dir=DRIVE_REPORTS,\n",
    "    drive_trajectory_dir=DRIVE_TRAJECTORIES\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Ready for trajectory preservation\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Step 7: Start Autonomous System"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"multi-agent\"))\n",
    "\n",
    "from autonomous_coordinator import AutonomousCoordinator\n",
    "\n",
    "print(\"🚀 Initializing Autonomous Coordinator...\\n\")\n",
    "\n",
    "coordinator = AutonomousCoordinator(\n",
    "    config_path=PROJECT_ROOT / \"multi-agent/configs/autonomous_coordination.yaml\",\n",
    "    project_root=PROJECT_ROOT\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Coordinator ready\")\n",
    "print(f\"   Agents: {len(coordinator.agents)}\")\n",
    "print(f\"   Channels: {len(coordinator.channels._subscribers)}\")\n",
    "print(f\"   Triggers: {len(coordinator.triggers._active_triggers)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Start auto-sync FIRST\n",
    "print(\"🔄 Starting auto-sync system...\\n\")\n",
    "preserver.start_auto_sync(interval_seconds=10)\n",
    "print(\"✅ Auto-sync active (every 10 seconds)\")\n",
    "\n",
    "# Start coordinator\n",
    "print(\"\\n💓 Starting autonomous system...\\n\")\n",
    "coordinator.start()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ AUTONOMOUS SYSTEM RUNNING\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n📊 Features active:\")\n",
    "print(\"   ✅ Hourly heartbeat cycles\")\n",
    "print(\"   ✅ Auto-sync to Drive (10s)\")\n",
    "print(\"   ✅ Trajectory preservation\")\n",
    "print(\"   ✅ Crash recovery\")\n",
    "print(\"\\n💡 All meeting artifacts saved to:\")\n",
    "print(f\"   {DRIVE_REPORTS}\")\n",
    "print(f\"\\n📊 Trajectory log:\")\n",
    "print(f\"   {DRIVE_TRAJECTORIES}\")\n",
    "print(f\"\\n📁 Session directory:\")\n",
    "print(f\"   {DRIVE_SESSION}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👁️ Step 8: Live Monitoring Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from IPython.display import clear_output, display, HTML\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def get_latest_reports():\n",
    "    \"\"\"Get latest report files from Drive\"\"\"\n",
    "    reports = {\n",
    "        'transcripts': list(DRIVE_REPORTS.glob(\"transcript_*.md\")),\n",
    "        'summaries': list(DRIVE_REPORTS.glob(\"summary_*.md\")),\n",
    "        'actions': list(DRIVE_REPORTS.glob(\"actions_*.json\"))\n",
    "    }\n",
    "    \n",
    "    # Sort by modification time\n",
    "    for key in reports:\n",
    "        reports[key] = sorted(reports[key], key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "    \n",
    "    return reports\n",
    "\n",
    "def display_dashboard():\n",
    "    \"\"\"Display live monitoring dashboard\"\"\"\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"👁️  LIVE MONITORING DASHBOARD\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"🕐 {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"📁 Session: {SESSION_ID}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Sync status\n",
    "    stats = preserver.sync_now(verbose=False)\n",
    "    print(f\"\\n🔄 Auto-Sync Status:\")\n",
    "    print(f\"   New files: {stats['new']}\")\n",
    "    print(f\"   Updated: {stats['updated']}\")\n",
    "    print(f\"   Total synced: {len(preserver.synced_files)}\")\n",
    "    \n",
    "    # Latest reports\n",
    "    reports = get_latest_reports()\n",
    "    print(f\"\\n📊 Latest Reports:\")\n",
    "    \n",
    "    if reports['transcripts']:\n",
    "        latest = reports['transcripts'][0]\n",
    "        mtime = datetime.fromtimestamp(latest.stat().st_mtime)\n",
    "        age = (datetime.now() - mtime).total_seconds() / 60\n",
    "        print(f\"   📝 Transcript: {latest.name}\")\n",
    "        print(f\"      Updated: {age:.1f} min ago\")\n",
    "    else:\n",
    "        print(f\"   📝 Transcript: None yet\")\n",
    "    \n",
    "    if reports['summaries']:\n",
    "        latest = reports['summaries'][0]\n",
    "        mtime = datetime.fromtimestamp(latest.stat().st_mtime)\n",
    "        age = (datetime.now() - mtime).total_seconds() / 60\n",
    "        print(f\"   📄 Summary: {latest.name}\")\n",
    "        print(f\"      Updated: {age:.1f} min ago\")\n",
    "    else:\n",
    "        print(f\"   📄 Summary: None yet\")\n",
    "    \n",
    "    if reports['actions']:\n",
    "        latest = reports['actions'][0]\n",
    "        try:\n",
    "            with open(latest, 'r') as f:\n",
    "                actions = json.load(f)\n",
    "            print(f\"   ⚡ Actions: {len(actions)} items\")\n",
    "        except:\n",
    "            print(f\"   ⚡ Actions: {latest.name}\")\n",
    "    else:\n",
    "        print(f\"   ⚡ Actions: None yet\")\n",
    "    \n",
    "    # Trajectory\n",
    "    print(f\"\\n📈 Trajectory:\")\n",
    "    print(f\"   Total artifacts: {len(preserver.trajectory_log)}\")\n",
    "    if preserver.trajectory_log:\n",
    "        first = preserver.trajectory_log[0]['timestamp']\n",
    "        last = preserver.trajectory_log[-1]['timestamp']\n",
    "        print(f\"   First: {first.split('T')[1][:8]}\")\n",
    "        print(f\"   Latest: {last.split('T')[1][:8]}\")\n",
    "    \n",
    "    # System state\n",
    "    state_file = PROJECT_ROOT / \"multi-agent/state/deployment_state.json\"\n",
    "    if state_file.exists():\n",
    "        with open(state_file, 'r') as f:\n",
    "            state = json.load(f)\n",
    "        print(f\"\\n🚀 Deployment:\")\n",
    "        print(f\"   Version: {state.get('current_version', 'N/A')}\")\n",
    "        print(f\"   Stage: {state.get('stage', 'N/A')}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🔄 Refreshing in 30 seconds...\")\n",
    "    print(\"⏹️  Press Stop button to exit\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# Run dashboard\n",
    "print(\"👁️ Starting live dashboard (Press Stop to exit)\\n\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        display_dashboard()\n",
    "        time.sleep(30)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n⏹️ Dashboard stopped\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Step 9: View Trajectory Summary"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Generate and display trajectory summary\n",
    "summary = preserver.create_trajectory_summary()\n",
    "print(summary)\n",
    "\n",
    "print(f\"\\n✅ Trajectory summary saved to:\")\n",
    "print(f\"   {DRIVE_TRAJECTORIES / 'trajectory_summary.md'}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📥 Step 10: View Latest Meeting Transcript"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Read and display latest transcript from Drive\n",
    "transcripts = sorted(DRIVE_REPORTS.glob(\"transcript_*.md\"), key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "\n",
    "if transcripts:\n",
    "    latest = transcripts[0]\n",
    "    print(f\"📝 Latest Transcript: {latest.name}\\n\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    with open(latest, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Show first 2000 characters\n",
    "    if len(content) > 2000:\n",
    "        print(content[:2000])\n",
    "        print(\"\\n... (truncated)\")\n",
    "        print(f\"\\n📄 Full transcript: {latest}\")\n",
    "    else:\n",
    "        print(content)\n",
    "else:\n",
    "    print(\"⏳ No transcripts yet. Wait for first meeting to complete.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛑 Step 11: Stop System & Final Sync"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"🛑 Stopping autonomous system...\\n\")\n",
    "\n",
    "# Stop coordinator\n",
    "coordinator.stop()\n",
    "print(\"✅ Coordinator stopped\")\n",
    "\n",
    "# Final sync\n",
    "print(\"\\n🔄 Final sync to Drive...\")\n",
    "stats = preserver.sync_now(verbose=True)\n",
    "print(f\"\\n✅ Final sync complete:\")\n",
    "print(f\"   New: {stats['new']}\")\n",
    "print(f\"   Updated: {stats['updated']}\")\n",
    "\n",
    "# Stop auto-sync\n",
    "preserver.stop_auto_sync()\n",
    "\n",
    "# Generate final trajectory\n",
    "print(\"\\n📊 Generating final trajectory summary...\")\n",
    "summary = preserver.create_trajectory_summary()\n",
    "print(\"✅ Trajectory summary saved\")\n",
    "\n",
    "# Create session summary\n",
    "session_summary = {\n",
    "    'session_id': SESSION_ID,\n",
    "    'start_time': preserver.trajectory_log[0]['timestamp'] if preserver.trajectory_log else None,\n",
    "    'end_time': datetime.now().isoformat(),\n",
    "    'total_artifacts': len(preserver.trajectory_log),\n",
    "    'total_synced': len(preserver.synced_files),\n",
    "    'location': str(DRIVE_SESSION)\n",
    "}\n",
    "\n",
    "summary_file = DRIVE_SESSION / \"session_summary.json\"\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(session_summary, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ SYSTEM STOPPED - ALL DATA SAVED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n📁 All files saved to:\")\n",
    "print(f\"   Reports: {DRIVE_REPORTS}\")\n",
    "print(f\"   Trajectory: {DRIVE_TRAJECTORIES}\")\n",
    "print(f\"   Session: {DRIVE_SESSION}\")\n",
    "print(f\"\\n✅ Safe to disconnect from Colab\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Utility: Manual Sync"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Run this cell anytime to manually sync\n",
    "print(\"🔄 Manual sync...\\n\")\n",
    "stats = preserver.sync_now(verbose=True)\n",
    "print(f\"\\n✅ Sync complete:\")\n",
    "print(f\"   New: {stats['new']}\")\n",
    "print(f\"   Updated: {stats['updated']}\")\n",
    "print(f\"   Skipped: {stats['skipped']}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Utility: List All Reports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# List all reports on Drive\n",
    "print(\"📋 All Reports on Google Drive:\\n\")\n",
    "\n",
    "for file in sorted(DRIVE_REPORTS.glob(\"**/*\"), key=lambda x: x.stat().st_mtime, reverse=True):\n",
    "    if file.is_file():\n",
    "        size = file.stat().st_size / 1024\n",
    "        mtime = datetime.fromtimestamp(file.stat().st_mtime)\n",
    "        rel_path = file.relative_to(DRIVE_REPORTS)\n",
    "        print(f\"   {rel_path} ({size:.1f} KB) - {mtime.strftime('%H:%M:%S')}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📚 Documentation\n",
    "\n",
    "### What Gets Saved\n",
    "\n",
    "**Real-time Reports (auto-synced every 10s):**\n",
    "- `transcript_*.md` - Complete meeting conversation\n",
    "- `summary_*.md` - Meeting summary and decisions\n",
    "- `actions_*.json` - Action items for execution team\n",
    "- `responses_*.json` - Individual agent responses\n",
    "- `integrity_*.json` - Integrity checks\n",
    "\n",
    "**Trajectory Log:**\n",
    "- `trajectory_log.json` - Complete artifact timeline\n",
    "- `trajectory_summary.md` - Human-readable summary\n",
    "\n",
    "**Session Data:**\n",
    "- `session_summary.json` - Session metadata\n",
    "- `state/` - System state snapshots\n",
    "\n",
    "### Recovery from Disconnect\n",
    "\n",
    "If Colab disconnects:\n",
    "1. All reports are already on Drive (auto-synced every 10s)\n",
    "2. Trajectory log preserved in `sessions/session_*/trajectories/`\n",
    "3. Latest state in `multi-agent/reports/`\n",
    "4. Re-run notebook to continue from last state\n",
    "\n",
    "### Monitoring\n",
    "\n",
    "Use **Step 8** (Live Dashboard) to monitor:\n",
    "- Real-time sync status\n",
    "- Latest reports and timestamps\n",
    "- Trajectory growth\n",
    "- System deployment state\n",
    "\n",
    "---\n",
    "\n",
    "**Version:** 3.0  \n",
    "**Features:** Auto-Sync ✅ | Trajectories ✅ | Monitoring ✅ | Crash Recovery ✅\n"
   ]
  }
 ]
}