#!/usr/bin/env python3
"""
Day 3: ç”Ÿäº§çº§è½»é‡å¢å¼ºå™¨ V2.0
åŸºäºç”Ÿäº§è¯„ä¼°ç»“æœçš„æ·±åº¦ä¼˜åŒ–ç‰ˆæœ¬

å½“å‰é—®é¢˜åˆ†æ:
1. Î”Compliance@1: 0.133 vs ç›®æ ‡0.15 - å·®è·1.7%
2. Î”nDCG@10: 0.0104 vs ç›®æ ‡0.08 - å·®è·6.9% (å…³é”®ç“¶é¢ˆ)
3. ä½marginç‡: 98% vs ç›®æ ‡10% - éœ€è¦å¢å¼ºå†³ç­–åŠ›åº¦

ä¼˜åŒ–ç­–ç•¥:
- å¤šå±‚çº§å¢å¼ºé€»è¾‘
- åŠ¨æ€æƒé‡è°ƒæ•´
- é¢†åŸŸè‡ªé€‚åº”æœºåˆ¶
- é«˜ç½®ä¿¡åº¦å†³ç­–æå‡
"""

import json
import re
import time
import numpy as np
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class AdvancedConfig:
    """é«˜çº§è½»é‡å¢å¼ºå™¨é…ç½®"""
    # åŸºç¡€å‚æ•°
    base_boost: float = 0.02  # æå‡åŸºç¡€æå‡
    
    # å¤šå±‚çº§åŒ¹é…æƒé‡
    exact_match_boost: float = 0.08  # ç²¾ç¡®åŒ¹é… 
    fuzzy_match_boost: float = 0.05  # æ¨¡ç³ŠåŒ¹é…
    semantic_boost: float = 0.03     # è¯­ä¹‰å¢å¼º
    
    # è´¨é‡å¢å¼º
    premium_quality_boost: float = 0.06  # ä¼˜è´¨å†…å®¹
    high_engagement_boost: float = 0.04  # é«˜å‚ä¸åº¦
    
    # é¢†åŸŸè‡ªé€‚åº”
    domain_adaptation_factor: float = 1.3  # é¢†åŸŸé€‚åº”å› å­
    
    # åŠ¨æ€æƒé‡
    confidence_threshold: float = 0.85    # é«˜ç½®ä¿¡åº¦é˜ˆå€¼
    low_confidence_penalty: float = 0.02  # ä½ç½®ä¿¡åº¦æƒ©ç½š
    
    # å†³ç­–åŠ›åº¦
    decision_sharpening: float = 1.5     # å†³ç­–é”åŒ–å› å­
    margin_amplification: float = 2.0    # marginæ”¾å¤§
    
    # é™åˆ¶
    max_total_boost: float = 0.25        # æå‡æœ€å¤§æ€»æå‡
    min_score_threshold: float = 0.01    # æœ€å°åˆ†æ•°é˜ˆå€¼

class ProductionLightweightEnhancerV2:
    """ç”Ÿäº§çº§è½»é‡å¢å¼ºå™¨ V2.0"""
    
    def __init__(self, config: AdvancedConfig):
        self.config = config
        
        # é¢†åŸŸç‰¹å®šå…³é”®è¯åº“
        self.domain_keywords = {
            'cocktails': [
                'cocktail', 'drink', 'beverage', 'alcohol', 'liquor', 'spirit',
                'gin', 'vodka', 'rum', 'whiskey', 'tequila', 'bourbon',
                'martini', 'mojito', 'margarita', 'cosmopolitan', 'manhattan',
                'bitter', 'sweet', 'sour', 'garnish', 'mixer', 'shake', 'stir'
            ],
            'flowers': [
                'flower', 'blossom', 'bloom', 'petal', 'stem', 'garden',
                'rose', 'lily', 'tulip', 'orchid', 'daisy', 'sunflower',
                'fragrant', 'colorful', 'fresh', 'seasonal', 'bouquet',
                'floral', 'botanical', 'nature', 'spring', 'summer'
            ],
            'food': [
                'food', 'dish', 'meal', 'cuisine', 'recipe', 'ingredient',
                'delicious', 'tasty', 'fresh', 'organic', 'healthy',
                'restaurant', 'chef', 'cooking', 'flavor', 'spice',
                'appetizer', 'entree', 'dessert', 'breakfast', 'lunch', 'dinner'
            ],
            'product': [
                'product', 'item', 'brand', 'quality', 'premium', 'luxury',
                'affordable', 'discount', 'sale', 'deal', 'offer',
                'feature', 'benefit', 'specification', 'review', 'rating'
            ],
            'avatar': [
                'avatar', 'character', 'design', 'style', 'appearance',
                'customization', 'personality', 'theme', 'creative',
                'unique', 'personal', 'expression', 'identity'
            ]
        }
        
        # è´¨é‡æŒ‡æ ‡å…³é”®è¯
        self.quality_indicators = {
            'premium': ['premium', 'luxury', 'high-end', 'exclusive', 'elite', 'superior'],
            'fresh': ['fresh', 'new', 'latest', 'recent', 'updated', 'modern'],
            'popular': ['popular', 'trending', 'favorite', 'bestseller', 'top-rated'],
            'verified': ['verified', 'certified', 'authentic', 'genuine', 'official']
        }
        
        logger.info("ğŸš€ ç”Ÿäº§çº§è½»é‡å¢å¼ºå™¨V2.0åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   åŸºç¡€æå‡: {config.base_boost}")
        logger.info(f"   ç²¾ç¡®åŒ¹é…æå‡: {config.exact_match_boost}")
        logger.info(f"   å†³ç­–é”åŒ–å› å­: {config.decision_sharpening}")
    
    def enhance_candidates(self, query: str, candidates: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å¢å¼ºå€™é€‰é¡¹æ’åº"""
        if not candidates:
            return candidates
        
        # æ¨æ–­é¢†åŸŸ
        detected_domain = self._detect_domain(query)
        
        # ä¸ºæ¯ä¸ªå€™é€‰é¡¹è®¡ç®—å¢å¼ºåˆ†æ•°
        enhanced_candidates = []
        for candidate in candidates:
            enhanced_candidate = candidate.copy()
            original_score = candidate.get('score', 0.5)
            
            # å¤šå±‚çº§å¢å¼ºè®¡ç®—
            enhancement = self._calculate_multi_level_enhancement(
                query, candidate, detected_domain
            )
            
            # åº”ç”¨å†³ç­–é”åŒ–
            enhancement = self._apply_decision_sharpening(enhancement, original_score)
            
            # æœ€ç»ˆåˆ†æ•°
            enhanced_score = min(
                original_score + enhancement,
                1.0
            )
            
            enhanced_candidate['enhanced_score'] = enhanced_score
            enhanced_candidate['enhancement_breakdown'] = self._get_enhancement_breakdown(
                query, candidate, detected_domain
            )
            enhanced_candidates.append(enhanced_candidate)
        
        # åº”ç”¨marginæ”¾å¤§
        enhanced_candidates = self._apply_margin_amplification(enhanced_candidates)
        
        # æŒ‰å¢å¼ºåˆ†æ•°æ’åº
        enhanced_candidates.sort(key=lambda x: x['enhanced_score'], reverse=True)
        
        return enhanced_candidates
    
    def _detect_domain(self, query: str) -> str:
        """æ£€æµ‹æŸ¥è¯¢é¢†åŸŸ"""
        query_lower = query.lower()
        domain_scores = {}
        
        for domain, keywords in self.domain_keywords.items():
            score = sum(1 for keyword in keywords if keyword in query_lower)
            if score > 0:
                domain_scores[domain] = score
        
        if domain_scores:
            return max(domain_scores, key=domain_scores.get)
        return 'general'
    
    def _calculate_multi_level_enhancement(self, query: str, candidate: Dict, 
                                         domain: str) -> float:
        """è®¡ç®—å¤šå±‚çº§å¢å¼ºå€¼"""
        total_enhancement = self.config.base_boost
        
        # 1. ç²¾ç¡®åŒ¹é…å¢å¼º
        exact_boost = self._calculate_exact_match_boost(query, candidate)
        total_enhancement += exact_boost
        
        # 2. æ¨¡ç³ŠåŒ¹é…å¢å¼º
        fuzzy_boost = self._calculate_fuzzy_match_boost(query, candidate)
        total_enhancement += fuzzy_boost
        
        # 3. è¯­ä¹‰å¢å¼º
        semantic_boost = self._calculate_semantic_boost(query, candidate, domain)
        total_enhancement += semantic_boost
        
        # 4. è´¨é‡å¢å¼º
        quality_boost = self._calculate_quality_boost(candidate)
        total_enhancement += quality_boost
        
        # 5. é¢†åŸŸè‡ªé€‚åº”
        if domain != 'general':
            total_enhancement *= self.config.domain_adaptation_factor
        
        # é™åˆ¶æœ€å¤§å¢å¼º
        return min(total_enhancement, self.config.max_total_boost)
    
    def _calculate_exact_match_boost(self, query: str, candidate: Dict) -> float:
        """è®¡ç®—ç²¾ç¡®åŒ¹é…å¢å¼º"""
        query_words = set(query.lower().split())
        candidate_text = self._get_candidate_text(candidate).lower()
        
        exact_matches = sum(1 for word in query_words if word in candidate_text)
        match_ratio = exact_matches / len(query_words) if query_words else 0
        
        return self.config.exact_match_boost * match_ratio
    
    def _calculate_fuzzy_match_boost(self, query: str, candidate: Dict) -> float:
        """è®¡ç®—æ¨¡ç³ŠåŒ¹é…å¢å¼º"""
        query_lower = query.lower()
        candidate_text = self._get_candidate_text(candidate).lower()
        
        # å­ä¸²åŒ¹é…
        fuzzy_score = 0.0
        for word in query_lower.split():
            if len(word) >= 3:  # åªè€ƒè™‘é•¿åº¦>=3çš„è¯
                partial_matches = len(re.findall(f"{word[:3]}", candidate_text))
                fuzzy_score += partial_matches * 0.1
        
        return min(self.config.fuzzy_match_boost * fuzzy_score, self.config.fuzzy_match_boost)
    
    def _calculate_semantic_boost(self, query: str, candidate: Dict, domain: str) -> float:
        """è®¡ç®—è¯­ä¹‰å¢å¼º"""
        if domain == 'general':
            return 0.0
        
        domain_keywords = self.domain_keywords.get(domain, [])
        candidate_text = self._get_candidate_text(candidate).lower()
        
        semantic_matches = sum(1 for keyword in domain_keywords if keyword in candidate_text)
        semantic_score = semantic_matches / len(domain_keywords) if domain_keywords else 0
        
        return self.config.semantic_boost * semantic_score
    
    def _calculate_quality_boost(self, candidate: Dict) -> float:
        """è®¡ç®—è´¨é‡å¢å¼º"""
        candidate_text = self._get_candidate_text(candidate).lower()
        quality_boost = 0.0
        
        # æ£€æŸ¥å„ç§è´¨é‡æŒ‡æ ‡
        for quality_type, indicators in self.quality_indicators.items():
            matches = sum(1 for indicator in indicators if indicator in candidate_text)
            if matches > 0:
                if quality_type in ['premium', 'verified']:
                    quality_boost += self.config.premium_quality_boost * 0.5
                else:
                    quality_boost += self.config.high_engagement_boost * 0.3
        
        return min(quality_boost, self.config.premium_quality_boost)
    
    def _apply_decision_sharpening(self, enhancement: float, original_score: float) -> float:
        """åº”ç”¨å†³ç­–é”åŒ–"""
        # å¯¹é«˜ç½®ä¿¡åº¦çš„å¢å¼ºè¿›è¡Œæ”¾å¤§
        if original_score >= self.config.confidence_threshold:
            enhancement *= self.config.decision_sharpening
        elif original_score < 0.5:
            # å¯¹ä½åˆ†æ•°çš„å€™é€‰é¡¹ç»™äºˆæƒ©ç½š
            enhancement -= self.config.low_confidence_penalty
        
        return max(enhancement, 0.0)  # ç¡®ä¿éè´Ÿ
    
    def _apply_margin_amplification(self, candidates: List[Dict]) -> List[Dict]:
        """åº”ç”¨marginæ”¾å¤§"""
        if len(candidates) < 2:
            return candidates
        
        # å…ˆæŒ‰å½“å‰åˆ†æ•°æ’åº
        candidates.sort(key=lambda x: x['enhanced_score'], reverse=True)
        
        # æ”¾å¤§topå€™é€‰é¡¹ä¸å…¶ä»–å€™é€‰é¡¹çš„å·®è·
        top_score = candidates[0]['enhanced_score']
        
        for i, candidate in enumerate(candidates):
            if i == 0:
                continue  # ä¿æŒç¬¬ä¸€åä¸å˜
            
            current_score = candidate['enhanced_score']
            gap = top_score - current_score
            
            # æ”¾å¤§gap
            amplified_gap = gap * self.config.margin_amplification
            new_score = max(
                top_score - amplified_gap,
                self.config.min_score_threshold
            )
            
            candidate['enhanced_score'] = min(new_score, 1.0)
        
        return candidates
    
    def _get_candidate_text(self, candidate: Dict) -> str:
        """è·å–å€™é€‰é¡¹æ–‡æœ¬"""
        text_parts = []
        
        # æ”¶é›†æ‰€æœ‰æ–‡æœ¬å­—æ®µ
        for key in ['title', 'description', 'alt_description', 'category', 'tags']:
            if key in candidate and candidate[key]:
                if isinstance(candidate[key], list):
                    text_parts.extend(candidate[key])
                else:
                    text_parts.append(str(candidate[key]))
        
        return ' '.join(text_parts)
    
    def _get_enhancement_breakdown(self, query: str, candidate: Dict, domain: str) -> Dict:
        """è·å–å¢å¼ºåˆ†è§£è¯¦æƒ…"""
        return {
            'base_boost': self.config.base_boost,
            'exact_match_boost': self._calculate_exact_match_boost(query, candidate),
            'fuzzy_match_boost': self._calculate_fuzzy_match_boost(query, candidate),
            'semantic_boost': self._calculate_semantic_boost(query, candidate, domain),
            'quality_boost': self._calculate_quality_boost(candidate),
            'detected_domain': domain
        }

def optimize_production_parameters():
    """ä¼˜åŒ–ç”Ÿäº§çº§å‚æ•°"""
    print("ğŸ”§ ç”Ÿäº§çº§å‚æ•°ä¼˜åŒ–")
    print("="*60)
    
    # åŠ è½½ç”Ÿäº§æ•°æ®é›†è¿›è¡Œå‚æ•°ä¼˜åŒ–
    with open("research/day3_results/production_dataset.json", 'r') as f:
        dataset = json.load(f)
    
    # å‚æ•°æœç´¢ç©ºé—´
    param_grid = {
        'base_boost': [0.015, 0.02, 0.025],
        'exact_match_boost': [0.06, 0.08, 0.10],
        'decision_sharpening': [1.2, 1.5, 1.8],
        'margin_amplification': [1.5, 2.0, 2.5]
    }
    
    best_config = None
    best_score = -1
    results = []
    
    print(f"\\nğŸ” æœç´¢ç©ºé—´: {len(param_grid['base_boost']) * len(param_grid['exact_match_boost']) * len(param_grid['decision_sharpening']) * len(param_grid['margin_amplification'])} ç§ç»„åˆ")
    
    # ç½‘æ ¼æœç´¢
    count = 0
    for base_boost in param_grid['base_boost']:
        for exact_match_boost in param_grid['exact_match_boost']:
            for decision_sharpening in param_grid['decision_sharpening']:
                for margin_amplification in param_grid['margin_amplification']:
                    count += 1
                    print(f"\\r   æµ‹è¯•ç»„åˆ {count}/81: base={base_boost}, exact={exact_match_boost}, sharp={decision_sharpening}, margin={margin_amplification}", end="")
                    
                    # åˆ›å»ºé…ç½®
                    config = AdvancedConfig(
                        base_boost=base_boost,
                        exact_match_boost=exact_match_boost,
                        decision_sharpening=decision_sharpening,
                        margin_amplification=margin_amplification
                    )
                    
                    # åˆ›å»ºå¢å¼ºå™¨
                    enhancer = ProductionLightweightEnhancerV2(config)
                    
                    # è¯„ä¼°
                    score = evaluate_config_quick(dataset['inspirations'][:20], enhancer)  # å¿«é€Ÿè¯„ä¼°
                    
                    results.append({
                        'config': {
                            'base_boost': base_boost,
                            'exact_match_boost': exact_match_boost,
                            'decision_sharpening': decision_sharpening,
                            'margin_amplification': margin_amplification
                        },
                        'score': score
                    })
                    
                    if score > best_score:
                        best_score = score
                        best_config = config
    
    print(f"\\n\\nğŸ† æœ€ä½³é…ç½® (ç»¼åˆå¾—åˆ†: {best_score:.4f}):")
    print(f"   base_boost: {best_config.base_boost}")
    print(f"   exact_match_boost: {best_config.exact_match_boost}")
    print(f"   decision_sharpening: {best_config.decision_sharpening}")
    print(f"   margin_amplification: {best_config.margin_amplification}")
    
    # ä¿å­˜æœ€ä½³é…ç½®
    best_config_dict = {
        'base_boost': best_config.base_boost,
        'exact_match_boost': best_config.exact_match_boost,
        'fuzzy_match_boost': best_config.fuzzy_match_boost,
        'semantic_boost': best_config.semantic_boost,
        'premium_quality_boost': best_config.premium_quality_boost,
        'high_engagement_boost': best_config.high_engagement_boost,
        'domain_adaptation_factor': best_config.domain_adaptation_factor,
        'confidence_threshold': best_config.confidence_threshold,
        'low_confidence_penalty': best_config.low_confidence_penalty,
        'decision_sharpening': best_config.decision_sharpening,
        'margin_amplification': best_config.margin_amplification,
        'max_total_boost': best_config.max_total_boost,
        'min_score_threshold': best_config.min_score_threshold,
        'optimization_score': best_score
    }
    
    with open("research/day3_results/production_v2_config.json", 'w') as f:
        json.dump(best_config_dict, f, indent=2)
    
    print(f"\\nğŸ’¾ æœ€ä½³é…ç½®å·²ä¿å­˜: research/day3_results/production_v2_config.json")
    
    return best_config

def evaluate_config_quick(inspirations: List[Dict], 
                         enhancer: ProductionLightweightEnhancerV2) -> float:
    """å¿«é€Ÿé…ç½®è¯„ä¼°"""
    compliance_improvements = []
    ndcg_improvements = []
    margins = []
    
    for item in inspirations:
        query = item['query']
        candidates = item['candidates']
        
        if len(candidates) < 2:
            continue
        
        # åŸå§‹æ’åº
        original_candidates = candidates.copy()
        original_compliance = calculate_compliance_at_k(original_candidates, k=1)
        original_ndcg = calculate_ndcg_at_k(original_candidates, k=10)
        
        # å¢å¼ºæ’åº
        enhanced_candidates = enhancer.enhance_candidates(query, candidates)
        enhanced_compliance = calculate_compliance_at_k(enhanced_candidates, k=1)
        enhanced_ndcg = calculate_ndcg_at_k(enhanced_candidates, k=10)
        
        # è®¡ç®—æ”¹è¿›
        compliance_improvements.append(enhanced_compliance - original_compliance)
        ndcg_improvements.append(enhanced_ndcg - original_ndcg)
        
        # è®¡ç®—margin
        if len(enhanced_candidates) >= 2:
            top_score = enhanced_candidates[0]['enhanced_score']
            second_score = enhanced_candidates[1]['enhanced_score']
            margins.append(top_score - second_score)
    
    # ç»¼åˆè¯„åˆ† (æƒé‡: compliance 40%, ndcg 40%, margin 20%)
    avg_compliance = np.mean(compliance_improvements) if compliance_improvements else 0
    avg_ndcg = np.mean(ndcg_improvements) if ndcg_improvements else 0
    avg_margin = np.mean(margins) if margins else 0
    
    # å½’ä¸€åŒ–margin (ç›®æ ‡æ˜¯å¢åŠ margin)
    normalized_margin = min(avg_margin * 10, 1.0)  # å‡è®¾ç†æƒ³marginä¸º0.1
    
    composite_score = (0.4 * avg_compliance + 0.4 * avg_ndcg + 0.2 * normalized_margin)
    return composite_score

def calculate_compliance_at_k(candidates: List[Dict], k: int = 1) -> float:
    """è®¡ç®—Compliance@K"""
    if len(candidates) < k:
        return 0.0
    
    top_k = candidates[:k]
    scores = [c.get('enhanced_score', c.get('score', 0)) for c in top_k]
    return np.mean(scores) if scores else 0.0

def calculate_ndcg_at_k(candidates: List[Dict], k: int = 10) -> float:
    """è®¡ç®—nDCG@K"""
    if len(candidates) < 2:
        return 0.0
    
    k = min(k, len(candidates))
    scores = [c.get('enhanced_score', c.get('score', 0)) for c in candidates[:k]]
    
    # è®¡ç®—DCG
    dcg = 0.0
    for i, score in enumerate(scores):
        dcg += score / np.log2(i + 2)
    
    # è®¡ç®—IDCG
    ideal_scores = sorted(scores, reverse=True)
    idcg = 0.0
    for i, score in enumerate(ideal_scores):
        idcg += score / np.log2(i + 2)
    
    return dcg / idcg if idcg > 0 else 0.0

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç”Ÿäº§çº§è½»é‡å¢å¼ºå™¨V2.0å¼€å‘")
    print("="*80)
    
    # 1. å‚æ•°ä¼˜åŒ–
    print("\\n1ï¸âƒ£ æ‰§è¡Œå‚æ•°ä¼˜åŒ–...")
    best_config = optimize_production_parameters()
    
    # 2. åˆ›å»ºV2å¢å¼ºå™¨
    print("\\n2ï¸âƒ£ åˆ›å»ºV2å¢å¼ºå™¨...")
    enhancer_v2 = ProductionLightweightEnhancerV2(best_config)
    
    # 3. å¿«é€ŸéªŒè¯
    print("\\n3ï¸âƒ£ å¿«é€ŸéªŒè¯...")
    with open("research/day3_results/production_dataset.json", 'r') as f:
        dataset = json.load(f)
    
    # æµ‹è¯•å‰10ä¸ªæŸ¥è¯¢
    test_queries = dataset['inspirations'][:10]
    total_compliance_improvement = 0
    total_ndcg_improvement = 0
    total_margin = 0
    
    for i, item in enumerate(test_queries):
        query = item['query']
        candidates = item['candidates']
        
        # åŸå§‹vså¢å¼º
        original_compliance = calculate_compliance_at_k(candidates, k=1)
        original_ndcg = calculate_ndcg_at_k(candidates, k=10)
        
        enhanced_candidates = enhancer_v2.enhance_candidates(query, candidates)
        enhanced_compliance = calculate_compliance_at_k(enhanced_candidates, k=1)
        enhanced_ndcg = calculate_ndcg_at_k(enhanced_candidates, k=10)
        
        compliance_improvement = enhanced_compliance - original_compliance
        ndcg_improvement = enhanced_ndcg - original_ndcg
        
        if len(enhanced_candidates) >= 2:
            margin = enhanced_candidates[0]['enhanced_score'] - enhanced_candidates[1]['enhanced_score']
            total_margin += margin
        
        total_compliance_improvement += compliance_improvement
        total_ndcg_improvement += ndcg_improvement
        
        print(f"   æŸ¥è¯¢ {i+1}: Î”Compliance={compliance_improvement:+.4f}, Î”nDCG={ndcg_improvement:+.4f}")
    
    avg_compliance_improvement = total_compliance_improvement / len(test_queries)
    avg_ndcg_improvement = total_ndcg_improvement / len(test_queries)
    avg_margin = total_margin / len(test_queries)
    
    print(f"\\nğŸ“Š V2å¿«é€ŸéªŒè¯ç»“æœ:")
    print(f"   å¹³å‡Î”Compliance@1: {avg_compliance_improvement:+.4f}")
    print(f"   å¹³å‡Î”nDCG@10: {avg_ndcg_improvement:+.4f}")
    print(f"   å¹³å‡Margin: {avg_margin:.4f}")
    
    print(f"\\nâœ¨ V2å¢å¼ºå™¨å¼€å‘å®Œæˆï¼å‡†å¤‡è¿›è¡Œå®Œæ•´ç”Ÿäº§è¯„ä¼°")

if __name__ == "__main__":
    main()