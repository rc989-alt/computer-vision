#!/usr/bin/env python3
"""
Day 3 Lightweight Pipeline Enhancer
åŸºäºDay 3å‘ç°çš„è½»é‡çº§ã€å®ç”¨ä¸»ä¹‰ä¼˜åŒ–æ–¹æ¡ˆ
"""

import json
import time
import re
import logging
from pathlib import Path
from typing import Dict, List, Any, Tuple
import numpy as np
from dataclasses import dataclass

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
import sys
sys.path.append('.')  # æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
from src.subject_object import check_subject_object
from src.conflict_penalty import conflict_penalty
from src.dual_score import fuse_dual_score

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class OptimizationConfig:
    """ä¼˜åŒ–é…ç½®"""
    compliance_weight: float = 0.6
    conflict_penalty_alpha: float = 0.25
    description_boost_weight: float = 0.3
    quality_threshold: float = 0.1
    enable_description_enhancement: bool = True
    enable_caching: bool = True

class LightweightPipelineEnhancer:
    """è½»é‡çº§pipelineå¢å¼ºå™¨ - å®ç”¨ä¸»ä¹‰æ–¹æ¡ˆ"""
    
    def __init__(self, config: OptimizationConfig = None):
        self.config = config or OptimizationConfig()
        self.cache = {} if self.config.enable_caching else None
        self.stats = {
            'processed_queries': 0,
            'cache_hits': 0,
            'enhancement_applied': 0,
            'avg_processing_time': 0.0
        }
        
        # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        self._compile_patterns()
        
        logger.info("ğŸš€ è½»é‡çº§Pipelineå¢å¼ºå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   Compliance weight: {self.config.compliance_weight}")
        logger.info(f"   Conflict penalty Î±: {self.config.conflict_penalty_alpha}")
        logger.info(f"   Description boost: {self.config.description_boost_weight}")
    
    def _compile_patterns(self):
        """é¢„ç¼–è¯‘å¸¸ç”¨æ­£åˆ™è¡¨è¾¾å¼"""
        self.patterns = {
            # ç»ç’ƒç±»å‹
            'glass_types': re.compile(r'\\b(coupe|martini|rocks|old.fashioned|wine|crystal|champagne|highball)\\b', re.I),
            # é¢œè‰²è¯æ±‡
            'colors': re.compile(r'\\b(pink|golden|amber|clear|blue|green|red|purple|yellow|orange|black|white)\\b', re.I),
            # è£…é¥°å…ƒç´ 
            'garnishes': re.compile(r'\\b(rose|petal|orange|lime|lemon|mint|berry|fruit|herb|cherry|olive)\\b', re.I),
            # è´¨é‡å½¢å®¹è¯
            'quality_words': re.compile(r'\\b(elegant|crystal|premium|artisanal|craft|fresh|vibrant|beautiful)\\b', re.I),
            # è´Ÿé¢è¯æ±‡
            'negative_words': re.compile(r'\\b(generic|basic|plain|simple|ordinary|dull)\\b', re.I)
        }
    
    def enhance_candidates(self, query: str, candidates: List[Dict]) -> List[Dict]:
        """å¢å¼ºå€™é€‰åˆ—è¡¨"""
        start_time = time.time()
        
        # ç»Ÿè®¡æ›´æ–°
        self.stats['processed_queries'] += 1
        
        # ç¼“å­˜æ£€æŸ¥
        cache_key = self._generate_cache_key(query, candidates)
        if self.cache and cache_key in self.cache:
            self.stats['cache_hits'] += 1
            return self.cache[cache_key]
        
        # æ‰§è¡Œå¢å¼º
        enhanced_candidates = []
        for candidate in candidates:
            enhanced = self._enhance_single_candidate(candidate, query)
            enhanced_candidates.append(enhanced)
        
        # é‡æ’åº
        enhanced_candidates.sort(key=lambda x: x.get('enhanced_score', 0), reverse=True)
        
        # ç¼“å­˜ç»“æœ
        if self.cache:
            self.cache[cache_key] = enhanced_candidates
        
        # æ›´æ–°ç»Ÿè®¡
        processing_time = time.time() - start_time
        self.stats['avg_processing_time'] = (
            self.stats['avg_processing_time'] * (self.stats['processed_queries'] - 1) + processing_time
        ) / self.stats['processed_queries']
        
        return enhanced_candidates
    
    def _enhance_single_candidate(self, candidate: Dict, query: str) -> Dict:
        """å¢å¼ºå•ä¸ªå€™é€‰"""
        enhanced = candidate.copy()
        
        # 1. åŸºç¡€åˆ†æ•°
        base_score = candidate.get('score', 0.5)
        
        # 2. æ ¸å¿ƒæ¨¡å—å¤„ç†
        regions = self._extract_regions_from_description(candidate)
        compliance_score, compliance_details = check_subject_object(regions=regions)
        penalty_score, penalty_details = conflict_penalty(regions, alpha=self.config.conflict_penalty_alpha)
        
        # 3. æ ¸å¿ƒåˆ†æ•°èåˆ
        core_enhanced_score = fuse_dual_score(
            compliance_score, penalty_score, 
            w_c=self.config.compliance_weight, w_n=0.4
        )
        
        # 4. æè¿°å¢å¼º (æ–°å¢)
        description_boost = 0.0
        if self.config.enable_description_enhancement:
            description_boost = self._calculate_description_boost(candidate, query)
        
        # 5. æœ€ç»ˆåˆ†æ•°è®¡ç®—
        final_score = (
            0.5 * base_score +  # ä¿ç•™50%åŸå§‹åˆ†æ•°
            0.3 * core_enhanced_score +  # 30%æ ¸å¿ƒæ¨¡å—å¢å¼º
            0.2 * description_boost  # 20%æè¿°å¢å¼º
        )
        
        # 6. æ›´æ–°å€™é€‰ä¿¡æ¯
        enhanced.update({
            'original_score': base_score,
            'compliance_score': compliance_score,
            'conflict_penalty': penalty_score,
            'core_enhanced_score': core_enhanced_score,
            'description_boost': description_boost,
            'enhanced_score': final_score,
            'score': final_score,  # æ›´æ–°ä¸»åˆ†æ•°
            'enhancement_details': {
                'regions_detected': len(regions),
                'compliance_details': compliance_details,
                'penalty_details': penalty_details,
                'description_features': self._get_description_features(candidate, query)
            }
        })
        
        return enhanced
    
    def _extract_regions_from_description(self, candidate: Dict) -> List[Dict]:
        """ä»æè¿°ä¸­æå–regions (æ”¹è¿›ç‰ˆ)"""
        description = candidate.get('alt_description', '').lower()
        regions = []
        
        # ç»ç’ƒæ£€æµ‹ (æ”¹è¿›)
        glass_match = self.patterns['glass_types'].search(description)
        if glass_match:
            glass_type = glass_match.group(1)
            confidence = 0.95 if glass_type in ['coupe', 'martini'] else 0.85
            regions.append({
                'label': 'glass',
                'type': f'{glass_type}_glass',
                'confidence': confidence
            })
        elif any(word in description for word in ['glass', 'cup']):
            regions.append({
                'label': 'glass',
                'type': 'generic_glass',
                'confidence': 0.7
            })
        
        # é¢œè‰²æ£€æµ‹ (æ”¹è¿›)
        color_matches = self.patterns['colors'].findall(description)
        for color in set(color_matches):  # å»é‡
            confidence = 0.9 if color in ['pink', 'golden', 'amber'] else 0.8
            regions.append({
                'label': f'{color}_liquid',
                'color': color,
                'type': 'cocktail',
                'confidence': confidence
            })
        
        # è£…é¥°æ£€æµ‹ (æ”¹è¿›)
        garnish_matches = self.patterns['garnishes'].findall(description)
        for garnish in set(garnish_matches):
            garnish_type = 'floral' if garnish in ['rose', 'petal'] else 'fruit'
            confidence = 0.85 if garnish in ['rose', 'orange', 'mint'] else 0.75
            regions.append({
                'label': f'{garnish}_garnish',
                'type': garnish_type,
                'confidence': confidence
            })
        
        return regions
    
    def _calculate_description_boost(self, candidate: Dict, query: str) -> float:
        """è®¡ç®—æè¿°å¢å¼ºåˆ†æ•°"""
        description = candidate.get('alt_description', '').lower()
        query_lower = query.lower()
        
        boost = 0.0
        
        # 1. æŸ¥è¯¢åŒ¹é…åº¦
        query_words = set(query_lower.split())
        desc_words = set(description.split())
        word_overlap = len(query_words & desc_words)
        if word_overlap > 0:
            boost += 0.3 * (word_overlap / len(query_words))
        
        # 2. è´¨é‡è¯æ±‡åŠ åˆ†
        quality_matches = len(self.patterns['quality_words'].findall(description))
        boost += min(0.2, quality_matches * 0.05)
        
        # 3. è´Ÿé¢è¯æ±‡å‡åˆ†
        negative_matches = len(self.patterns['negative_words'].findall(description))
        boost -= min(0.15, negative_matches * 0.05)
        
        # 4. ç‰¹å®šæŸ¥è¯¢å¢å¼º
        if 'floral' in query_lower and any(word in description for word in ['rose', 'petal', 'flower']):
            boost += 0.25
        
        if 'whiskey' in query_lower and 'whiskey' in description:
            boost += 0.2
        
        if 'cocktail' in query_lower and 'cocktail' in description:
            boost += 0.1
        
        # 5. é¢œè‰²ä¸€è‡´æ€§
        query_colors = self.patterns['colors'].findall(query_lower)
        desc_colors = self.patterns['colors'].findall(description)
        if query_colors and desc_colors:
            color_match = len(set(query_colors) & set(desc_colors))
            if color_match > 0:
                boost += 0.2 * color_match
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        return max(0.0, min(1.0, boost))
    
    def _get_description_features(self, candidate: Dict, query: str) -> Dict:
        """è·å–æè¿°ç‰¹å¾åˆ†æ (ç”¨äºè°ƒè¯•å’Œç›‘æ§)"""
        description = candidate.get('alt_description', '').lower()
        query_lower = query.lower()
        
        return {
            'glass_types': self.patterns['glass_types'].findall(description),
            'colors': self.patterns['colors'].findall(description),
            'garnishes': self.patterns['garnishes'].findall(description),
            'quality_words': self.patterns['quality_words'].findall(description),
            'negative_words': self.patterns['negative_words'].findall(description),
            'query_word_overlap': len(set(query_lower.split()) & set(description.split()))
        }
    
    def _generate_cache_key(self, query: str, candidates: List[Dict]) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        candidate_ids = [c.get('id', str(hash(str(c)))) for c in candidates]
        return f"{hash(query)}_{hash(tuple(candidate_ids))}"
    
    def optimize_parameters(self, test_data: List[Dict], target_metric: str = 'enhanced_score') -> OptimizationConfig:
        """å‚æ•°ä¼˜åŒ– (ç½‘æ ¼æœç´¢)"""
        logger.info("ğŸ” å¼€å§‹å‚æ•°ä¼˜åŒ–")
        
        # å‚æ•°æœç´¢ç©ºé—´
        param_grid = {
            'compliance_weight': [0.4, 0.5, 0.6, 0.7, 0.8],
            'conflict_penalty_alpha': [0.15, 0.2, 0.25, 0.3, 0.35],
            'description_boost_weight': [0.1, 0.2, 0.3, 0.4]
        }
        
        best_score = -float('inf')
        best_config = None
        
        # ç½‘æ ¼æœç´¢
        for comp_weight in param_grid['compliance_weight']:
            for penalty_alpha in param_grid['conflict_penalty_alpha']:
                for desc_weight in param_grid['description_boost_weight']:
                    # æµ‹è¯•é…ç½®
                    test_config = OptimizationConfig(
                        compliance_weight=comp_weight,
                        conflict_penalty_alpha=penalty_alpha,
                        description_boost_weight=desc_weight
                    )
                    
                    # è¯„ä¼°é…ç½®
                    score = self._evaluate_config(test_config, test_data, target_metric)
                    
                    if score > best_score:
                        best_score = score
                        best_config = test_config
        
        logger.info(f"âœ… å‚æ•°ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³åˆ†æ•°: {best_score:.4f}")
        return best_config
    
    def _evaluate_config(self, config: OptimizationConfig, test_data: List[Dict], metric: str) -> float:
        """è¯„ä¼°é…ç½®æ€§èƒ½"""
        # ä¸´æ—¶åˆ›å»ºæµ‹è¯•å¢å¼ºå™¨
        temp_enhancer = LightweightPipelineEnhancer(config)
        
        total_improvement = 0.0
        valid_queries = 0
        
        for item in test_data:
            query = item.get('query', '')
            candidates = item.get('candidates', [])
            
            if len(candidates) < 2:
                continue
            
            # åŸå§‹åˆ†æ•°
            original_scores = [c.get('score', 0) for c in candidates]
            
            # å¢å¼ºååˆ†æ•°
            enhanced_candidates = temp_enhancer.enhance_candidates(query, candidates)
            enhanced_scores = [c.get('enhanced_score', 0) for c in enhanced_candidates]
            
            # è®¡ç®—æ”¹å–„
            improvement = np.mean(enhanced_scores) - np.mean(original_scores)
            total_improvement += improvement
            valid_queries += 1
        
        return total_improvement / valid_queries if valid_queries > 0 else 0.0
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        stats = self.stats.copy()
        
        # è®¡ç®—è¡ç”ŸæŒ‡æ ‡
        if stats['processed_queries'] > 0:
            stats['cache_hit_rate'] = stats['cache_hits'] / stats['processed_queries']
        else:
            stats['cache_hit_rate'] = 0.0
        
        stats['config'] = {
            'compliance_weight': self.config.compliance_weight,
            'conflict_penalty_alpha': self.config.conflict_penalty_alpha,
            'description_boost_weight': self.config.description_boost_weight
        }
        
        return stats
    
    def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
            test_candidate = {
                'id': 'health_check',
                'alt_description': 'Pink cocktail with rose petals in elegant coupe glass',
                'score': 0.75
            }
            
            result = self._enhance_single_candidate(test_candidate, 'pink floral cocktail')
            
            return {
                'status': 'healthy',
                'basic_enhancement': result.get('enhanced_score', 0) > 0,
                'processing_time': self.stats.get('avg_processing_time', 0),
                'cache_enabled': self.cache is not None
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e)
            }

# æ€§èƒ½æµ‹è¯•å’Œå¯¹æ¯”å·¥å…·
class LightweightTester:
    """è½»é‡çº§å¢å¼ºå™¨æµ‹è¯•å·¥å…·"""
    
    def __init__(self):
        self.enhancer = LightweightPipelineEnhancer()
        self.results_dir = Path("research/day3_results")
        self.results_dir.mkdir(exist_ok=True)
    
    def run_performance_test(self, test_data_path: str = "data/input/sample_input.json") -> Dict[str, Any]:
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹è½»é‡çº§å¢å¼ºå™¨æ€§èƒ½æµ‹è¯•")
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        with open(test_data_path, 'r') as f:
            data = json.load(f)
        
        test_queries = data.get('inspirations', [])
        
        results = []
        total_start_time = time.time()
        
        for item in test_queries:
            query = item.get('query', '')
            original_candidates = item.get('candidates', [])
            
            if len(original_candidates) < 2:
                continue
            
            # è®°å½•åŸå§‹åˆ†æ•°
            original_scores = [c.get('score', 0) for c in original_candidates]
            
            # å¢å¼ºå¤„ç†
            start_time = time.time()
            enhanced_candidates = self.enhancer.enhance_candidates(query, original_candidates)
            processing_time = time.time() - start_time
            
            # è®°å½•å¢å¼ºåˆ†æ•°
            enhanced_scores = [c.get('enhanced_score', 0) for c in enhanced_candidates]
            
            # åˆ†æç»“æœ
            result = {
                'query': query,
                'candidates_count': len(original_candidates),
                'processing_time': processing_time,
                'scores': {
                    'original_mean': np.mean(original_scores),
                    'enhanced_mean': np.mean(enhanced_scores),
                    'improvement': np.mean(enhanced_scores) - np.mean(original_scores)
                },
                'ranking_changed': [c.get('id') for c in original_candidates] != [c.get('id') for c in enhanced_candidates]
            }
            
            results.append(result)
        
        total_time = time.time() - total_start_time
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'test_metadata': {
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'queries_tested': len(results),
                'total_processing_time': total_time
            },
            'performance_summary': {
                'avg_processing_time': np.mean([r['processing_time'] for r in results]),
                'total_improvement': np.mean([r['scores']['improvement'] for r in results]),
                'queries_reranked': sum(1 for r in results if r['ranking_changed']),
                'rerank_rate': sum(1 for r in results if r['ranking_changed']) / len(results) if results else 0
            },
            'detailed_results': results,
            'enhancer_stats': self.enhancer.get_performance_stats(),
            'health_check': self.enhancer.health_check()
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.results_dir / f"lightweight_test_{int(time.time())}.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        logger.info(f"âœ… æµ‹è¯•å®Œæˆï¼ŒæŠ¥å‘Šä¿å­˜è‡³: {report_file}")
        
        return report

if __name__ == "__main__":
    # è¿è¡Œè½»é‡çº§å¢å¼ºå™¨æµ‹è¯•
    tester = LightweightTester()
    report = tester.run_performance_test()
    
    # æ‰“å°ç»“æœ
    print("\\n" + "="*60)
    print("ğŸ¯ Lightweight Pipeline Enhancer Results")
    print("="*60)
    
    perf = report.get('performance_summary', {})
    print(f"\\nâš¡ Performance:")
    print(f"   Avg processing time: {perf.get('avg_processing_time', 0)*1000:.2f}ms")
    print(f"   Total improvement: {perf.get('total_improvement', 0):+.4f}")
    print(f"   Rerank rate: {perf.get('rerank_rate', 0):.1%}")
    print(f"   Queries reranked: {perf.get('queries_reranked', 0)}")
    
    health = report.get('health_check', {})
    print(f"\\nğŸ” Health Check:")
    print(f"   Status: {health.get('status', 'unknown')}")
    print(f"   Basic enhancement: {health.get('basic_enhancement', False)}")
    
    stats = report.get('enhancer_stats', {})
    print(f"\\nğŸ“Š Statistics:")
    print(f"   Processed queries: {stats.get('processed_queries', 0)}")
    print(f"   Cache hit rate: {stats.get('cache_hit_rate', 0):.1%}")
    
    # åˆ¤æ–­æ˜¯å¦æˆåŠŸ
    improvement = perf.get('total_improvement', 0)
    processing_time = perf.get('avg_processing_time', 0)
    
    if improvement > 0.02 and processing_time < 0.01:  # 10msä»¥å†…
        print(f"\\nğŸ† Result: SUCCESS - è½»é‡çº§æ–¹æ¡ˆæœ‰æ•ˆï¼")
        print(f"   âœ… è´¨é‡æ”¹è¿›: {improvement:+.4f}")
        print(f"   âœ… æ€§èƒ½å¼€é”€: {processing_time*1000:.1f}ms (acceptable)")
    elif improvement > 0.01:
        print(f"\\nğŸ“ˆ Result: MODERATE SUCCESS - æœ‰æ”¹è¿›ç©ºé—´")
        print(f"   ğŸ“Š è´¨é‡æ”¹è¿›: {improvement:+.4f}")
        print(f"   âš¡ æ€§èƒ½å¼€é”€: {processing_time*1000:.1f}ms")
    else:
        print(f"\\nâŒ Result: NEEDS IMPROVEMENT")
        print(f"   ğŸ“‰ è´¨é‡æ”¹è¿›ä¸è¶³: {improvement:+.4f}")
        print(f"   ğŸ”§ éœ€è¦è¿›ä¸€æ­¥å‚æ•°è°ƒä¼˜")
    
    print(f"\\nğŸ“ è¯¦ç»†æŠ¥å‘Š: research/day3_results/")