#!/usr/bin/env python3
"""
Day 3 æ”¹è¿›ç‰ˆè½»é‡çº§å¢å¼ºå™¨
åŸºäºè¯Šæ–­ç»“æœçš„ç®€åŒ–ã€æ­£å‘å¢å¼ºæ–¹æ¡ˆ
"""

import json
import time
import re
import logging
from typing import Dict, List, Any
import numpy as np
from dataclasses import dataclass

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SimpleConfig:
    """ç®€åŒ–é…ç½®"""
    base_boost: float = 0.01
    keyword_match_boost: float = 0.02
    quality_match_boost: float = 0.015
    max_total_boost: float = 0.10  # æœ€å¤§æå‡é™åˆ¶
    enable_caching: bool = True

class ImprovedLightweightEnhancer:
    """æ”¹è¿›ç‰ˆè½»é‡çº§å¢å¼ºå™¨ - ä¸“æ³¨æ­£å‘å¢å¼º"""
    
    def __init__(self, config: SimpleConfig = None):
        self.config = config or SimpleConfig()
        self.cache = {} if self.config.enable_caching else None
        self.stats = {
            'processed_queries': 0,
            'cache_hits': 0,
            'avg_improvement': 0.0,
            'avg_processing_time': 0.0
        }
        
        # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        self._compile_patterns()
        
        logger.info("ğŸš€ æ”¹è¿›ç‰ˆè½»é‡çº§å¢å¼ºå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   åŸºç¡€æå‡: {self.config.base_boost}")
        logger.info(f"   å…³é”®è¯åŒ¹é…æå‡: {self.config.keyword_match_boost}")
        logger.info(f"   è´¨é‡åŒ¹é…æå‡: {self.config.quality_match_boost}")
    
    def _compile_patterns(self):
        """é¢„ç¼–è¯‘åŒ¹é…æ¨¡å¼"""
        self.patterns = {
            # é¢œè‰²åŒ¹é…
            'colors': re.compile(r'\\b(pink|golden|amber|clear|blue|green|red|purple|yellow|orange|rose)\\b', re.I),
            # ç»ç’ƒå™¨çš¿
            'glassware': re.compile(r'\\b(coupe|martini|rocks|wine|crystal|champagne|highball|glass)\\b', re.I),
            # è£…é¥°å…ƒç´ 
            'garnishes': re.compile(r'\\b(rose|petal|orange|lime|lemon|mint|berry|fruit|herb|cherry|olive|floral)\\b', re.I),
            # è´¨é‡è¯æ±‡
            'quality': re.compile(r'\\b(elegant|beautiful|fresh|vibrant|premium|artisanal|craft|delicate|refined)\\b', re.I),
            # é¥®å“ç±»å‹
            'drink_types': re.compile(r'\\b(cocktail|martini|spritz|mojito|cosmopolitan|bellini|sangria)\\b', re.I)
        }
    
    def enhance_candidates(self, query: str, candidates: List[Dict]) -> List[Dict]:
        """å¢å¼ºå€™é€‰åˆ—è¡¨ - ç®€åŒ–ç‰ˆ"""
        start_time = time.time()
        
        # ç¼“å­˜æ£€æŸ¥
        cache_key = f"{query}_{len(candidates)}"
        if self.cache and cache_key in self.cache:
            self.stats['cache_hits'] += 1
            return self.cache[cache_key]
        
        # å¤„ç†æ¯ä¸ªå€™é€‰é¡¹
        enhanced_candidates = []
        total_improvement = 0
        
        for candidate in candidates:
            enhanced = self._enhance_single_candidate(candidate, query)
            enhanced_candidates.append(enhanced)
            
            # è®¡ç®—æ”¹è¿›
            improvement = enhanced.get('enhanced_score', 0) - candidate.get('score', 0)
            total_improvement += improvement
        
        # é‡æ–°æ’åº
        enhanced_candidates.sort(key=lambda x: x.get('enhanced_score', 0), reverse=True)
        
        # æ›´æ–°ç»Ÿè®¡
        processing_time = time.time() - start_time
        self.stats['processed_queries'] += 1
        avg_improvement = total_improvement / len(candidates) if candidates else 0
        
        # æ»‘åŠ¨å¹³å‡æ›´æ–°
        self.stats['avg_improvement'] = (
            self.stats['avg_improvement'] * 0.9 + avg_improvement * 0.1
        )
        self.stats['avg_processing_time'] = (
            self.stats['avg_processing_time'] * 0.9 + processing_time * 0.1
        )
        
        # ç¼“å­˜ç»“æœ
        if self.cache:
            self.cache[cache_key] = enhanced_candidates
        
        return enhanced_candidates
    
    def _enhance_single_candidate(self, candidate: Dict, query: str) -> Dict:
        """å¢å¼ºå•ä¸ªå€™é€‰é¡¹ - çº¯æ­£å‘é€»è¾‘"""
        enhanced = candidate.copy()
        original_score = candidate.get('score', 0.5)
        
        # è®¡ç®—å„ç§åŒ¹é…å¾—åˆ†
        matches = self._calculate_matches(candidate, query)
        
        # åŸºç¡€æå‡
        boost = self.config.base_boost
        
        # å…³é”®è¯åŒ¹é…æå‡
        boost += matches['keyword_matches'] * self.config.keyword_match_boost
        
        # è´¨é‡åŒ¹é…æå‡
        boost += matches['quality_matches'] * self.config.quality_match_boost
        
        # ç‰¹æ®Šæ¨¡å¼åŒ¹é…
        boost += matches['pattern_matches'] * 0.01
        
        # åº”ç”¨æå‡ä¸Šé™
        boost = min(boost, self.config.max_total_boost)
        
        # è®¡ç®—æœ€ç»ˆåˆ†æ•°
        enhanced_score = original_score + boost
        
        # æ›´æ–°å€™é€‰é¡¹
        enhanced.update({
            'original_score': original_score,
            'enhancement_boost': boost,
            'enhanced_score': enhanced_score,
            'score': enhanced_score,  # æ›´æ–°ä¸»åˆ†æ•°
            'match_details': matches
        })
        
        return enhanced
    
    def _calculate_matches(self, candidate: Dict, query: str) -> Dict:
        """è®¡ç®—å„ç§åŒ¹é…å¾—åˆ†"""
        description = candidate.get('alt_description', '').lower()
        query_lower = query.lower()
        query_words = query_lower.split()
        
        matches = {
            'keyword_matches': 0,
            'quality_matches': 0,
            'pattern_matches': 0,
            'details': {}
        }
        
        # 1. ç›´æ¥å…³é”®è¯åŒ¹é…
        keyword_matches = sum(1 for word in query_words if word in description)
        matches['keyword_matches'] = keyword_matches
        matches['details']['matched_keywords'] = keyword_matches
        
        # 2. æ¨¡å¼åŒ¹é…
        pattern_matches = 0
        pattern_details = {}
        
        for pattern_name, pattern in self.patterns.items():
            pattern_hits = len(pattern.findall(description))
            if pattern_hits > 0:
                pattern_matches += pattern_hits
                pattern_details[pattern_name] = pattern_hits
        
        matches['pattern_matches'] = pattern_matches
        matches['details']['pattern_matches'] = pattern_details
        
        # 3. è´¨é‡è¯æ±‡åŒ¹é…
        quality_matches = len(self.patterns['quality'].findall(description))
        matches['quality_matches'] = quality_matches
        matches['details']['quality_words'] = quality_matches
        
        # 4. ç‰¹æ®ŠæŸ¥è¯¢åŒ¹é…é€»è¾‘
        if 'pink' in query_lower and 'pink' in description:
            matches['pattern_matches'] += 2  # é¢å¤–å¥–åŠ±ç²¾ç¡®é¢œè‰²åŒ¹é…
        
        if 'floral' in query_lower and any(word in description for word in ['rose', 'petal', 'flower']):
            matches['pattern_matches'] += 2  # èŠ±å‰ä¸»é¢˜åŒ¹é…
        
        return matches
    
    def get_performance_stats(self) -> Dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        return {
            'processed_queries': self.stats['processed_queries'],
            'cache_hits': self.stats['cache_hits'],
            'cache_hit_rate': self.stats['cache_hits'] / max(1, self.stats['processed_queries']),
            'avg_improvement': self.stats['avg_improvement'],
            'avg_processing_time_ms': self.stats['avg_processing_time'] * 1000,
            'status': 'healthy' if self.stats['avg_improvement'] > 0 else 'needs_tuning'
        }
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡"""
        self.stats = {
            'processed_queries': 0,
            'cache_hits': 0,
            'avg_improvement': 0.0,
            'avg_processing_time': 0.0
        }

class ImprovedParameterOptimizer:
    """æ”¹è¿›ç‰ˆå‚æ•°ä¼˜åŒ–å™¨"""
    
    def __init__(self, test_data_path: str = "data/input/sample_input.json"):
        with open(test_data_path, 'r') as f:
            data = json.load(f)
        self.test_data = data.get('inspirations', [])
        logger.info(f"ğŸ“Š åŠ è½½äº† {len(self.test_data)} ä¸ªæµ‹è¯•æŸ¥è¯¢")
    
    def optimize_parameters(self) -> SimpleConfig:
        """ä¼˜åŒ–å‚æ•°"""
        logger.info("ğŸ” å¼€å§‹å‚æ•°ä¼˜åŒ–")
        
        best_score = -float('inf')
        best_config = None
        
        # å‚æ•°æœç´¢ç©ºé—´
        base_boosts = [0.005, 0.01, 0.015, 0.02]
        keyword_boosts = [0.01, 0.02, 0.03, 0.04]
        quality_boosts = [0.005, 0.01, 0.015, 0.02]
        
        total_combinations = len(base_boosts) * len(keyword_boosts) * len(quality_boosts)
        current = 0
        
        for base_boost in base_boosts:
            for keyword_boost in keyword_boosts:
                for quality_boost in quality_boosts:
                    current += 1
                    
                    config = SimpleConfig(
                        base_boost=base_boost,
                        keyword_match_boost=keyword_boost,
                        quality_match_boost=quality_boost
                    )
                    
                    score = self._evaluate_config(config)
                    
                    if current % 10 == 0 or score > best_score:
                        logger.info(f"   è¿›åº¦: {current}/{total_combinations}, å½“å‰æœ€ä½³: {best_score:.4f}, æµ‹è¯•åˆ†æ•°: {score:.4f}")
                    
                    if score > best_score:
                        best_score = score
                        best_config = config
        
        logger.info(f"âœ… å‚æ•°ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³åˆ†æ•°: {best_score:.4f}")
        return best_config, best_score
    
    def _evaluate_config(self, config: SimpleConfig) -> float:
        """è¯„ä¼°é…ç½®"""
        enhancer = ImprovedLightweightEnhancer(config)
        
        improvements = []
        processing_times = []
        
        for item in self.test_data:
            query = item.get('query', '')
            candidates = item.get('candidates', [])
            
            if len(candidates) < 2:
                continue
            
            # æµ‹è¯•å¢å¼º
            start_time = time.time()
            enhanced_candidates = enhancer.enhance_candidates(query, candidates)
            processing_time = time.time() - start_time
            
            # è®¡ç®—æ”¹è¿›
            original_scores = [c.get('score', 0) for c in candidates]
            enhanced_scores = [c.get('enhanced_score', 0) for c in enhanced_candidates]
            
            improvement = np.mean(enhanced_scores) - np.mean(original_scores)
            improvements.append(improvement)
            processing_times.append(processing_time)
        
        if not improvements:
            return 0.0
        
        # è¯„åˆ†ï¼šä¸»è¦çœ‹æ”¹è¿›ï¼Œè¾…åŠ©çœ‹æ€§èƒ½
        avg_improvement = np.mean(improvements)
        avg_time = np.mean(processing_times)
        
        # è¯„åˆ†å‡½æ•°
        score = avg_improvement * 100  # æ”¹è¿›æ˜¯ä¸»è¦æŒ‡æ ‡
        
        # æ€§èƒ½å¥–åŠ±/æƒ©ç½š
        if avg_time < 0.001:  # å°äº1mså¥–åŠ±
            score += 1.0
        elif avg_time > 0.005:  # å¤§äº5msæƒ©ç½š
            score -= 2.0
        
        return score

def test_improved_enhancer():
    """æµ‹è¯•æ”¹è¿›ç‰ˆå¢å¼ºå™¨"""
    print("\\n" + "="*60)
    print("ğŸ¯ Testing Improved Lightweight Enhancer")
    print("="*60)
    
    # åŠ è½½æ•°æ®
    with open("data/input/sample_input.json", 'r') as f:
        data = json.load(f)
    
    test_data = data.get('inspirations', [])
    item = test_data[0]
    query = item.get('query', '')
    candidates = item.get('candidates', [])
    
    # åˆ›å»ºæ”¹è¿›ç‰ˆå¢å¼ºå™¨
    config = SimpleConfig(
        base_boost=0.01,
        keyword_match_boost=0.025,
        quality_match_boost=0.015
    )
    
    enhancer = ImprovedLightweightEnhancer(config)
    
    print(f"æŸ¥è¯¢: '{query}'")
    print("\\nå¤„ç†ç»“æœ:")
    
    # å¤„ç†å¢å¼º
    start_time = time.time()
    enhanced_candidates = enhancer.enhance_candidates(query, candidates)
    processing_time = time.time() - start_time
    
    # æ˜¾ç¤ºç»“æœ
    for i, (orig, enh) in enumerate(zip(candidates, enhanced_candidates)):
        orig_score = orig.get('score', 0)
        enh_score = enh.get('enhanced_score', 0)
        boost = enh.get('enhancement_boost', 0)
        matches = enh.get('match_details', {})
        
        print(f"\\n   å€™é€‰é¡¹ {i+1}:")
        print(f"      åˆ†æ•°: {orig_score:.3f} â†’ {enh_score:.3f} (+{boost:.4f})")
        print(f"      å…³é”®è¯åŒ¹é…: {matches.get('keyword_matches', 0)}")
        print(f"      è´¨é‡åŒ¹é…: {matches.get('quality_matches', 0)}")
        print(f"      æ¨¡å¼åŒ¹é…: {matches.get('pattern_matches', 0)}")
    
    # æ€»ä½“ç»Ÿè®¡
    original_avg = sum(c.get('score', 0) for c in candidates) / len(candidates)
    enhanced_avg = sum(c.get('enhanced_score', 0) for c in enhanced_candidates) / len(enhanced_candidates)
    total_improvement = enhanced_avg - original_avg
    
    print(f"\\nğŸ“Š æ€»ä½“ç»“æœ:")
    print(f"   åŸå§‹å¹³å‡åˆ†: {original_avg:.4f}")
    print(f"   å¢å¼ºå¹³å‡åˆ†: {enhanced_avg:.4f}")
    print(f"   æ€»ä½“æ”¹è¿›: {total_improvement:+.4f}")
    print(f"   å¤„ç†æ—¶é—´: {processing_time*1000:.2f}ms")
    
    # æ€§èƒ½ç»Ÿè®¡
    stats = enhancer.get_performance_stats()
    print(f"   çŠ¶æ€: {stats['status']}")
    
    # åˆ¤æ–­æˆåŠŸä¸å¦
    if total_improvement > 0.02:
        print("\\nğŸš€ EXCELLENT: æ˜¾è‘—æ”¹è¿›ä¸”é«˜æ•ˆ!")
        return True
    elif total_improvement > 0:
        print("\\nâœ… GOOD: æœ‰æ•ˆæ”¹è¿›!")
        return True
    else:
        print("\\nâŒ POOR: ä»éœ€ä¼˜åŒ–")
        return False

if __name__ == "__main__":
    # æµ‹è¯•æ”¹è¿›ç‰ˆå¢å¼ºå™¨
    success = test_improved_enhancer()
    
    if success:
        print("\\nğŸ¯ æ‰§è¡Œå‚æ•°ä¼˜åŒ–:")
        optimizer = ImprovedParameterOptimizer()
        best_config, best_score = optimizer.optimize_parameters()
        
        print(f"\\nğŸ† æœ€ä½³é…ç½®:")
        print(f"   åŸºç¡€æå‡: {best_config.base_boost}")
        print(f"   å…³é”®è¯æå‡: {best_config.keyword_match_boost}")
        print(f"   è´¨é‡æå‡: {best_config.quality_match_boost}")
        print(f"   è¯„åˆ†: {best_score:.4f}")
        
        # ä¿å­˜é…ç½®
        config_dict = {
            'base_boost': best_config.base_boost,
            'keyword_match_boost': best_config.keyword_match_boost,
            'quality_match_boost': best_config.quality_match_boost,
            'max_total_boost': best_config.max_total_boost,
            'score': best_score
        }
        
        with open("research/day3_results/improved_config.json", 'w') as f:
            json.dump(config_dict, f, indent=2)
        
        print(f"\\nğŸ“ æœ€ä½³é…ç½®å·²ä¿å­˜")
    else:
        print("\\nâŒ éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•åŸºç¡€é€»è¾‘")