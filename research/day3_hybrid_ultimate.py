#!/usr/bin/env python3
"""
Day 3+ æ··åˆç­–ç•¥ç»ˆæä¼˜åŒ–å™¨
ç»“åˆV1.0ä¼˜åŠ¿ + nDCGä¸“é¡¹æ”»å…³ + å…¨æ–°çªç ´ç‚¹

ç­–ç•¥é‡æ–°å®¡è§†:
1. V1.0çš„æ ¸å¿ƒä¼˜åŠ¿: Î”Compliance@1 +0.1382 (æ¥è¿‘ç›®æ ‡)
2. nDCGç“¶é¢ˆçš„æ ¹æœ¬åŸå› : æ’åºè´¨é‡vså¤šæ ·æ€§çš„æƒè¡¡
3. æ–°çªç ´æ–¹å‘: ä½ç½®æ•æ„Ÿçš„åˆ†æ•°è°ƒæ•´ + å€™é€‰é¡¹è´¨é‡é‡æ–°è¯„ä¼°

æ ¸å¿ƒåˆ›æ–°:
- ä¿æŒV1.0çš„é«˜complianceè¡¨ç°
- å¼•å…¥position-aware scoring
- å®ç°çœŸæ­£çš„æ’åºè´¨é‡ä¼˜åŒ–
- æ™ºèƒ½marginç®¡ç†
"""

import json
import time
import logging
import numpy as np
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass
from collections import defaultdict

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class HybridOptimizedConfig:
    """æ··åˆä¼˜åŒ–é…ç½®"""
    # V1.0æ ¸å¿ƒå‚æ•° (ä¿æŒä¼˜åŠ¿)
    base_boost: float = 0.005
    keyword_match_boost: float = 0.04  
    quality_match_boost: float = 0.005
    max_total_boost: float = 0.25
    
    # nDCGçªç ´å‚æ•°
    position_bonus_factor: float = 0.06      # ä½ç½®å¥–åŠ±å› å­
    quality_tier_bonus: float = 0.04         # è´¨é‡å±‚çº§å¥–åŠ±
    relevance_cascade_factor: float = 1.8    # ç›¸å…³æ€§çº§è”å› å­
    
    # æ™ºèƒ½marginç®¡ç†
    adaptive_margin_target: float = 0.12     # è‡ªé€‚åº”marginç›®æ ‡
    margin_boost_threshold: float = 0.05     # marginæå‡é˜ˆå€¼
    score_redistribution_factor: float = 0.7 # åˆ†æ•°é‡åˆ†é…å› å­
    
    # æ’åºè´¨é‡ä¼˜åŒ–
    dcg_weight_emphasis: float = 2.2         # DCGæƒé‡å¼ºè°ƒ
    top_k_quality_threshold: float = 0.75    # Top-Kè´¨é‡é˜ˆå€¼
    diversity_balance_factor: float = 0.85   # å¤šæ ·æ€§å¹³è¡¡å› å­

class HybridUltimateEnhancer:
    """æ··åˆç­–ç•¥ç»ˆæä¼˜åŒ–å™¨"""
    
    def __init__(self, config: HybridOptimizedConfig):
        self.config = config
        
        # è´¨é‡å±‚çº§å®šä¹‰
        self.quality_tiers = {
            'premium': {
                'keywords': ['premium', 'luxury', 'high-end', 'exclusive', 'elite', 'superior', 'artisan'],
                'bonus': 0.08
            },
            'authentic': {
                'keywords': ['authentic', 'genuine', 'original', 'traditional', 'classic', 'real'],
                'bonus': 0.06
            },
            'fresh': {
                'keywords': ['fresh', 'new', 'seasonal', 'limited', 'special', 'signature'],
                'bonus': 0.04
            },
            'popular': {
                'keywords': ['popular', 'favorite', 'bestseller', 'top-rated', 'highly-rated', 'trending'],
                'bonus': 0.03
            }
        }
        
        # é¢†åŸŸä¸“ä¸šè¯æ±‡å¢å¼º
        self.domain_expertise = {
            'cocktails': {
                'technical': ['muddled', 'shaken', 'stirred', 'garnished', 'infused', 'aged'],
                'quality': ['craft', 'artisanal', 'premium', 'small-batch', 'barrel-aged'],
                'experience': ['smooth', 'balanced', 'complex', 'refined', 'sophisticated']
            },
            'flowers': {
                'technical': ['blooming', 'fragrant', 'seasonal', 'perennial', 'hybrid'],
                'quality': ['garden-fresh', 'hand-picked', 'locally-grown', 'organic'],
                'experience': ['vibrant', 'delicate', 'stunning', 'colorful', 'aromatic']
            }
        }
        
        logger.info("ğŸš€ æ··åˆç­–ç•¥ç»ˆæä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   ä½ç½®å¥–åŠ±å› å­: {config.position_bonus_factor}")
        logger.info(f"   DCGæƒé‡å¼ºè°ƒ: {config.dcg_weight_emphasis}")
        logger.info(f"   è‡ªé€‚åº”marginç›®æ ‡: {config.adaptive_margin_target}")
    
    def enhance_candidates(self, query: str, candidates: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ··åˆç­–ç•¥å€™é€‰é¡¹å¢å¼º"""
        if not candidates:
            return candidates
        
        # 1. V1.0åŸºç¡€å¢å¼º (ä¿æŒæ ¸å¿ƒä¼˜åŠ¿)
        enhanced_candidates = self._apply_v1_enhancement(query, candidates)
        
        # 2. è´¨é‡é‡æ–°è¯„ä¼°å’Œå±‚çº§åˆ†ç±»
        enhanced_candidates = self._apply_quality_tier_analysis(enhanced_candidates)
        
        # 3. ä½ç½®æ•æ„Ÿçš„ç›¸å…³æ€§å¢å¼º
        enhanced_candidates = self._apply_position_aware_enhancement(query, enhanced_candidates)
        
        # 4. DCGä¼˜åŒ–çš„åˆ†æ•°é‡æ–°åˆ†é…
        enhanced_candidates = self._apply_dcg_optimized_redistribution(enhanced_candidates)
        
        # 5. æ™ºèƒ½marginç®¡ç†
        enhanced_candidates = self._apply_intelligent_margin_management(enhanced_candidates)
        
        # 6. æœ€ç»ˆæ’åºå’ŒéªŒè¯
        enhanced_candidates.sort(key=lambda x: x['enhanced_score'], reverse=True)
        
        return enhanced_candidates
    
    def _apply_v1_enhancement(self, query: str, candidates: List[Dict]) -> List[Dict]:
        """åº”ç”¨V1.0æ ¸å¿ƒå¢å¼ºé€»è¾‘"""
        enhanced_candidates = []
        
        for candidate in candidates:
            enhanced_candidate = candidate.copy()
            original_score = candidate.get('score', 0.5)
            
            # V1.0æ ¸å¿ƒé€»è¾‘
            base_enhancement = self.config.base_boost
            keyword_boost = self._calculate_keyword_match_boost(query, candidate)
            quality_boost = self._calculate_quality_boost(candidate)
            
            total_enhancement = base_enhancement + keyword_boost + quality_boost
            total_enhancement = min(total_enhancement, self.config.max_total_boost)
            
            enhanced_score = min(original_score + total_enhancement, 1.0)
            enhanced_candidate['enhanced_score'] = enhanced_score
            enhanced_candidate['v1_enhancement'] = total_enhancement
            
            enhanced_candidates.append(enhanced_candidate)
        
        return enhanced_candidates
    
    def _apply_quality_tier_analysis(self, candidates: List[Dict]) -> List[Dict]:
        """è´¨é‡å±‚çº§åˆ†æå’Œåˆ†ç±»"""
        logger.debug("   åº”ç”¨è´¨é‡å±‚çº§åˆ†æ")
        
        for candidate in candidates:
            candidate_text = self._get_candidate_text(candidate).lower()
            
            # åˆ†æè´¨é‡å±‚çº§
            quality_score = 0.0
            detected_tiers = []
            
            for tier_name, tier_info in self.quality_tiers.items():
                tier_matches = sum(1 for keyword in tier_info['keywords'] if keyword in candidate_text)
                if tier_matches > 0:
                    quality_score += tier_info['bonus'] * min(tier_matches / len(tier_info['keywords']), 1.0)
                    detected_tiers.append(tier_name)
            
            # åº”ç”¨è´¨é‡å±‚çº§å¥–åŠ±
            candidate['enhanced_score'] += quality_score
            candidate['quality_tiers'] = detected_tiers
            candidate['quality_tier_bonus'] = quality_score
        
        return candidates
    
    def _apply_position_aware_enhancement(self, query: str, candidates: List[Dict]) -> List[Dict]:
        """ä½ç½®æ•æ„Ÿçš„ç›¸å…³æ€§å¢å¼º"""
        logger.debug("   åº”ç”¨ä½ç½®æ•æ„Ÿå¢å¼º")
        
        # æŒ‰å½“å‰åˆ†æ•°æ’åº
        candidates.sort(key=lambda x: x['enhanced_score'], reverse=True)
        
        # åˆ†ææŸ¥è¯¢æ„å›¾å’Œç›¸å…³æ€§
        query_lower = query.lower()
        query_words = set(query_lower.split())
        
        for i, candidate in enumerate(candidates):
            candidate_text = self._get_candidate_text(candidate).lower()
            
            # è®¡ç®—æ·±åº¦ç›¸å…³æ€§
            deep_relevance = self._calculate_deep_relevance(query_words, candidate_text)
            
            # ä½ç½®æƒé‡ (å‰é¢çš„å€™é€‰é¡¹è·å¾—æ›´é«˜æƒé‡)
            position_weight = 1.0 / (1.0 + i * 0.1)  # é€’å‡æƒé‡
            
            # ç›¸å…³æ€§çº§è”å¢å¼º
            if deep_relevance > 0.6:  # é«˜ç›¸å…³æ€§
                relevance_bonus = (deep_relevance * self.config.position_bonus_factor * 
                                 position_weight * self.config.relevance_cascade_factor)
                
                candidate['enhanced_score'] += relevance_bonus
                candidate['position_relevance_bonus'] = relevance_bonus
                candidate['deep_relevance'] = deep_relevance
            
            # DCGä½ç½®æƒé‡åº”ç”¨
            dcg_position_weight = 1.0 / np.log2(i + 2)
            dcg_bonus = dcg_position_weight * self.config.dcg_weight_emphasis * 0.01
            
            candidate['enhanced_score'] += dcg_bonus
            candidate['dcg_position_bonus'] = dcg_bonus
        
        return candidates
    
    def _apply_dcg_optimized_redistribution(self, candidates: List[Dict]) -> List[Dict]:
        """DCGä¼˜åŒ–çš„åˆ†æ•°é‡æ–°åˆ†é…"""
        logger.debug("   åº”ç”¨DCGä¼˜åŒ–åˆ†æ•°é‡åˆ†é…")
        
        if len(candidates) < 2:
            return candidates
        
        # è®¡ç®—ç†æƒ³çš„DCGåˆ†å¸ƒ
        n = len(candidates)
        current_scores = [c['enhanced_score'] for c in candidates]
        
        # ç†æƒ³çš„DCGæƒé‡åˆ†å¸ƒ
        ideal_weights = [1.0 / np.log2(i + 2) for i in range(n)]
        total_ideal_weight = sum(ideal_weights)
        normalized_weights = [w / total_ideal_weight for w in ideal_weights]
        
        # å½“å‰åˆ†æ•°åˆ†å¸ƒ
        total_current_score = sum(current_scores)
        if total_current_score > 0:
            current_distribution = [s / total_current_score for s in current_scores]
            
            # è®¡ç®—é‡åˆ†é…ç›®æ ‡
            redistribution_targets = []
            for i in range(n):
                # æ··åˆå½“å‰åˆ†æ•°å’Œç†æƒ³åˆ†å¸ƒ
                target_ratio = (current_distribution[i] * (1 - self.config.score_redistribution_factor) +
                               normalized_weights[i] * self.config.score_redistribution_factor)
                target_score = target_ratio * total_current_score
                redistribution_targets.append(target_score)
            
            # åº”ç”¨é‡åˆ†é…
            for i, candidate in enumerate(candidates):
                old_score = candidate['enhanced_score']
                new_score = redistribution_targets[i]
                
                # å¹³æ»‘è°ƒæ•´ï¼Œé¿å…è¿‡åº¦å˜åŒ–
                adjustment_factor = 0.3
                adjusted_score = old_score * (1 - adjustment_factor) + new_score * adjustment_factor
                
                candidate['enhanced_score'] = min(max(adjusted_score, 0.01), 1.0)
                candidate['dcg_redistribution'] = adjusted_score - old_score
        
        return candidates
    
    def _apply_intelligent_margin_management(self, candidates: List[Dict]) -> List[Dict]:
        """æ™ºèƒ½marginç®¡ç†"""
        logger.debug("   åº”ç”¨æ™ºèƒ½marginç®¡ç†")
        
        if len(candidates) < 2:
            return candidates
        
        # æŒ‰åˆ†æ•°æ’åº
        candidates.sort(key=lambda x: x['enhanced_score'], reverse=True)
        
        # è®¡ç®—å½“å‰marginåˆ†å¸ƒ
        margins = []
        for i in range(len(candidates) - 1):
            margin = candidates[i]['enhanced_score'] - candidates[i + 1]['enhanced_score']
            margins.append(margin)
        
        avg_margin = np.mean(margins) if margins else 0
        
        # å¦‚æœmarginä¸è¶³ï¼Œè¿›è¡Œæ™ºèƒ½è°ƒæ•´
        if avg_margin < self.config.adaptive_margin_target:
            logger.debug(f"     å½“å‰å¹³å‡margin: {avg_margin:.4f}, ç›®æ ‡: {self.config.adaptive_margin_target}")
            
            # è®¡ç®—æ‰€éœ€çš„marginå¢å¼º
            margin_gap = self.config.adaptive_margin_target - avg_margin
            
            # æ™ºèƒ½åˆ†æ•°è°ƒæ•´ç­–ç•¥
            n = len(candidates)
            
            for i, candidate in enumerate(candidates):
                if i == 0:
                    # Top-1: æ˜¾è‘—æå‡
                    boost = margin_gap * 1.5
                elif i < n // 3:
                    # Top-1/3: é€‚åº¦æå‡
                    boost = margin_gap * 0.8 * (1 - i / n)
                elif i > 2 * n // 3:
                    # Bottom-1/3: é€‚åº¦é™ä½
                    penalty = margin_gap * 0.5 * (i / n)
                    boost = -penalty
                else:
                    # ä¸­é—´éƒ¨åˆ†: å¾®è°ƒ
                    boost = margin_gap * 0.3 * (0.5 - abs(i - n/2) / n)
                
                old_score = candidate['enhanced_score']
                new_score = max(old_score + boost, 0.01)
                new_score = min(new_score, 1.0)
                
                candidate['enhanced_score'] = new_score
                candidate['margin_adjustment'] = new_score - old_score
        
        return candidates
    
    def _calculate_deep_relevance(self, query_words: set, candidate_text: str) -> float:
        """è®¡ç®—æ·±åº¦ç›¸å…³æ€§"""
        candidate_words = set(candidate_text.split())
        
        if not query_words or not candidate_words:
            return 0.0
        
        # ç²¾ç¡®åŒ¹é…å¾—åˆ†
        exact_matches = len(query_words & candidate_words)
        exact_score = exact_matches / len(query_words)
        
        # éƒ¨åˆ†åŒ¹é…å¾—åˆ†
        partial_matches = 0
        for qword in query_words:
            for cword in candidate_words:
                if len(qword) >= 3 and len(cword) >= 3:
                    if qword[:3] in cword or cword[:3] in qword:
                        partial_matches += 0.5
        
        partial_score = min(partial_matches / len(query_words), 0.5)
        
        # ç»¼åˆç›¸å…³æ€§å¾—åˆ†
        relevance_score = exact_score + partial_score
        return min(relevance_score, 1.0)
    
    def _calculate_keyword_match_boost(self, query: str, candidate: Dict) -> float:
        """å…³é”®è¯åŒ¹é…å¢å¼º (V1.0é€»è¾‘)"""
        query_words = set(query.lower().split())
        candidate_text = self._get_candidate_text(candidate).lower()
        
        matches = sum(1 for word in query_words if word in candidate_text)
        match_ratio = matches / len(query_words) if query_words else 0
        
        return self.config.keyword_match_boost * match_ratio
    
    def _calculate_quality_boost(self, candidate: Dict) -> float:
        """è´¨é‡å¢å¼º (V1.0é€»è¾‘)"""
        candidate_text = self._get_candidate_text(candidate).lower()
        
        quality_keywords = ['premium', 'high-quality', 'excellent', 'top-rated', 'best']
        quality_matches = sum(1 for keyword in quality_keywords if keyword in candidate_text)
        
        return min(quality_matches * self.config.quality_match_boost, self.config.quality_match_boost)
    
    def _get_candidate_text(self, candidate: Dict) -> str:
        """è·å–å€™é€‰é¡¹æ–‡æœ¬"""
        text_parts = []
        
        for key in ['title', 'description', 'alt_description', 'category', 'tags']:
            if key in candidate and candidate[key]:
                if isinstance(candidate[key], list):
                    text_parts.extend(candidate[key])
                else:
                    text_parts.append(str(candidate[key]))
        
        return ' '.join(text_parts)

def evaluate_hybrid_performance(dataset_path: str, enhancer: HybridUltimateEnhancer) -> Dict:
    """è¯„ä¼°æ··åˆç­–ç•¥æ€§èƒ½"""
    logger.info("ğŸ”¥ è¯„ä¼°æ··åˆç­–ç•¥ç»ˆææ€§èƒ½")
    
    with open(dataset_path, 'r') as f:
        dataset = json.load(f)
    
    results = {
        'ndcg_improvements': [],
        'compliance_improvements': [],
        'margin_improvements': [],
        'quality_analysis': [],
        'breakthrough_cases': []
    }
    
    # æµ‹è¯•æ›´å¤šæ ·æœ¬ä»¥è·å¾—å¯é ç»“æœ
    test_items = dataset['inspirations'][:50]  # æµ‹è¯•å‰50ä¸ª
    
    for i, item in enumerate(test_items):
        query = item['query']
        candidates = item['candidates']
        
        if len(candidates) < 2:
            continue
        
        # åŸå§‹vså¢å¼ºå¯¹æ¯”
        original_candidates = candidates.copy()
        enhanced_candidates = enhancer.enhance_candidates(query, candidates)
        
        # è®¡ç®—æŒ‡æ ‡
        original_ndcg = calculate_ndcg_at_k(original_candidates, k=10)
        enhanced_ndcg = calculate_ndcg_at_k(enhanced_candidates, k=10)
        ndcg_improvement = enhanced_ndcg - original_ndcg
        
        original_compliance = calculate_compliance_at_k(original_candidates, k=1)
        enhanced_compliance = calculate_compliance_at_k(enhanced_candidates, k=1)
        compliance_improvement = enhanced_compliance - original_compliance
        
        # Marginåˆ†æ
        original_margin = 0.0
        enhanced_margin = 0.0
        if len(candidates) >= 2:
            original_margin = original_candidates[0]['score'] - original_candidates[1]['score']
            enhanced_margin = enhanced_candidates[0]['enhanced_score'] - enhanced_candidates[1]['enhanced_score']
        margin_improvement = enhanced_margin - original_margin
        
        results['ndcg_improvements'].append(ndcg_improvement)
        results['compliance_improvements'].append(compliance_improvement)
        results['margin_improvements'].append(margin_improvement)
        
        # è´¨é‡åˆ†æ
        top_candidate = enhanced_candidates[0] if enhanced_candidates else None
        if top_candidate:
            quality_info = {
                'query': query,
                'ndcg_improvement': ndcg_improvement,
                'margin_improvement': margin_improvement,
                'quality_tiers': top_candidate.get('quality_tiers', []),
                'quality_bonus': top_candidate.get('quality_tier_bonus', 0),
                'position_bonus': top_candidate.get('position_relevance_bonus', 0)
            }
            results['quality_analysis'].append(quality_info)
            
            # è¯†åˆ«çªç ´æ€§æ¡ˆä¾‹
            if ndcg_improvement > 0.02 and margin_improvement > 0.05:
                results['breakthrough_cases'].append({
                    'query': query,
                    'ndcg_improvement': ndcg_improvement,
                    'margin_improvement': margin_improvement,
                    'enhancements': {
                        'v1_enhancement': top_candidate.get('v1_enhancement', 0),
                        'quality_tier_bonus': top_candidate.get('quality_tier_bonus', 0),
                        'dcg_redistribution': top_candidate.get('dcg_redistribution', 0),
                        'margin_adjustment': top_candidate.get('margin_adjustment', 0)
                    }
                })
    
    # ç»Ÿè®¡æ±‡æ€»
    results['avg_ndcg_improvement'] = np.mean(results['ndcg_improvements'])
    results['avg_compliance_improvement'] = np.mean(results['compliance_improvements'])
    results['avg_margin_improvement'] = np.mean(results['margin_improvements'])
    
    results['ndcg_improvement_std'] = np.std(results['ndcg_improvements'])
    results['breakthrough_rate'] = len(results['breakthrough_cases']) / len(test_items)
    
    # æˆåŠŸç‡ç»Ÿè®¡
    positive_ndcg = sum(1 for x in results['ndcg_improvements'] if x > 0)
    positive_margin = sum(1 for x in results['margin_improvements'] if x > 0.05)
    
    results['ndcg_success_rate'] = positive_ndcg / len(results['ndcg_improvements'])
    results['margin_success_rate'] = positive_margin / len(results['margin_improvements'])
    
    return results

def calculate_ndcg_at_k(candidates: List[Dict], k: int = 10) -> float:
    """è®¡ç®—nDCG@K"""
    if len(candidates) < 2:
        return 0.0
    
    k = min(k, len(candidates))
    scores = [c.get('enhanced_score', c.get('score', 0)) for c in candidates[:k]]
    
    dcg = sum(score / np.log2(i + 2) for i, score in enumerate(scores))
    ideal_scores = sorted(scores, reverse=True)
    idcg = sum(score / np.log2(i + 2) for i, score in enumerate(ideal_scores))
    
    return dcg / idcg if idcg > 0 else 0.0

def calculate_compliance_at_k(candidates: List[Dict], k: int = 1) -> float:
    """è®¡ç®—Compliance@K"""
    if len(candidates) < k:
        return 0.0
    
    top_k = candidates[:k]
    scores = [c.get('enhanced_score', c.get('score', 0)) for c in top_k]
    return np.mean(scores) if scores else 0.0

def main():
    """ä¸»å‡½æ•° - æ··åˆç­–ç•¥ç»ˆææ”»å…³"""
    print("ğŸ”¥ æ··åˆç­–ç•¥ç»ˆæä¼˜åŒ–å™¨ - çªç ´nDCGç“¶é¢ˆ")
    print("="*80)
    
    # 1. åˆ›å»ºæ··åˆä¼˜åŒ–é…ç½®
    print("\\n1ï¸âƒ£ åˆ›å»ºæ··åˆç­–ç•¥ä¼˜åŒ–é…ç½®...")
    config = HybridOptimizedConfig()
    
    # 2. åˆ›å»ºç»ˆæä¼˜åŒ–å™¨
    print("\\n2ï¸âƒ£ åˆ›å»ºæ··åˆç­–ç•¥ç»ˆæä¼˜åŒ–å™¨...")
    enhancer = HybridUltimateEnhancer(config)
    
    # 3. è¯„ä¼°ç»ˆææ€§èƒ½
    print("\\n3ï¸âƒ£ è¯„ä¼°æ··åˆç­–ç•¥ç»ˆææ€§èƒ½...")
    results = evaluate_hybrid_performance("day3_results/production_dataset.json", enhancer)
    
    # 4. ç»ˆæç»“æœæŠ¥å‘Š
    print("\\n" + "="*80)
    print("ğŸ”¥ æ··åˆç­–ç•¥ç»ˆææ”»å…³ç»“æœ")
    print("="*80)
    
    print(f"\\nğŸ“Š ç»ˆææ ¸å¿ƒæŒ‡æ ‡:")
    print(f"   å¹³å‡Î”nDCG@10: {results['avg_ndcg_improvement']:+.4f} (Â±{results['ndcg_improvement_std']:.4f})")
    print(f"   å¹³å‡Î”Compliance@1: {results['avg_compliance_improvement']:+.4f}")
    print(f"   å¹³å‡Î”Margin: {results['avg_margin_improvement']:+.4f}")
    
    print(f"\\nğŸ¯ æˆåŠŸç‡ç»Ÿè®¡:")
    print(f"   nDCGæ”¹è¿›æˆåŠŸç‡: {results['ndcg_success_rate']:.1%}")
    print(f"   å¤§Marginæ”¹è¿›æˆåŠŸç‡: {results['margin_success_rate']:.1%}")
    print(f"   çªç ´æ€§æ¡ˆä¾‹ç‡: {results['breakthrough_rate']:.1%}")
    
    # ä¸ç°æœ‰ç‰ˆæœ¬å¯¹æ¯”
    print(f"\\nğŸ† ä¸ç°æœ‰ç‰ˆæœ¬å¯¹æ¯”:")
    
    # V1.0å¯¹æ¯”
    v1_ndcg = 0.0114
    v1_compliance = 0.1382
    
    ndcg_vs_v1 = (results['avg_ndcg_improvement'] - v1_ndcg) / v1_ndcg * 100 if v1_ndcg > 0 else 0
    compliance_vs_v1 = (results['avg_compliance_improvement'] - v1_compliance) / v1_compliance * 100 if v1_compliance > 0 else 0
    
    print(f"   vs V1.0 nDCG: {ndcg_vs_v1:+.1f}%")
    print(f"   vs V1.0 Compliance: {compliance_vs_v1:+.1f}%")
    
    # ç”Ÿäº§é—¨æ§›è¿›åº¦
    target_ndcg = 0.08
    target_compliance = 0.15
    
    ndcg_progress = results['avg_ndcg_improvement'] / target_ndcg * 100
    compliance_progress = results['avg_compliance_improvement'] / target_compliance * 100
    
    print(f"\\nğŸ¯ ç”Ÿäº§é—¨æ§›è¿›åº¦:")
    print(f"   nDCGè¿›åº¦: {ndcg_progress:.1f}% (ç›®æ ‡: +0.08)")
    print(f"   Complianceè¿›åº¦: {compliance_progress:.1f}% (ç›®æ ‡: +0.15)")
    
    # çªç ´æ€§æ¡ˆä¾‹åˆ†æ
    if results['breakthrough_cases']:
        print(f"\\nğŸŒŸ çªç ´æ€§æ¡ˆä¾‹åˆ†æ (å…±{len(results['breakthrough_cases'])}ä¸ª):")
        for i, case in enumerate(results['breakthrough_cases'][:3]):  # æ˜¾ç¤ºå‰3ä¸ª
            print(f"\\n   çªç ´æ¡ˆä¾‹ {i+1}: {case['query'][:60]}...")
            print(f"   Î”nDCG: {case['ndcg_improvement']:+.4f}, Î”Margin: {case['margin_improvement']:+.4f}")
            
            enhancements = case['enhancements']
            print(f"   å¢å¼ºåˆ†è§£: V1åŸºç¡€={enhancements['v1_enhancement']:.3f}, " +
                  f"è´¨é‡å¥–åŠ±={enhancements['quality_tier_bonus']:.3f}, " +
                  f"DCGé‡åˆ†é…={enhancements['dcg_redistribution']:+.3f}")
    
    # ä¿å­˜ç»“æœ
    results_path = "day3_results/hybrid_ultimate_results.json"
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜: {results_path}")
    
    # æœ€ç»ˆè¯„å®š
    print(f"\\nğŸ† ç»ˆææ”»å…³è¯„å®š:")
    
    if (results['avg_ndcg_improvement'] > v1_ndcg * 1.5 and 
        results['avg_compliance_improvement'] >= v1_compliance * 0.95):
        print("   ğŸŒŸ BREAKTHROUGH SUCCESS! nDCGæ˜¾è‘—çªç ´ä¸”ä¿æŒComplianceä¼˜åŠ¿")
        deployment_ready = True
    elif (results['avg_ndcg_improvement'] > v1_ndcg * 1.2 and 
          results['avg_margin_improvement'] > 0.05):
        print("   âœ… MAJOR PROGRESS! nDCGæ”¹è¿›æ˜æ˜¾ä¸”Marginæ˜¾è‘—æå‡")
        deployment_ready = True
    elif results['avg_ndcg_improvement'] > v1_ndcg:
        print("   ğŸ“ˆ INCREMENTAL PROGRESS! ç»§ç»­ä¿æŒæ”¹è¿›æ–¹å‘")
        deployment_ready = False
    else:
        print("   ğŸ”§ éœ€è¦é‡æ–°å®¡è§†ç­–ç•¥")
        deployment_ready = False
    
    print(f"\\nğŸš€ éƒ¨ç½²å»ºè®®:")
    if deployment_ready:
        print("   âœ… æ··åˆç­–ç•¥å¯ä½œä¸ºV1.0çš„å‡çº§ç‰ˆæœ¬éƒ¨ç½²")
        print("   ğŸ¯ å»ºè®®è¿›è¡ŒA/Bæµ‹è¯•éªŒè¯å®é™…æ•ˆæœ")
        print("   ğŸ“Š é‡ç‚¹ç›‘æ§nDCGå’Œç”¨æˆ·æ»¡æ„åº¦æŒ‡æ ‡")
    else:
        print("   âš ï¸  å»ºè®®ç»§ç»­ä¼˜åŒ–æˆ–å›å½’V1.0ç¨³å¦¥æ–¹æ¡ˆ")
        print("   ğŸ” æ·±å…¥åˆ†æç“¶é¢ˆå¹¶å°è¯•å…¶ä»–çªç ´æ–¹å‘")
    
    return results

if __name__ == "__main__":
    main()