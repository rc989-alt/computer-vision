{
  "ndcg_improvements": [
    0.002854135498321697,
    0.016654843544153364,
    0.021367107733177515,
    0.009980897268568434,
    0.008057812659300168,
    0.013135536508013801,
    0.01420106621781514,
    0.01874053189964897,
    0.022383114544650362,
    0.015311286893382126,
    0.007933601267663848,
    0.01954951807401073,
    0.008117143107541969,
    0.006787283067195782,
    0.00804571321287828,
    0.012341767699928341,
    0.01220608317719496,
    0.0016967811723102022,
    0.009386846554843897,
    0.00959399812198991,
    0.012316896565648716,
    0.004388073357966649,
    0.012530138491058662,
    0.0030953190513827167,
    0.011540846829620643,
    0.0021898871977867884,
    0.0049432828066448,
    0.016061196403087008,
    0.011056214997115399,
    0.011437740656215167
  ],
  "compliance_improvements": [
    0.055499999999999994,
    0.1372,
    0.13629999999999998,
    0.12360000000000004,
    0.07869999999999999,
    0.12880000000000003,
    0.09079999999999999,
    0.14680000000000004,
    0.14170000000000005,
    0.11180000000000001,
    0.08189999999999997,
    0.1371,
    0.08830000000000005,
    0.08279999999999998,
    0.0927,
    0.08850000000000002,
    0.10029999999999994,
    0.06399999999999995,
    0.1089,
    0.06440000000000001,
    0.11809999999999998,
    0.06430000000000002,
    0.11619999999999997,
    0.07110000000000005,
    0.11229999999999996,
    0.06420000000000003,
    0.09909999999999997,
    0.11739999999999995,
    0.10550000000000004,
    0.1129
  ],
  "margin_improvements": [
    -0.02388027872768783,
    0.08336268827680471,
    0.02030947872436506,
    0.09799633036104316,
    -0.0035548056581143905,
    0.051265546998240596,
    0.006694408714594924,
    0.09578760194685332,
    0.06066039963956693,
    0.03671893253291747,
    0.039758286261944775,
    0.04466488607379804,
    0.05122936409689427,
    0.028060939251792316,
    0.05470573493848252,
    0.008082877943418554,
    0.05358707785998318,
    0.04570989100488421,
    0.04964600494795457,
    -0.0393286559925361,
    0.04092686806114476,
    0.012869237457625693,
    0.019478063412844415,
    0.021196846047705442,
    0.084420429608142,
    -0.0008247526980859066,
    0.036852482922757335,
    0.030927424340364107,
    -0.0029259702333305215,
    0.04190777398821366
  ],
  "detailed_analysis": [
    {
      "query": "pink floral cocktail",
      "original_ndcg": 0.9971458645016783,
      "enhanced_ndcg": 1.0,
      "ndcg_improvement": 0.002854135498321697,
      "original_margin": 0.05600000000000005,
      "enhanced_margin": 0.03211972127231222,
      "margin_improvement": -0.02388027872768783,
      "top_candidate_features": {
        "query_length": 0.3,
        "candidate_length": 0.65,
        "edit_distance": 0.75,
        "tfidf": 0.674967307062827,
        "semantic": 0.0,
        "total_ltr_score": 0.040124182676570676
      }
    },
    {
      "query": "golden whiskey cocktail",
      "original_ndcg": 0.9833451564558466,
      "enhanced_ndcg": 1.0,
      "ndcg_improvement": 0.016654843544153364,
      "original_margin": -0.048899999999999944,
      "enhanced_margin": 0.034462688276804765,
      "margin_improvement": 0.08336268827680471,
      "top_candidate_features": {
        "query_length": 0.3,
        "candidate_length": 0.65,
        "edit_distance": 0.75,
        "tfidf": 0.674967307062827,
        "semantic": 0.0,
        "total_ltr_score": 0.040124182676570676
      }
    },
    {
      "query": "blue martini glass",
      "original_ndcg": 0.9786328922668225,
      "enhanced_ndcg": 1.0,
      "ndcg_improvement": 0.021367107733177515,
      "original_margin": 0.012600000000000056,
      "enhanced_margin": 0.032909478724365115,
      "margin_improvement": 0.02030947872436506,
      "top_candidate_features": {
        "query_length": 0.3,
        "candidate_length": 0.65,
        "edit_distance": 0.75,
        "tfidf": 0.5431254465935684,
        "semantic": 0.0,
        "total_ltr_score": 0.03682813616483921
      }
    },
    {
      "query": "clear gin fizz",
      "original_ndcg": 0.9900191027314316,
      "enhanced_ndcg": 1.0,
      "ndcg_improvement": 0.009980897268568434,
      "original_margin": -0.07210000000000005,
      "enhanced_margin": 0.025896330361043107,
      "margin_improvement": 0.09799633036104316,
      "top_candidate_features": {
        "query_length": 0.3,
        "candidate_length": 0.65,
        "edit_distance": 0.75,
        "tfidf": 0.44108109139123086,
        "semantic": 0.0,
        "total_ltr_score": 0.03427702728478077
      }
    },
    {
      "query": "amber old fashioned",
      "original_ndcg": 0.9919421873406998,
      "enhanced_ndcg": 1.0,
      "ndcg_improvement": 0.008057812659300168,
      "original_margin": 0.053200000000000025,
      "enhanced_margin": 0.049645194341885635,
      "margin_improvement": -0.0035548056581143905,
      "top_candidate_features": {
        "query_length": 0.3,
        "candidate_length": 0.65,
        "edit_distance": 0.75,
        "tfidf": 0.44108109139123086,
        "semantic": 0.0,
        "total_ltr_score": 0.03427702728478077
      }
    }
  ],
  "avg_ndcg_improvement": 0.010930155485970535,
  "avg_compliance_improvement": 0.10137333333333333,
  "avg_margin_improvement": 0.03487683707008604,
  "ndcg_improvement_std": 0.005479027685775104,
  "ndcg_improvement_success_rate": 1.0,
  "large_margin_success_rate": 0.0
}