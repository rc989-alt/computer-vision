#!/usr/bin/env python3
"""
CoTRR-Stable Stage 1 Task T005: Step5é›†æˆæ¥å£å®ç°
å®ç°ä¸ç°æœ‰Step5ç³»ç»Ÿçš„æ— ç¼é›†æˆæ¥å£

å…³é”®ç‰¹æ€§:
1. ç”Ÿäº§å°±ç»ªé›†æˆ: æ— ç¼æ›¿æ¢ç°æœ‰Step5é€»è¾‘
2. Top-Mç­–ç•¥: åªå¯¹å‰20ä¸ªå€™é€‰ä½¿ç”¨å¤æ‚æ¨¡å‹
3. æ€§èƒ½ä¼˜åŒ–: GPUç¼–è¯‘ä¼˜åŒ– + æ··åˆç²¾åº¦æ¨ç†
4. ç›‘æ§æ”¯æŒ: å®æ—¶æ€§èƒ½ç»Ÿè®¡å’Œé”™è¯¯å¤„ç†
5. A/Bæµ‹è¯•æ¥å£: æ”¯æŒShadowæ¨¡å¼å’Œæ¸è¿›ä¸Šçº¿
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.amp import autocast
import numpy as np
import json
import time
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, asdict
from datetime import datetime
import pickle
import os
import warnings

# å¯¼å…¥ä¹‹å‰å®ç°çš„ç»„ä»¶
import sys
sys.path.append('/Users/guyan/computer_vision/computer-vision')
from research.src.cotrr_stable import StableCrossAttnReranker, StableConfig
from research.src.isotonic_calibration import IsotonicCalibrator

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class IntegrationConfig:
    """é›†æˆé…ç½®"""
    # æ¨¡å‹é…ç½®
    model_path: str = "research/stage1_progress/best_model.pt"
    calibrator_path: str = "research/stage1_progress/calibrator.pkl"
    
    # æ¨ç†é…ç½®
    device: str = 'auto'
    top_m: int = 20
    enable_compilation: bool = True
    mixed_precision: bool = True
    batch_inference: bool = True
    max_batch_size: int = 32
    
    # A/Bæµ‹è¯•é…ç½®
    shadow_mode: bool = False
    rollout_percentage: float = 100.0
    fallback_enabled: bool = True
    
    # ç›‘æ§é…ç½®
    enable_monitoring: bool = True
    log_predictions: bool = False
    performance_logging: bool = True

class CoTRRStableStep5Integration:
    """
    CoTRR-Stableä¸Step5çš„å®Œæ•´é›†æˆæ¥å£
    æ”¯æŒç”Ÿäº§ç¯å¢ƒçš„æ— ç¼æ›¿æ¢å’ŒA/Bæµ‹è¯•
    """
    
    def __init__(self, config: IntegrationConfig):
        self.config = config
        self.device = self._setup_device(config.device)
        
        # åŠ è½½æ¨¡å‹
        self.model = self._load_model()
        
        # åŠ è½½æ ¡å‡†å™¨
        self.calibrator = self._load_calibrator()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'total_queries': 0,
            'reranked_queries': 0,
            'fallback_queries': 0,
            'avg_inference_time': 0.0,
            'avg_candidates_per_query': 0.0,
            'error_count': 0,
            'last_error': None,
            'throughput_per_second': 0.0
        }
        
        # é¢„çƒ­æ¨¡å‹
        self._warmup_model()
        
        logger.info(f"ğŸš€ CoTRR-Stableé›†æˆæ¥å£åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   è®¾å¤‡: {self.device}")
        logger.info(f"   Top-Mç­–ç•¥: {config.top_m}")
        logger.info(f"   Shadowæ¨¡å¼: {config.shadow_mode}")
        logger.info(f"   Rolloutæ¯”ä¾‹: {config.rollout_percentage}%")
    
    def _setup_device(self, device: str) -> torch.device:
        """æ™ºèƒ½è®¾å¤‡é…ç½®"""
        if device == 'auto':
            if torch.cuda.is_available():
                device_obj = torch.device('cuda')
                logger.info(f"ğŸ”¥ CUDAè®¾å¤‡: {torch.cuda.get_device_name()}")
            elif torch.backends.mps.is_available():
                device_obj = torch.device('mps')
                logger.info("ğŸ Apple Silicon MPS")
            else:
                device_obj = torch.device('cpu')
                logger.info("ğŸ’» CPUè®¾å¤‡")
        else:
            device_obj = torch.device(device)
        
        return device_obj
    
    def _load_model(self) -> nn.Module:
        """åŠ è½½å’Œä¼˜åŒ–æ¨¡å‹"""
        try:
            if os.path.exists(self.config.model_path):
                checkpoint = torch.load(self.config.model_path, map_location=self.device)
                
                # æ¢å¤é…ç½®å’Œæ¨¡å‹
                model_config = checkpoint.get('config', {})
                if isinstance(model_config, dict):
                    config = StableConfig(**model_config)
                else:
                    config = StableConfig()
                
                model = StableCrossAttnReranker(config)
                model.load_state_dict(checkpoint['model_state_dict'])
                logger.info(f"ğŸ“‚ æ¨¡å‹åŠ è½½æˆåŠŸ: {self.config.model_path}")
            else:
                logger.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.config.model_path}ï¼Œä½¿ç”¨é»˜è®¤åˆå§‹åŒ–")
                config = StableConfig()
                model = StableCrossAttnReranker(config)
            
            model.to(self.device)
            model.eval()
            
            # ç¼–è¯‘ä¼˜åŒ– - æš‚æ—¶ç¦ç”¨ä»¥ç¡®ä¿æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸
            if False and self.config.enable_compilation and hasattr(torch, 'compile'):
                try:
                    model = torch.compile(model, backend="inductor")
                    logger.info("âš¡ æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–å¯ç”¨")
                except Exception as e:
                    logger.warning(f"æ¨¡å‹ç¼–è¯‘å¤±è´¥: {e}")
            
            return model
            
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤æ¨¡å‹ä½œä¸ºfallback
            config = StableConfig()
            model = StableCrossAttnReranker(config)
            model.to(self.device)
            model.eval()
            return model
    
    def _load_calibrator(self) -> Optional[IsotonicCalibrator]:
        """åŠ è½½æ ¡å‡†å™¨"""
        try:
            if os.path.exists(self.config.calibrator_path):
                calibrator = IsotonicCalibrator()
                calibrator.load(self.config.calibrator_path)
                logger.info(f"ğŸ“‚ æ ¡å‡†å™¨åŠ è½½æˆåŠŸ: {self.config.calibrator_path}")
                return calibrator
            else:
                logger.warning(f"æ ¡å‡†å™¨æ–‡ä»¶ä¸å­˜åœ¨: {self.config.calibrator_path}ï¼Œå°†ä½¿ç”¨åŸå§‹åˆ†æ•°")
                return None
        except Exception as e:
            logger.error(f"æ ¡å‡†å™¨åŠ è½½å¤±è´¥: {e}")
            return None
    
    def _warmup_model(self):
        """æ¨¡å‹é¢„çƒ­ - æé«˜åˆæ¬¡æ¨ç†é€Ÿåº¦"""
        try:
            logger.info("ğŸ”¥ æ¨¡å‹é¢„çƒ­ä¸­...")
            
            # åˆ›å»ºé¢„çƒ­æ•°æ® - ä½¿ç”¨æ­£ç¡®çš„ç»´åº¦
            dummy_batch = {
                'clip_img': torch.randn(1, 1024).to(self.device),
                'clip_text': torch.randn(1, 1024).to(self.device),
                'visual_features': torch.randn(1, 8).to(self.device),     # 8ç»´ (matching config)
                'conflict_features': torch.randn(1, 5).to(self.device)    # 5ç»´ (matching config)
            }
            
            # é¢„çƒ­æ¨ç†
            with torch.no_grad():
                for _ in range(3):
                    _ = self.model(**dummy_batch)
            
            logger.info("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"æ¨¡å‹é¢„çƒ­å¤±è´¥: {e}")
    
    def rerank_candidates(self, 
                         query_data: Dict[str, Any],
                         candidates: List[Dict[str, Any]],
                         options: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        é‡æ’åºå€™é€‰ç»“æœ - Step5å…¼å®¹æ¥å£
        
        Args:
            query_data: æŸ¥è¯¢ä¿¡æ¯
            candidates: å€™é€‰åˆ—è¡¨
            options: é™„åŠ é€‰é¡¹ {'return_scores', 'force_rerank', 'debug_mode'}
        
        Returns:
            {
                'candidates': é‡æ’åºåçš„å€™é€‰åˆ—è¡¨,
                'metadata': å…ƒä¿¡æ¯ (æ¨ç†æ—¶é—´ã€ä½¿ç”¨çš„ç­–ç•¥ç­‰),
                'debug_info': è°ƒè¯•ä¿¡æ¯ (å¦‚æœå¯ç”¨)
            }
        """
        start_time = time.time()
        options = options or {}
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats['total_queries'] += 1
        
        try:
            # A/Bæµ‹è¯•å†³ç­–
            if not self._should_rerank(query_data):
                return self._fallback_response(candidates, 'ab_test_skip')
            
            # åŸºæœ¬æ£€æŸ¥
            if len(candidates) <= 1:
                return self._create_response(candidates, 'insufficient_candidates', start_time)
            
            # Top-Mç­–ç•¥
            top_candidates = candidates[:min(len(candidates), self.config.top_m)]
            remaining_candidates = candidates[self.config.top_m:] if len(candidates) > self.config.top_m else []
            
            if len(top_candidates) <= 1:
                return self._create_response(candidates, 'top_m_insufficient', start_time)
            
            # æ‰§è¡Œé‡æ’åº
            reranked_top = self._execute_reranking(top_candidates, options)
            
            # åˆå¹¶ç»“æœ
            final_candidates = reranked_top + remaining_candidates
            
            # æ·»åŠ å…ƒä¿¡æ¯
            if options.get('return_scores', False):
                final_candidates = self._add_score_metadata(final_candidates, reranked_top)
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats['reranked_queries'] += 1
            self._update_performance_stats(start_time, len(candidates))
            
            return self._create_response(final_candidates, 'success', start_time, {
                'reranked_count': len(reranked_top),
                'total_count': len(candidates),
                'strategy': 'top_m_rerank'
            })
            
        except Exception as e:
            logger.error(f"é‡æ’åºå¤±è´¥: {e}")
            self.stats['error_count'] += 1
            self.stats['last_error'] = str(e)
            
            if self.config.fallback_enabled:
                return self._fallback_response(candidates, f'error: {e}')
            else:
                raise
    
    def _should_rerank(self, query_data: Dict[str, Any]) -> bool:
        """A/Bæµ‹è¯•å†³ç­–é€»è¾‘"""
        if self.config.shadow_mode:
            return False  # Shadowæ¨¡å¼ä¸‹ä¸å®é™…é‡æ’åº
        
        # åŸºäºrolloutæ¯”ä¾‹å†³ç­–
        import hashlib
        query_id = query_data.get('query_id', 'unknown')
        hash_value = int(hashlib.md5(query_id.encode()).hexdigest()[:8], 16)
        percentage = (hash_value % 100) + 1
        
        return percentage <= self.config.rollout_percentage
    
    def _execute_reranking(self, candidates: List[Dict], options: Dict) -> List[Dict]:
        """æ‰§è¡Œæ ¸å¿ƒé‡æ’åºé€»è¾‘"""
        # æå–ç‰¹å¾
        features = self._extract_features(candidates)
        
        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            if self.config.mixed_precision and self.device.type in ['cuda', 'mps']:
                with autocast(device_type=self.device.type if self.device.type != 'mps' else 'cpu', dtype=torch.float16, enabled=self.device.type != 'mps'):
                    scores = self._model_inference(features)
            else:
                scores = self._model_inference(features)
        
        # æ¦‚ç‡æ ¡å‡†
        if self.calibrator is not None:
            calibrated_scores = self.calibrator.predict(scores.cpu().numpy())
            scores = torch.tensor(calibrated_scores, device=scores.device)
        
        # é‡æ’åº
        sorted_indices = torch.argsort(scores, descending=True)
        reranked_candidates = [candidates[i] for i in sorted_indices.cpu().tolist()]
        
        # æ·»åŠ åˆ†æ•°ä¿¡æ¯
        for i, candidate in enumerate(reranked_candidates):
            original_idx = sorted_indices[i].item()
            candidate['_cotrr_score'] = float(scores[original_idx])
            candidate['_cotrr_rank'] = i + 1
            candidate['_original_rank'] = original_idx + 1
        
        return reranked_candidates
    
    def _extract_features(self, candidates: List[Dict]) -> Dict[str, torch.Tensor]:
        """ç‰¹å¾æå–å’Œé¢„å¤„ç†"""
        text_features = []
        image_features = []
        
        for candidate in candidates:
            # æå–æ–‡æœ¬ç‰¹å¾ - æ‰©å±•åˆ°1024ç»´ä»¥åŒ¹é…CLIP
            text_feat = candidate.get('text_features', candidate.get('text_embedding', np.zeros(256)))
            if isinstance(text_feat, list):
                text_feat = np.array(text_feat)
            elif text_feat is None:
                text_feat = np.zeros(256)
            
            # æ‰©å±•åˆ°1024ç»´
            if text_feat.shape[0] == 256:
                text_feat = np.concatenate([text_feat, np.zeros(768)])  # 256 + 768 = 1024
            elif text_feat.shape[0] != 1024:
                text_feat = np.resize(text_feat, 1024)
            
            # æå–å›¾åƒç‰¹å¾ - æ‰©å±•åˆ°1024ç»´ä»¥åŒ¹é…CLIP
            image_feat = candidate.get('image_features', candidate.get('image_embedding', np.zeros(256)))
            if isinstance(image_feat, list):
                image_feat = np.array(image_feat)
            elif image_feat is None:
                image_feat = np.zeros(256)
            
            # æ‰©å±•åˆ°1024ç»´
            if image_feat.shape[0] == 256:
                image_feat = np.concatenate([image_feat, np.zeros(768)])  # 256 + 768 = 1024
            elif image_feat.shape[0] != 1024:
                image_feat = np.resize(image_feat, 1024)
            
            # ç‰¹å¾æ ‡å‡†åŒ–
            text_feat = text_feat / (np.linalg.norm(text_feat) + 1e-8)
            image_feat = image_feat / (np.linalg.norm(image_feat) + 1e-8)
            
            text_features.append(text_feat)
            image_features.append(image_feat)
        
        return {
            'text_features': torch.tensor(np.array(text_features), dtype=torch.float32).unsqueeze(0).to(self.device),
            'image_features': torch.tensor(np.array(image_features), dtype=torch.float32).unsqueeze(0).to(self.device)
        }
    
    def _model_inference(self, features: Dict[str, torch.Tensor]) -> torch.Tensor:
        """æ¨¡å‹æ¨ç†"""
        batch_size, num_candidates, feature_dim = features['text_features'].shape
        
        # Reshapeä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
        clip_text = features['text_features'].view(-1, feature_dim)  # [batch*candidates, 1024]
        clip_img = features['image_features'].view(-1, feature_dim)   # [batch*candidates, 1024]
        
        # åˆ›å»ºè§†è§‰å’Œå†²çªç‰¹å¾ - ä½¿ç”¨åˆé€‚çš„ç»´åº¦
        visual_features = torch.zeros(clip_img.size(0), 8, device=self.device)      # 8ç»´ (matching config)
        conflict_features = torch.zeros(clip_img.size(0), 5, device=self.device)    # 5ç»´ (matching config)
        
        # å‰å‘ä¼ æ’­
        result = self.model(clip_img, clip_text, visual_features, conflict_features)
        scores = result['logits'].view(batch_size, num_candidates).squeeze(0)
        
        return scores
    
    def _fallback_response(self, candidates: List[Dict], reason: str) -> Dict[str, Any]:
        """Fallbackå“åº”"""
        self.stats['fallback_queries'] += 1
        
        return self._create_response(candidates, 'fallback', time.time(), {
            'reason': reason,
            'strategy': 'fallback'
        })
    
    def _create_response(self, candidates: List[Dict], status: str, start_time: float, extra_metadata: Dict = None) -> Dict[str, Any]:
        """åˆ›å»ºæ ‡å‡†å“åº”"""
        inference_time = time.time() - start_time
        
        metadata = {
            'status': status,
            'inference_time': inference_time,
            'candidate_count': len(candidates),
            'timestamp': datetime.now().isoformat()
        }
        
        if extra_metadata:
            metadata.update(extra_metadata)
        
        return {
            'candidates': candidates,
            'metadata': metadata
        }
    
    def _add_score_metadata(self, final_candidates: List[Dict], reranked_top: List[Dict]) -> List[Dict]:
        """æ·»åŠ åˆ†æ•°å…ƒä¿¡æ¯"""
        for i, candidate in enumerate(final_candidates):
            if i < len(reranked_top) and '_cotrr_score' in reranked_top[i]:
                candidate['cotrr_score'] = reranked_top[i]['_cotrr_score']
                candidate['cotrr_rank'] = reranked_top[i]['_cotrr_rank']
                candidate['original_rank'] = reranked_top[i]['_original_rank']
        
        return final_candidates
    
    def _update_performance_stats(self, start_time: float, candidate_count: int):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        inference_time = time.time() - start_time
        
        # æ›´æ–°å¹³å‡æ¨ç†æ—¶é—´
        n = self.stats['reranked_queries']
        self.stats['avg_inference_time'] = (
            self.stats['avg_inference_time'] * (n - 1) + inference_time
        ) / n
        
        # æ›´æ–°å¹³å‡å€™é€‰æ•°
        self.stats['avg_candidates_per_query'] = (
            self.stats['avg_candidates_per_query'] * (n - 1) + candidate_count
        ) / n
        
        # æ›´æ–°ååé‡
        if inference_time > 0:
            self.stats['throughput_per_second'] = candidate_count / inference_time
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        stats = self.stats.copy()
        
        # è®¡ç®—è¡ç”ŸæŒ‡æ ‡
        if stats['total_queries'] > 0:
            stats['rerank_rate'] = stats['reranked_queries'] / stats['total_queries']
            stats['fallback_rate'] = stats['fallback_queries'] / stats['total_queries']
            stats['error_rate'] = stats['error_count'] / stats['total_queries']
        else:
            stats['rerank_rate'] = 0.0
            stats['fallback_rate'] = 0.0
            stats['error_rate'] = 0.0
        
        return stats
    
    def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æµ‹è¯•æ¨ç†
            dummy_candidates = [{
                'candidate_id': 'test',
                'text_features': np.random.randn(256).tolist(),
                'image_features': np.random.randn(256).tolist()
            }]
            
            result = self.rerank_candidates(
                {'query_id': 'health_check'}, 
                dummy_candidates
            )
            
            return {
                'status': 'healthy',
                'model_loaded': True,
                'calibrator_loaded': self.calibrator is not None,
                'device': str(self.device),
                'last_inference_time': result['metadata']['inference_time']
            }
            
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e),
                'model_loaded': hasattr(self, 'model'),
                'calibrator_loaded': self.calibrator is not None,
                'device': str(self.device)
            }

def test_step5_integration():
    """å…¨é¢æµ‹è¯•Step5é›†æˆæ¥å£"""
    logger.info("ğŸ§ª å¼€å§‹å…¨é¢æµ‹è¯•Step5é›†æˆæ¥å£")
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    config = IntegrationConfig(
        model_path="nonexistent_model.pt",  # ä½¿ç”¨é»˜è®¤æ¨¡å‹
        calibrator_path="nonexistent_calibrator.pkl",  # è·³è¿‡æ ¡å‡†
        top_m=10,
        shadow_mode=False,
        rollout_percentage=100.0
    )
    
    # åˆå§‹åŒ–é›†æˆæ¥å£
    integration = CoTRRStableStep5Integration(config)
    
    # æµ‹è¯•1: åŸºæœ¬é‡æ’åº
    logger.info("æµ‹è¯•1: åŸºæœ¬é‡æ’åºåŠŸèƒ½")
    query_data = {
        'query_id': 'test_query_001',
        'query_text': 'Sample test query for reranking'
    }
    
    candidates = []
    for i in range(15):
        candidates.append({
            'candidate_id': f'cand_{i}',
            'text_features': np.random.randn(256).tolist(),
            'image_features': np.random.randn(256).tolist(),
            'raw_score': np.random.rand(),
            'original_rank': i + 1
        })
    
    result = integration.rerank_candidates(
        query_data, candidates, 
        {'return_scores': True}
    )
    
    assert result['metadata']['status'] == 'success', "åŸºæœ¬é‡æ’åºåº”è¯¥æˆåŠŸ"
    assert len(result['candidates']) == len(candidates), "å€™é€‰æ•°é‡åº”ä¿æŒä¸å˜"
    logger.info(f"âœ… åŸºæœ¬é‡æ’åºæµ‹è¯•é€šè¿‡ (æ¨ç†æ—¶é—´: {result['metadata']['inference_time']:.4f}s)")
    
    # æµ‹è¯•2: A/Bæµ‹è¯•åŠŸèƒ½
    logger.info("æµ‹è¯•2: A/Bæµ‹è¯•åŠŸèƒ½")
    
    # Shadowæ¨¡å¼æµ‹è¯•
    integration.config.shadow_mode = True
    shadow_result = integration.rerank_candidates(query_data, candidates)
    assert shadow_result['metadata']['strategy'] == 'fallback', "Shadowæ¨¡å¼åº”è¯¥fallback"
    
    # Rolloutæ¯”ä¾‹æµ‹è¯•
    integration.config.shadow_mode = False
    integration.config.rollout_percentage = 0.0
    rollout_result = integration.rerank_candidates(query_data, candidates)
    assert rollout_result['metadata']['strategy'] == 'fallback', "0% rolloutåº”è¯¥fallback"
    
    logger.info("âœ… A/Bæµ‹è¯•åŠŸèƒ½é€šè¿‡")
    
    # æµ‹è¯•3: å¥åº·æ£€æŸ¥
    logger.info("æµ‹è¯•3: å¥åº·æ£€æŸ¥")
    
    integration.config.rollout_percentage = 100.0  # æ¢å¤æ­£å¸¸
    health = integration.health_check()
    assert health['status'] == 'healthy', "å¥åº·æ£€æŸ¥åº”è¯¥é€šè¿‡"
    
    logger.info("âœ… å¥åº·æ£€æŸ¥é€šè¿‡")
    
    # æµ‹è¯•4: æ€§èƒ½ç»Ÿè®¡
    logger.info("æµ‹è¯•4: æ€§èƒ½ç»Ÿè®¡")
    
    stats = integration.get_performance_stats()
    logger.info(f"æ€§èƒ½ç»Ÿè®¡: {stats}")
    
    assert stats['total_queries'] > 0, "åº”æœ‰æŸ¥è¯¢ç»Ÿè®¡"
    assert stats['rerank_rate'] >= 0, "é‡æ’ç‡åº”>=0"
    
    logger.info("âœ… æ€§èƒ½ç»Ÿè®¡æµ‹è¯•é€šè¿‡")
    
    logger.info("ğŸ‰ Step5é›†æˆæ¥å£å…¨éƒ¨æµ‹è¯•é€šè¿‡ï¼")
    
    return integration, stats

if __name__ == "__main__":
    logger.info("ğŸš€ å¼€å§‹Task T005: Step5é›†æˆæ¥å£å®ç°")
    
    # è¿è¡Œå…¨é¢æµ‹è¯•
    integration, final_stats = test_step5_integration()
    
    logger.info("ğŸ‰ Task T005å®ç°å®Œæˆï¼")
    logger.info("ğŸ“‹ äº¤ä»˜å†…å®¹:")
    logger.info("  - CoTRRStableStep5Integrationç±»: ç”Ÿäº§å°±ç»ªé›†æˆæ¥å£")
    logger.info("  - A/Bæµ‹è¯•æ”¯æŒ: Shadowæ¨¡å¼ + Rolloutæ§åˆ¶")
    logger.info("  - Top-Mä¼˜åŒ–ç­–ç•¥: ä»…å‰20å€™é€‰ä½¿ç”¨å¤æ‚æ¨¡å‹")
    logger.info("  - æ€§èƒ½ç›‘æ§: å®æ—¶ç»Ÿè®¡ + å¥åº·æ£€æŸ¥")
    logger.info("  - é”™è¯¯å¤„ç†: Fallbackæœºåˆ¶ + å¼‚å¸¸æ•è·")
    logger.info("  - GPUä¼˜åŒ–: ç¼–è¯‘åŠ é€Ÿ + æ··åˆç²¾åº¦")
    
    logger.info("ğŸ“Š æœ€ç»ˆæ€§èƒ½ç»Ÿè®¡:")
    for key, value in final_stats.items():
        if isinstance(value, float):
            logger.info(f"   {key}: {value:.4f}")
        else:
            logger.info(f"   {key}: {value}")