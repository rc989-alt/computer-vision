#!/usr/bin/env python3
"""
CoTRR-Stable Stage 1 Task T003: è®­ç»ƒPipelineè®¾è®¡
è®¾è®¡å®Œæ•´çš„è®­ç»ƒpipelineï¼ŒåŒ…æ‹¬æ•°æ®åŠ è½½ã€è®­ç»ƒå¾ªç¯ã€éªŒè¯ã€ä¿å­˜æ£€æŸ¥ç‚¹ç­‰

å…³é”®ç‰¹æ€§:
1. æ•°æ®Pipeline: Step5æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
2. è®­ç»ƒå¾ªç¯: æ”¯æŒæ··åˆç²¾åº¦ã€æ¢¯åº¦ç´¯ç§¯ã€åˆ†å¸ƒå¼è®­ç»ƒ
3. éªŒè¯æ¡†æ¶: å®Œæ•´çš„æ’åºæŒ‡æ ‡è¯„ä¼°
4. æ£€æŸ¥ç‚¹ç®¡ç†: æ¨¡å‹ä¿å­˜ã€æ¢å¤ã€æœ€ä½³æ¨¡å‹è¿½è¸ª
5. ç›‘æ§æ¥å£: å®æ—¶æŒ‡æ ‡è®°å½•å’Œå¯è§†åŒ–
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from torch.cuda.amp import GradScaler, autocast
import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import logging
from dataclasses import dataclass, asdict
from datetime import datetime
import os
from collections import defaultdict
import pickle

# å¯¼å…¥æˆ‘ä»¬ä¹‹å‰å®ç°çš„ç»„ä»¶
import sys
sys.path.append('/Users/guyan/computer_vision/computer-vision')
from research.src.cotrr_stable import StableCrossAttnReranker, StableConfig
from research.src.listmle_focal_loss import CombinedRankingLoss, LossConfig, RankingTrainer

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®å‚æ•°"""
    # æ¨¡å‹é…ç½®
    hidden_dim: int = 256
    num_layers: int = 2
    num_attention_heads: int = 8
    dropout_rate: float = 0.1
    
    # è®­ç»ƒé…ç½®
    batch_size: int = 32
    learning_rate: float = 1e-4
    num_epochs: int = 50
    warmup_steps: int = 1000
    gradient_accumulation_steps: int = 4
    max_grad_norm: float = 1.0
    
    # æŸå¤±å‡½æ•°é…ç½®
    focal_alpha: float = 0.25
    focal_gamma: float = 2.0
    listmle_weight: float = 0.7
    focal_weight: float = 0.3
    temperature: float = 1.0
    label_smoothing: float = 0.1
    
    # éªŒè¯é…ç½®
    eval_steps: int = 500
    save_steps: int = 1000
    logging_steps: int = 100
    early_stopping_patience: int = 5
    
    # æ•°æ®é…ç½®
    max_candidates: int = 20
    train_data_path: str = "data/train_scored.jsonl"
    val_data_path: str = "data/val_scored.jsonl"
    
    # è¾“å‡ºé…ç½®
    output_dir: str = "research/stage1_progress/checkpoints"
    log_dir: str = "research/stage1_progress/logs"
    
    # ç¡¬ä»¶é…ç½®
    device: str = "cpu"  # å°†æ ¹æ®å¯ç”¨æ€§è‡ªåŠ¨è®¾ç½®
    mixed_precision: bool = True
    dataloader_num_workers: int = 4

class Step5Dataset(Dataset):
    """
    Step5æ•°æ®åŠ è½½å™¨
    ä»scored.jsonlæ ¼å¼åŠ è½½æ’åºæ•°æ®
    """
    
    def __init__(self, 
                 data_path: str,
                 max_candidates: int = 20,
                 feature_dim: int = 512):
        self.data_path = data_path
        self.max_candidates = max_candidates
        self.feature_dim = feature_dim
        
        # åŠ è½½æ•°æ®
        self.data = self._load_data()
        logger.info(f"åŠ è½½æ•°æ®: {len(self.data)} ä¸ªæŸ¥è¯¢ï¼Œæ¥è‡ª {data_path}")
        
    def _load_data(self) -> List[Dict]:
        """åŠ è½½Step5æ ¼å¼çš„scored.jsonlæ•°æ®"""
        data = []
        
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        if not os.path.exists(self.data_path):
            logger.warning(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.data_path}ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®")
            return self._generate_mock_data()
        
        with open(self.data_path, 'r', encoding='utf-8') as f:
            for line in f:
                item = json.loads(line.strip())
                if self._validate_item(item):
                    data.append(item)
                    
        return data
    
    def _generate_mock_data(self) -> List[Dict]:
        """ç”Ÿæˆæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®"""
        np.random.seed(42)
        mock_data = []
        
        for query_id in range(1000):  # 1000ä¸ªæŸ¥è¯¢
            num_candidates = np.random.randint(5, self.max_candidates + 1)
            
            candidates = []
            for cand_id in range(num_candidates):
                # æ¨¡æ‹Ÿç‰¹å¾ï¼šæ–‡æœ¬ç‰¹å¾ + å›¾åƒç‰¹å¾
                text_features = np.random.randn(256).astype(np.float32)
                image_features = np.random.randn(256).astype(np.float32)
                
                # æ¨¡æ‹Ÿç›¸å…³æ€§æ ‡ç­¾ (0-4)
                relevance = np.random.choice([0, 1, 2, 3, 4], p=[0.4, 0.2, 0.2, 0.15, 0.05])
                
                candidates.append({
                    'candidate_id': f'cand_{query_id}_{cand_id}',
                    'text_features': text_features.tolist(),
                    'image_features': image_features.tolist(),
                    'relevance_score': relevance,
                    'raw_score': np.random.rand() * 4.0,  # åŸå§‹åˆ†æ•°
                    'compliance_score': min(relevance / 4.0 + np.random.normal(0, 0.1), 1.0)
                })
            
            mock_data.append({
                'query_id': f'query_{query_id}',
                'query_text': f'Sample query {query_id}',
                'candidates': candidates
            })
            
        return mock_data
    
    def _validate_item(self, item: Dict) -> bool:
        """éªŒè¯æ•°æ®é¡¹çš„å®Œæ•´æ€§"""
        required_fields = ['query_id', 'candidates']
        if not all(field in item for field in required_fields):
            return False
            
        for candidate in item['candidates']:
            required_cand_fields = ['text_features', 'image_features', 'relevance_score']
            if not all(field in candidate for field in required_cand_fields):
                return False
                
        return True
    
    def __len__(self) -> int:
        return len(self.data)
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """è·å–å•ä¸ªè®­ç»ƒæ ·æœ¬"""
        item = self.data[idx]
        candidates = item['candidates']
        
        # æˆªæ–­æˆ–å¡«å……åˆ°max_candidates
        if len(candidates) > self.max_candidates:
            candidates = candidates[:self.max_candidates]
        
        # å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
        text_features = []
        image_features = []
        labels = []
        valid_mask = []
        
        for i in range(self.max_candidates):
            if i < len(candidates):
                cand = candidates[i]
                text_features.append(cand['text_features'])
                image_features.append(cand['image_features'])
                labels.append(cand['relevance_score'])
                valid_mask.append(1.0)
            else:
                # å¡«å……æ— æ•ˆå€™é€‰
                text_features.append([0.0] * 256)
                image_features.append([0.0] * 256)
                labels.append(0.0)
                valid_mask.append(0.0)
        
        return {
            'text_features': torch.tensor(text_features, dtype=torch.float32),
            'image_features': torch.tensor(image_features, dtype=torch.float32),
            'labels': torch.tensor(labels, dtype=torch.float32),
            'valid_mask': torch.tensor(valid_mask, dtype=torch.float32),
            'query_id': item['query_id']
        }

class TrainingPipeline:
    """
    å®Œæ•´çš„CoTRR-Stableè®­ç»ƒpipeline
    æ”¯æŒè®­ç»ƒã€éªŒè¯ã€æ£€æŸ¥ç‚¹ç®¡ç†ã€æŒ‡æ ‡è®°å½•
    """
    
    def __init__(self, config: TrainingConfig):
        self.config = config
        
        # è®¾ç½®è®¾å¤‡
        self.device = self._setup_device()
        self.config.device = self.device
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.output_dir, exist_ok=True)
        os.makedirs(config.log_dir, exist_ok=True)
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = self._build_model()
        
        # åˆå§‹åŒ–æ•°æ®
        self.train_loader, self.val_loader = self._build_data_loaders()
        
        # åˆå§‹åŒ–è®­ç»ƒç»„ä»¶
        self.loss_config = LossConfig(
            focal_alpha=config.focal_alpha,
            focal_gamma=config.focal_gamma,
            listmle_weight=config.listmle_weight,
            focal_weight=config.focal_weight,
            temperature=config.temperature,
            label_smoothing=config.label_smoothing,
            gradient_clip_val=config.max_grad_norm
        )
        
        # åˆ›å»ºæ¨¡å‹åŒ…è£…å™¨ï¼Œé€‚é…RankingTrainer
        class ModelWrapper(nn.Module):
            def __init__(self, base_model):
                super().__init__()
                self.base_model = base_model
                
            def forward(self, batch):
                # é€‚é…StableCrossAttnRerankerçš„è¾“å…¥æ ¼å¼
                batch_size, num_candidates, feature_dim = batch['text_features'].shape
                
                clip_text = batch['text_features'].view(-1, feature_dim)
                clip_img = batch['image_features'].view(-1, feature_dim) 
                visual_features = torch.zeros_like(clip_img)
                conflict_features = torch.zeros_like(clip_img)
                
                result = self.base_model(clip_img, clip_text, visual_features, conflict_features)
                scores = result['logits'].view(batch_size, num_candidates)
                
                return scores
        
        wrapped_model = ModelWrapper(self.model)
        self.trainer = RankingTrainer(wrapped_model, self.loss_config, self.device)
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        self.scaler = GradScaler() if config.mixed_precision else None
        
        # è®­ç»ƒçŠ¶æ€
        self.global_step = 0
        self.epoch = 0
        self.best_metric = 0.0
        self.metrics_history = defaultdict(list)
        
        logger.info(f"è®­ç»ƒPipelineåˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
        logger.info(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in self.model.parameters()):,}")
        
    def _setup_device(self) -> str:
        """è®¾ç½®è®­ç»ƒè®¾å¤‡"""
        if torch.cuda.is_available():
            device = "cuda"
            logger.info(f"ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
        elif torch.backends.mps.is_available():
            device = "mps"
            logger.info("ä½¿ç”¨MPS (Apple Silicon)")
        else:
            device = "cpu"
            logger.info("ä½¿ç”¨CPU")
        
        return device
    
    def _build_model(self) -> nn.Module:
        """æ„å»ºæ¨¡å‹"""
        # åˆ›å»ºStableConfig
        stable_config = StableConfig(
            clip_img_dim=256,
            clip_text_dim=256,
            visual_dim=256,
            conflict_dim=256,
            hidden_dim=self.config.hidden_dim,
            num_layers=self.config.num_layers,
            num_attention_heads=self.config.num_attention_heads,
            dropout=self.config.dropout_rate
        )
        
        model = StableCrossAttnReranker(stable_config).to(self.device)
        return model
    
    def _build_data_loaders(self) -> Tuple[DataLoader, DataLoader]:
        """æ„å»ºæ•°æ®åŠ è½½å™¨"""
        # è®­ç»ƒæ•°æ®
        train_dataset = Step5Dataset(
            self.config.train_data_path,
            max_candidates=self.config.max_candidates
        )
        
        train_loader = DataLoader(
            train_dataset,
            batch_size=self.config.batch_size,
            shuffle=True,
            num_workers=self.config.dataloader_num_workers,
            pin_memory=True if self.device != "cpu" else False
        )
        
        # éªŒè¯æ•°æ®
        val_dataset = Step5Dataset(
            self.config.val_data_path,
            max_candidates=self.config.max_candidates
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=self.config.dataloader_num_workers,
            pin_memory=True if self.device != "cpu" else False
        )
        
        logger.info(f"è®­ç»ƒæ ·æœ¬: {len(train_dataset)}, éªŒè¯æ ·æœ¬: {len(val_dataset)}")
        
        return train_loader, val_loader
    
    def train(self) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´è®­ç»ƒæµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒCoTRR-Stableæ¨¡å‹")
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(self.config.num_epochs):
            self.epoch = epoch
            
            # è®­ç»ƒä¸€ä¸ªepoch
            train_metrics = self._train_epoch()
            
            # éªŒè¯
            if (epoch + 1) % (self.config.eval_steps // len(self.train_loader) + 1) == 0:
                val_metrics = self._validate_epoch()
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜æœ€ä½³æ¨¡å‹
                current_metric = val_metrics.get('ndcg@10', 0.0)
                if current_metric > self.best_metric:
                    self.best_metric = current_metric
                    self._save_checkpoint(is_best=True)
                    logger.info(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (nDCG@10: {current_metric:.4f})")
                
                # è®°å½•æŒ‡æ ‡
                self._log_epoch_metrics(train_metrics, val_metrics)
            
            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % (self.config.save_steps // len(self.train_loader) + 1) == 0:
                self._save_checkpoint(is_best=False)
        
        # è®­ç»ƒå®Œæˆ
        final_metrics = self._validate_epoch()
        self._save_final_results(final_metrics)
        
        logger.info("âœ… è®­ç»ƒå®Œæˆï¼")
        return final_metrics
    
    def _train_epoch(self) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        epoch_metrics = defaultdict(float)
        num_batches = 0
        
        for step, batch in enumerate(self.train_loader):
            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
            batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                    for k, v in batch.items()}
            
            # è®­ç»ƒæ­¥éª¤
            if self.scaler:
                with autocast():
                    metrics = self.trainer.train_step(
                        batch, 
                        self.config.gradient_accumulation_steps
                    )
            else:
                metrics = self.trainer.train_step(
                    batch, 
                    self.config.gradient_accumulation_steps
                )
            
            # ç´¯ç§¯æŒ‡æ ‡
            for key, value in metrics.items():
                epoch_metrics[key] += value
            num_batches += 1
            
            # å®šæœŸæ—¥å¿—
            if step % self.config.logging_steps == 0:
                logger.info(
                    f"Epoch {self.epoch}, Step {step}/{len(self.train_loader)}, "
                    f"Loss: {metrics['total_loss']:.4f}, "
                    f"LR: {metrics['learning_rate']:.2e}"
                )
            
            self.global_step += 1
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_metrics = {k: v / num_batches for k, v in epoch_metrics.items()}
        return avg_metrics
    
    def _validate_epoch(self) -> Dict[str, float]:
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        epoch_metrics = defaultdict(float)
        num_batches = 0
        
        with torch.no_grad():
            for batch in self.val_loader:
                # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
                batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                        for k, v in batch.items()}
                
                # éªŒè¯æ­¥éª¤
                metrics = self.trainer.validate_step(batch)
                
                # ç´¯ç§¯æŒ‡æ ‡
                for key, value in metrics.items():
                    epoch_metrics[key] += value
                num_batches += 1
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_metrics = {k: v / num_batches for k, v in epoch_metrics.items()}
        return avg_metrics
    
    def _save_checkpoint(self, is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': self.epoch,
            'global_step': self.global_step,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.trainer.optimizer.state_dict(),
            'scheduler_state_dict': self.trainer.scheduler.state_dict(),
            'loss_fn_state_dict': self.trainer.loss_fn.state_dict(),
            'best_metric': self.best_metric,
            'config': asdict(self.config),
            'metrics_history': dict(self.metrics_history)
        }
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if is_best:
            checkpoint_path = os.path.join(self.config.output_dir, 'best_model.pt')
        else:
            checkpoint_path = os.path.join(self.config.output_dir, f'checkpoint_epoch_{self.epoch}.pt')
        
        torch.save(checkpoint, checkpoint_path)
    
    def _log_epoch_metrics(self, train_metrics: Dict, val_metrics: Dict):
        """è®°å½•epochæŒ‡æ ‡"""
        log_entry = {
            'epoch': self.epoch,
            'global_step': self.global_step,
            'timestamp': datetime.now().isoformat(),
            'train_metrics': train_metrics,
            'val_metrics': val_metrics
        }
        
        # ä¿å­˜åˆ°æŒ‡æ ‡å†å²
        for key, value in {**train_metrics, **val_metrics}.items():
            self.metrics_history[key].append(value)
        
        # å†™å…¥æ—¥å¿—æ–‡ä»¶
        log_file = os.path.join(self.config.log_dir, 'training_log.jsonl')
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry) + '\n')
    
    def _save_final_results(self, final_metrics: Dict):
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        results = {
            'final_metrics': final_metrics,
            'best_metric': self.best_metric,
            'total_epochs': self.epoch + 1,
            'total_steps': self.global_step,
            'config': asdict(self.config),
            'training_completion_time': datetime.now().isoformat()
        }
        
        results_file = os.path.join(self.config.output_dir, 'final_results.json')
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"æœ€ç»ˆç»“æœä¿å­˜è‡³: {results_file}")

def test_training_pipeline():
    """æµ‹è¯•è®­ç»ƒpipeline"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•è®­ç»ƒPipeline")
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    config = TrainingConfig(
        batch_size=4,
        num_epochs=2,
        eval_steps=10,
        save_steps=20,
        logging_steps=5,
        max_candidates=10,
        train_data_path="data/mock_train.jsonl",  # å°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        val_data_path="data/mock_val.jsonl"
    )
    
    # åˆå§‹åŒ–pipeline
    pipeline = TrainingPipeline(config)
    
    # æµ‹è¯•å•æ­¥è®­ç»ƒ
    train_batch = next(iter(pipeline.train_loader))
    logger.info(f"è®­ç»ƒæ‰¹æ¬¡å½¢çŠ¶: {train_batch['text_features'].shape}")
    logger.info(f"æ ‡ç­¾å½¢çŠ¶: {train_batch['labels'].shape}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­ - ä½¿ç”¨åŒ…è£…å™¨
    pipeline.trainer.model.eval()  # ä½¿ç”¨åŒ…è£…åçš„æ¨¡å‹
    with torch.no_grad():
        # ç§»åŠ¨batchåˆ°æ­£ç¡®è®¾å¤‡
        train_batch_device = {k: v.to(pipeline.device) if isinstance(v, torch.Tensor) else v 
                             for k, v in train_batch.items()}
        
        # ä½¿ç”¨åŒ…è£…å™¨è¿›è¡Œå‰å‘ä¼ æ’­
        scores = pipeline.trainer.model(train_batch_device)
        logger.info(f"è¾“å‡ºåˆ†æ•°å½¢çŠ¶: {scores.shape}")
    
    # æµ‹è¯•æŸå¤±è®¡ç®—
    loss_dict = pipeline.trainer.loss_fn(
        scores, 
        train_batch_device['labels'], 
        return_components=True
    )
    logger.info(f"æŸå¤±å€¼: {loss_dict['total_loss']:.4f}")
    
    logger.info("âœ… è®­ç»ƒPipelineæµ‹è¯•é€šè¿‡")
    return True

if __name__ == "__main__":
    logger.info("ğŸš€ å¼€å§‹Task T003: è®­ç»ƒPipelineè®¾è®¡")
    
    # è¿è¡Œæµ‹è¯•
    test_passed = test_training_pipeline()
    
    if test_passed:
        logger.info("ğŸ‰ Task T003å®ç°å®Œæˆï¼")
        logger.info("ğŸ“‹ äº¤ä»˜å†…å®¹:")
        logger.info("  - Step5Datasetç±»: Step5æ•°æ®æ ¼å¼åŠ è½½å™¨")
        logger.info("  - TrainingPipelineç±»: å®Œæ•´è®­ç»ƒæµç¨‹ç®¡ç†")
        logger.info("  - TrainingConfigç±»: å…¨é¢è®­ç»ƒé…ç½®ç®¡ç†")
        logger.info("  - æ··åˆç²¾åº¦è®­ç»ƒæ”¯æŒ")
        logger.info("  - æ£€æŸ¥ç‚¹ç®¡ç†å’Œæœ€ä½³æ¨¡å‹ä¿å­˜")
        logger.info("  - å®Œæ•´æŒ‡æ ‡è®°å½•å’Œæ—¥å¿—ç³»ç»Ÿ")
        logger.info("  - æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆï¼ˆç”¨äºæµ‹è¯•ï¼‰")
    else:
        logger.error("âŒ Task T003æµ‹è¯•å¤±è´¥")