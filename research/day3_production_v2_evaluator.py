#!/usr/bin/env python3
"""
ç”Ÿäº§çº§è¯„ä¼°å™¨ - V2é€‚é…ç‰ˆæœ¬
ç”¨äºè¯„ä¼°ç”Ÿäº§çº§è½»é‡å¢å¼ºå™¨V2.0
"""

import json
import time
import logging
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from day3_production_evaluator import ProductionEvaluator, ProductionMetrics
from day3_production_enhancer_v2 import ProductionLightweightEnhancerV2, AdvancedConfig

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def main():
    """ä¸»å‡½æ•° - è¯„ä¼°V2å¢å¼ºå™¨"""
    print("ğŸ­ ç”Ÿäº§çº§è½»é‡å¢å¼ºå™¨V2.0å®Œæ•´è¯„ä¼°")
    print("="*80)
    
    # 1. åŠ è½½V2æœ€ä¼˜é…ç½®
    print("\\n1ï¸âƒ£ åŠ è½½V2æœ€ä¼˜é…ç½®...")
    with open("research/day3_results/production_v2_config.json", 'r') as f:
        v2_config_data = json.load(f)
    
    v2_config = AdvancedConfig(
        base_boost=v2_config_data['base_boost'],
        exact_match_boost=v2_config_data['exact_match_boost'],
        fuzzy_match_boost=v2_config_data['fuzzy_match_boost'],
        semantic_boost=v2_config_data['semantic_boost'],
        premium_quality_boost=v2_config_data['premium_quality_boost'],
        high_engagement_boost=v2_config_data['high_engagement_boost'],
        domain_adaptation_factor=v2_config_data['domain_adaptation_factor'],
        confidence_threshold=v2_config_data['confidence_threshold'],
        low_confidence_penalty=v2_config_data['low_confidence_penalty'],
        decision_sharpening=v2_config_data['decision_sharpening'],
        margin_amplification=v2_config_data['margin_amplification'],
        max_total_boost=v2_config_data['max_total_boost'],
        min_score_threshold=v2_config_data['min_score_threshold']
    )
    
    # 2. åˆ›å»ºV2å¢å¼ºå™¨
    print("\\n2ï¸âƒ£ åˆ›å»ºV2å¢å¼ºå™¨...")
    enhancer_v2 = ProductionLightweightEnhancerV2(v2_config)
    
    # 3. æ‰§è¡Œå®Œæ•´ç”Ÿäº§çº§è¯„ä¼°
    print("\\n3ï¸âƒ£ æ‰§è¡Œå®Œæ•´ç”Ÿäº§çº§è¯„ä¼°...")
    from day3_production_upgrade import ProductionConfig
    production_config = ProductionConfig()
    
    evaluator = ProductionEvaluator(production_config)
    
    production_metrics = evaluator.evaluate_production_system(
        "research/day3_results/production_dataset.json", 
        enhancer_v2
    )
    
    # 4. æ‰“å°V2æŠ¥å‘Š
    print("\\n" + "="*100)
    print("ğŸ­ ç”Ÿäº§çº§è½»é‡å¢å¼ºå™¨V2.0è¯„ä¼°æŠ¥å‘Š")
    print("="*100)
    
    # ä¸»è¦æŒ‡æ ‡
    print(f"\\nğŸ“Š V2.0ä¸»è¦æŒ‡æ ‡:")
    print(f"   Î”Compliance@1: {production_metrics.compliance_improvement:+.4f}")
    print(f"   Î”Compliance@1 CI95: [{production_metrics.compliance_ci95[0]:+.4f}, {production_metrics.compliance_ci95[1]:+.4f}]")
    print(f"   Î”nDCG@10: {production_metrics.ndcg_improvement:+.4f}")
    print(f"   Î”nDCG@10 CI95: [{production_metrics.ndcg_ci95[0]:+.4f}, {production_metrics.ndcg_ci95[1]:+.4f}]")
    
    # æ€§èƒ½æŒ‡æ ‡
    print(f"\\nâš¡ V2.0æ€§èƒ½æŒ‡æ ‡:")
    print(f"   P95å»¶è¿Ÿ: {production_metrics.p95_latency_ms:.2f}ms")
    
    # ä¸“é¡¹æŒ‡æ ‡
    print(f"\\nğŸŒ¸ V2.0 Blossomâ†”Fruitä¸“é¡¹:")
    print(f"   è¯¯åˆ¤ç‡: {production_metrics.blossom_fruit_error_rate:.1%}")
    print(f"   ä½marginç‡: {production_metrics.low_margin_rate:.1%}")
    
    # V1 vs V2 å¯¹æ¯”
    print(f"\\nğŸ†š V1 vs V2 å¯¹æ¯”:")
    
    # åŠ è½½V1ç»“æœè¿›è¡Œå¯¹æ¯”
    try:
        with open("research/day3_results/production_evaluation.json", 'r') as f:
            v1_results = json.load(f)
        
        v1_compliance = v1_results['metrics']['compliance_improvement']
        v1_ndcg = v1_results['metrics']['ndcg_improvement']
        v1_latency = v1_results['metrics']['p95_latency_ms']
        v1_margin_rate = v1_results['metrics']['low_margin_rate']
        
        compliance_improvement = production_metrics.compliance_improvement - v1_compliance
        ndcg_improvement = production_metrics.ndcg_improvement - v1_ndcg
        latency_change = production_metrics.p95_latency_ms - v1_latency
        margin_improvement = v1_margin_rate - production_metrics.low_margin_rate
        
        print(f"   Î”Compliance@1æ”¹è¿›: {compliance_improvement:+.4f} ({compliance_improvement/v1_compliance*100:+.1f}%)")
        print(f"   Î”nDCG@10æ”¹è¿›: {ndcg_improvement:+.4f} ({ndcg_improvement/v1_ndcg*100:+.1f}%)")
        print(f"   P95å»¶è¿Ÿå˜åŒ–: {latency_change:+.3f}ms")
        print(f"   ä½marginç‡æ”¹è¿›: {margin_improvement:+.3f} ({margin_improvement/v1_margin_rate*100:+.1f}%)")
        
    except Exception as e:
        print(f"   âš ï¸ æ— æ³•åŠ è½½V1ç»“æœè¿›è¡Œå¯¹æ¯”: {e}")
    
    # é—¨æ§›æ£€æŸ¥
    print(f"\\nğŸ¯ V2.0ç”Ÿäº§çº§é—¨æ§›æ£€æŸ¥:")
    thresholds = production_metrics.meets_thresholds(production_config)
    
    status_map = {
        'compliance_improvement': (f"Î”Compliance@1 CI95ä¸‹ç•Œ â‰¥ +{production_config.min_compliance_improvement}", production_metrics.compliance_ci95[0]),
        'ndcg_improvement': (f"Î”nDCG@10 CI95ä¸‹ç•Œ â‰¥ +{production_config.target_ndcg_improvement}", production_metrics.ndcg_ci95[0]),
        'latency': (f"P95å»¶è¿Ÿ < {production_config.max_p95_latency_ms}ms", production_metrics.p95_latency_ms),
        'blossom_fruit_error': (f"Blossomâ†’Fruitè¯¯åˆ¤ â‰¤ {production_config.max_blossom_fruit_error_rate:.1%}", production_metrics.blossom_fruit_error_rate),
        'low_margin': (f"ä½marginå æ¯” â‰¤ {production_config.max_low_margin_rate:.1%}", production_metrics.low_margin_rate)
    }
    
    all_passed = True
    for key, passed in thresholds.items():
        status = "âœ…" if passed else "âŒ"
        desc, value = status_map[key]
        if key in ['compliance_improvement', 'ndcg_improvement', 'blossom_fruit_error', 'low_margin']:
            print(f"   {status} {desc}: {value:.4f}")
        else:
            print(f"   {status} {desc}: {value:.3f}")
        if not passed:
            all_passed = False
    
    # æœ€ç»ˆåˆ¤æ–­
    print(f"\\nğŸ† V2.0æœ€ç»ˆè¯„ä¼°:")
    if all_passed:
        print("   ğŸš€ PRODUCTION READY! V2.0æ‰€æœ‰æŒ‡æ ‡å‡è¾¾åˆ°ç”Ÿäº§çº§é—¨æ§›")
        print("   âœ… å¯ä»¥ç«‹å³éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒè¿›è¡ŒA/Bæµ‹è¯•")
        
        # æ€§èƒ½ç­‰çº§
        if (production_metrics.compliance_improvement >= production_config.target_compliance_improvement and 
            production_metrics.p95_latency_ms < 0.5):
            print("   ğŸŒŸ EXCELLENCEçº§åˆ«: è¶…è¶Šç›®æ ‡æŒ‡æ ‡ä¸”æ€§èƒ½å“è¶Š")
        else:
            print("   â­ PRODUCTIONçº§åˆ«: æ»¡è¶³ç”Ÿäº§éƒ¨ç½²è¦æ±‚")
            
    else:
        print("   âŒ NOT READY: V2.0éƒ¨åˆ†æŒ‡æ ‡ä»æœªè¾¾åˆ°ç”Ÿäº§çº§é—¨æ§›")
        failed_metrics = [key for key, passed in thresholds.items() if not passed]
        print(f"   ğŸ”§ å¾…ä¼˜åŒ–æŒ‡æ ‡: {', '.join(failed_metrics)}")
    
    # æŠ€æœ¯æ”¹è¿›æ€»ç»“
    print(f"\\nğŸ’¡ V2.0æŠ€æœ¯æ”¹è¿›æ€»ç»“:")
    print("   âœ¨ å¤šå±‚çº§å¢å¼ºé€»è¾‘ (ç²¾ç¡®+æ¨¡ç³Š+è¯­ä¹‰)")
    print("   âœ¨ é¢†åŸŸè‡ªé€‚åº”æœºåˆ¶")
    print("   âœ¨ åŠ¨æ€æƒé‡è°ƒæ•´")
    print("   âœ¨ å†³ç­–é”åŒ–å’Œmarginæ”¾å¤§")
    print("   âœ¨ ç½‘æ ¼æœç´¢å‚æ•°ä¼˜åŒ–")
    
    # ä¿å­˜V2ç»“æœ
    v2_results = {
        'version': '2.0',
        'metrics': {
            'compliance_improvement': float(production_metrics.compliance_improvement),
            'compliance_ci95': [float(x) for x in production_metrics.compliance_ci95],
            'ndcg_improvement': float(production_metrics.ndcg_improvement),
            'ndcg_ci95': [float(x) for x in production_metrics.ndcg_ci95],
            'p95_latency_ms': float(production_metrics.p95_latency_ms),
            'blossom_fruit_error_rate': float(production_metrics.blossom_fruit_error_rate),
            'low_margin_rate': float(production_metrics.low_margin_rate)
        },
        'thresholds_met': {k: bool(v) for k, v in thresholds.items()},
        'config': {
            'min_compliance_improvement': production_config.min_compliance_improvement,
            'target_ndcg_improvement': production_config.target_ndcg_improvement,
            'max_p95_latency_ms': production_config.max_p95_latency_ms,
            'max_blossom_fruit_error_rate': production_config.max_blossom_fruit_error_rate,
            'max_low_margin_rate': production_config.max_low_margin_rate
        },
        'optimization_score': v2_config_data.get('optimization_score', 0),
        'evaluation_time': time.time()
    }
    
    results_path = "research/day3_results/production_v2_evaluation.json"
    with open(results_path, 'w') as f:
        json.dump(v2_results, f, indent=2)
    
    print(f"\\nğŸ“ V2.0è¯¦ç»†ç»“æœå·²ä¿å­˜: {results_path}")

if __name__ == "__main__":
    main()