{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3c93890",
   "metadata": {},
   "source": [
    "# ðŸŒ™ Computer Vision Night Experiments - Colab GPU Optimization\n",
    "\n",
    "This notebook provides a complete solution for running overnight GPU optimization experiments in Google Colab. It implements a robust, resumable, and auto-saving experimental framework.\n",
    "\n",
    "## ðŸŽ¯ Features\n",
    "- **Resumable**: Shard-based execution survives disconnections\n",
    "- **Auto-saving**: All results saved to Google Drive\n",
    "- **Statistical rigor**: Bootstrap CI + permutation tests\n",
    "- **One-click setup**: Automated environment configuration\n",
    "\n",
    "## ðŸ“Š Experiment Overview\n",
    "- **MMR Alpha Grid**: [0.70, 0.75, 0.80] diversity parameters\n",
    "- **Topic Coverage**: [0, 1, 2] forced topic slots\n",
    "- **Sample Size**: 320+ queries for 95% statistical power\n",
    "- **Total Runtime**: ~8 hours across 4 shards\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fb00a1",
   "metadata": {},
   "source": [
    "## ðŸš€ Section 1: Download Quick Start Script\n",
    "\n",
    "Download the automated setup script directly from the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b050366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the quick start script from GitHub\n",
    "!wget -q https://raw.githubusercontent.com/rc989-alt/computer-vision/main/colab_quick_start.py\n",
    "!wget -q https://raw.githubusercontent.com/rc989-alt/computer-vision/main/colab_night_runner.py\n",
    "!wget -q https://raw.githubusercontent.com/rc989-alt/computer-vision/main/production_dataset.json\n",
    "\n",
    "print(\"âœ… Files downloaded successfully!\")\n",
    "print(\"ðŸ“ Available files:\")\n",
    "!ls -la *.py *.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ace99",
   "metadata": {},
   "source": [
    "## ðŸ”§ Section 2: Execute Quick Start Script (Option A - Fully Automated)\n",
    "\n",
    "Run the quick start script for completely automated setup and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47959cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the quick start script - this will handle everything automatically\n",
    "!python colab_quick_start.py\n",
    "\n",
    "print(\"ðŸŽ‰ Automated setup complete!\")\n",
    "print(\"ðŸ’¤ Experiments will now run overnight in the background\")\n",
    "print(\"ðŸ“ Check Google Drive in the morning for results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07137de",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Section 3: Mount Google Drive (Option B - Manual Setup)\n",
    "\n",
    "For manual control, start by mounting Google Drive to save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb69b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for result storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify Drive mount\n",
    "import os\n",
    "drive_path = \"/content/drive/MyDrive\"\n",
    "if os.path.exists(drive_path):\n",
    "    print(\"âœ… Google Drive mounted successfully!\")\n",
    "    print(f\"ðŸ“ Drive path: {drive_path}\")\n",
    "else:\n",
    "    print(\"âŒ Drive mount failed!\")\n",
    "\n",
    "# Create experiment directory\n",
    "experiment_dir = \"/content/drive/MyDrive/v1_night_opt\"\n",
    "os.makedirs(experiment_dir, exist_ok=True)\n",
    "print(f\"ðŸ“‚ Experiment directory ready: {experiment_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8b2f6",
   "metadata": {},
   "source": [
    "## ðŸ”§ Section 4: Verify Environment Setup\n",
    "\n",
    "Check GPU availability and install required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b37e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "# Install required dependencies\n",
    "!pip install -q numpy tqdm\n",
    "\n",
    "# Verify Python version and imports\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"âœ… Python version: {sys.version}\")\n",
    "print(f\"âœ… NumPy version: {np.__version__}\")\n",
    "print(f\"âœ… Current time: {datetime.now()}\")\n",
    "\n",
    "# Check if files are available\n",
    "required_files = ['colab_night_runner.py', 'production_dataset.json']\n",
    "for file in required_files:\n",
    "    if Path(file).exists():\n",
    "        print(f\"âœ… {file} is available\")\n",
    "    else:\n",
    "        print(f\"âŒ {file} is missing!\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Environment verification complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50962de",
   "metadata": {},
   "source": [
    "## âš™ï¸ Section 5: Configure Experiment Parameters\n",
    "\n",
    "Set up the experimental parameters and validate the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d381ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Configuration\n",
    "EXPERIMENT_CONFIG = {\n",
    "    \"data_file\": \"/content/production_dataset.json\",\n",
    "    \"output_dir\": \"/content/drive/MyDrive/v1_night_opt\",\n",
    "    \"hours_per_shard\": 2.0,\n",
    "    \"total_shards\": 4,\n",
    "    \n",
    "    # Algorithm parameters\n",
    "    \"mmr_alphas\": [0.70, 0.75, 0.80],\n",
    "    \"topic_slots\": [0, 1, 2],\n",
    "    \n",
    "    # Statistical parameters\n",
    "    \"bootstrap_samples\": 1000,\n",
    "    \"confidence_level\": 0.95,\n",
    "    \"significance_threshold\": 0.05\n",
    "}\n",
    "\n",
    "print(\"ðŸ“Š Experiment Configuration:\")\n",
    "print(\"=\" * 40)\n",
    "for key, value in EXPERIMENT_CONFIG.items():\n",
    "    print(f\"{key:20}: {value}\")\n",
    "\n",
    "# Calculate total experiments\n",
    "total_configs = len(EXPERIMENT_CONFIG[\"mmr_alphas\"]) * len(EXPERIMENT_CONFIG[\"topic_slots\"])\n",
    "total_experiments = total_configs * EXPERIMENT_CONFIG[\"total_shards\"]\n",
    "estimated_hours = EXPERIMENT_CONFIG[\"hours_per_shard\"] * EXPERIMENT_CONFIG[\"total_shards\"]\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Experiment Scale:\")\n",
    "print(f\"Total configurations: {total_configs}\")\n",
    "print(f\"Total experiments: {total_experiments}\")\n",
    "print(f\"Estimated runtime: {estimated_hours} hours\")\n",
    "\n",
    "# Validate data file\n",
    "with open(EXPERIMENT_CONFIG[\"data_file\"], 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "if \"inspirations\" in data:\n",
    "    num_queries = len(data[\"inspirations\"])\n",
    "    total_candidates = sum(len(ins.get(\"candidates\", [])) for ins in data[\"inspirations\"])\n",
    "    print(f\"\\nðŸ“ˆ Dataset Statistics:\")\n",
    "    print(f\"Queries: {num_queries}\")\n",
    "    print(f\"Total candidates: {total_candidates}\")\n",
    "    print(f\"Avg candidates per query: {total_candidates/num_queries:.1f}\")\n",
    "else:\n",
    "    print(\"âŒ Invalid data format!\")\n",
    "\n",
    "print(\"\\nâœ… Configuration validated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f90f5",
   "metadata": {},
   "source": [
    "## ðŸš€ Section 6: Run Manual Setup Alternative\n",
    "\n",
    "Execute the night experiments manually with full control over parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b347393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the night experiments manually\n",
    "print(\"ðŸŒ™ Starting Night Experiments...\")\n",
    "print(f\"ðŸ• Start time: {datetime.now()}\")\n",
    "\n",
    "# Choose experiment mode\n",
    "QUICK_TEST = True  # Set to False for full 8-hour experiment\n",
    "\n",
    "if QUICK_TEST:\n",
    "    print(\"âš¡ Running QUICK TEST MODE (30 minutes)\")\n",
    "    command = f\"\"\"python colab_night_runner.py \\\\\n",
    "      --data {EXPERIMENT_CONFIG['data_file']} \\\\\n",
    "      --out_dir {EXPERIMENT_CONFIG['output_dir']}_test \\\\\n",
    "      --hours_per_shard 0.25 \\\\\n",
    "      --total_shards 2\"\"\"\n",
    "else:\n",
    "    print(\"ðŸŒ Running FULL EXPERIMENT MODE (8+ hours)\")\n",
    "    command = f\"\"\"python colab_night_runner.py \\\\\n",
    "      --data {EXPERIMENT_CONFIG['data_file']} \\\\\n",
    "      --out_dir {EXPERIMENT_CONFIG['output_dir']} \\\\\n",
    "      --hours_per_shard {EXPERIMENT_CONFIG['hours_per_shard']} \\\\\n",
    "      --total_shards {EXPERIMENT_CONFIG['total_shards']}\"\"\"\n",
    "\n",
    "print(\"ðŸ”§ Command to execute:\")\n",
    "print(command)\n",
    "print(\"\\nðŸš¨ WARNING: This will run for hours. Only proceed if ready!\")\n",
    "\n",
    "# Uncomment the line below to actually run the experiments\n",
    "# !{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74921929",
   "metadata": {},
   "source": [
    "## ðŸ“Š Section 7: Monitor Experiment Progress\n",
    "\n",
    "Track experiment progress and check results in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58b24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor experiment progress\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def check_experiment_progress(base_dir):\n",
    "    \"\"\"Check the progress of running experiments\"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    \n",
    "    if not base_path.exists():\n",
    "        print(f\"âŒ Experiment directory not found: {base_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ðŸ“ Checking progress in: {base_dir}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check progress files\n",
    "    progress_files = list(base_path.glob(\"progress_*.json\"))\n",
    "    if progress_files:\n",
    "        latest_progress = max(progress_files, key=lambda x: x.stat().st_mtime)\n",
    "        with open(latest_progress, 'r') as f:\n",
    "            progress = json.load(f)\n",
    "        \n",
    "        print(f\"ðŸ“Š Session: {progress.get('session_id', 'Unknown')}\")\n",
    "        print(f\"ðŸ• Last update: {progress.get('last_update', 'Unknown')}\")\n",
    "        print(f\"âœ… Completed: {len(progress.get('completed', []))}\")\n",
    "        print(f\"âŒ Failed: {len(progress.get('failed', []))}\")\n",
    "        print(f\"ðŸ“ˆ Total expected: {progress.get('total_experiments', 'Unknown')}\")\n",
    "    else:\n",
    "        print(\"â³ No progress files found - experiments may not have started yet\")\n",
    "    \n",
    "    # Check result directories\n",
    "    result_dirs = list(base_path.glob(\"shard_*_mmr_*\"))\n",
    "    print(f\"\\nðŸ§ª Experiment directories found: {len(result_dirs)}\")\n",
    "    \n",
    "    completed_experiments = 0\n",
    "    for exp_dir in result_dirs:\n",
    "        result_file = exp_dir / \"results.json\"\n",
    "        if result_file.exists():\n",
    "            completed_experiments += 1\n",
    "    \n",
    "    print(f\"âœ… Completed experiments: {completed_experiments}\")\n",
    "    \n",
    "    # Check for summary report\n",
    "    summary_file = base_path / \"morning_summary.json\"\n",
    "    if summary_file.exists():\n",
    "        print(\"\\nðŸŽ‰ EXPERIMENTS COMPLETE!\")\n",
    "        with open(summary_file, 'r') as f:\n",
    "            summary = json.load(f)\n",
    "        \n",
    "        recommendation = summary.get('recommendation', {})\n",
    "        print(f\"ðŸŽ¯ Decision: {recommendation.get('decision', 'Unknown')}\")\n",
    "        print(f\"ðŸ“Š Confidence: {recommendation.get('confidence', 'Unknown')}\")\n",
    "        \n",
    "        if summary.get('best_configuration'):\n",
    "            best_config = summary['configurations'][summary['best_configuration']]\n",
    "            print(f\"â­ Best config: {best_config['parameters']}\")\n",
    "            print(f\"ðŸ“ˆ Improvement: {best_config['mean_improvement']:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nâ³ Experiments still running...\")\n",
    "\n",
    "# Check progress for both test and full experiments\n",
    "print(\"ðŸ” Checking experiment progress...\")\n",
    "\n",
    "# Check test experiments\n",
    "test_dir = \"/content/drive/MyDrive/v1_night_opt_test\"\n",
    "check_experiment_progress(test_dir)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Check full experiments  \n",
    "full_dir = \"/content/drive/MyDrive/v1_night_opt\"\n",
    "check_experiment_progress(full_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e7d1c",
   "metadata": {},
   "source": [
    "## ðŸŒ… Results Analysis\n",
    "\n",
    "Analyze completed experiments and generate decision recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f910ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze experiment results and generate recommendations\n",
    "def analyze_results(summary_file_path):\n",
    "    \"\"\"Analyze the morning summary and provide detailed insights\"\"\"\n",
    "    \n",
    "    if not Path(summary_file_path).exists():\n",
    "        print(f\"âŒ Summary file not found: {summary_file_path}\")\n",
    "        print(\"â³ Experiments may still be running...\")\n",
    "        return\n",
    "    \n",
    "    with open(summary_file_path, 'r') as f:\n",
    "        summary = json.load(f)\n",
    "    \n",
    "    print(\"ðŸŽ¯ EXPERIMENT RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"ðŸ“Š Session ID: {summary.get('session_id')}\")\n",
    "    print(f\"ðŸ• Completion: {summary.get('completion_time')}\")\n",
    "    print(f\"ðŸ§ª Total experiments: {summary.get('total_experiments')}\")\n",
    "    \n",
    "    # Configuration analysis\n",
    "    configs = summary.get('configurations', {})\n",
    "    print(f\"\\nðŸ“ˆ Configuration Results ({len(configs)} total):\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    significant_configs = []\n",
    "    for config_name, config_data in configs.items():\n",
    "        params = config_data['parameters']\n",
    "        is_sig = config_data.get('is_significant', False)\n",
    "        improvement = config_data.get('mean_improvement', 0)\n",
    "        ci_lower = config_data.get('ci_95_lower', 0)\n",
    "        ci_upper = config_data.get('ci_95_upper', 0)\n",
    "        \n",
    "        status = \"ðŸŸ¢ SIGNIFICANT\" if is_sig else \"ðŸ”´ NOT SIGNIFICANT\"\n",
    "        print(f\"{config_name}:\")\n",
    "        print(f\"  Params: Î±={params['alpha']}, slots={params['slots']}\")\n",
    "        print(f\"  Status: {status}\")\n",
    "        print(f\"  Improvement: {improvement:.4f}\")\n",
    "        print(f\"  95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "        print()\n",
    "        \n",
    "        if is_sig:\n",
    "            significant_configs.append((config_name, improvement, config_data))\n",
    "    \n",
    "    # Recommendation analysis\n",
    "    recommendation = summary.get('recommendation', {})\n",
    "    decision = recommendation.get('decision', 'UNKNOWN')\n",
    "    confidence = recommendation.get('confidence', 'UNKNOWN')\n",
    "    \n",
    "    print(\"ðŸŽ¯ FINAL RECOMMENDATION:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    if decision == \"GO\":\n",
    "        print(\"ðŸŸ¢ DECISION: PROCEED TO PRODUCTION\")\n",
    "        print(\"âœ… Statistical significance confirmed\")\n",
    "        print(\"âœ… Practical improvement demonstrated\")\n",
    "    elif decision == \"GO_WITH_CAUTION\":\n",
    "        print(\"ðŸŸ¡ DECISION: PROCEED WITH CAUTION\")\n",
    "        print(\"âš ï¸  Marginal but positive improvement\")\n",
    "        print(\"âš ï¸  Consider additional validation\")\n",
    "    elif decision == \"PAUSE\":\n",
    "        print(\"ðŸŸ¡ DECISION: PAUSE FOR MORE DATA\")\n",
    "        print(\"âš ï¸  Inconclusive results\")\n",
    "        print(\"âš ï¸  Need larger sample size\")\n",
    "    else:\n",
    "        print(\"ðŸ”´ DECISION: DO NOT PROCEED\")\n",
    "        print(\"âŒ No significant improvement found\")\n",
    "        print(\"âŒ Consider alternative approaches\")\n",
    "    \n",
    "    print(f\"ðŸ“Š Confidence Level: {confidence}\")\n",
    "    \n",
    "    # Best configuration details\n",
    "    best_config = summary.get('best_configuration')\n",
    "    if best_config and best_config in configs:\n",
    "        best_data = configs[best_config]\n",
    "        print(f\"\\nâ­ BEST CONFIGURATION:\")\n",
    "        print(f\"  Config: {best_config}\")\n",
    "        print(f\"  Parameters: {best_data['parameters']}\")\n",
    "        print(f\"  Expected improvement: {best_data['mean_improvement']:.4f}\")\n",
    "        print(f\"  Sample size: {best_data['aggregated_sample_size']}\")\n",
    "        print(f\"  Number of shards: {best_data['num_shards']}\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Analyze results from both experiments\n",
    "print(\"ðŸ” ANALYZING EXPERIMENT RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Try to analyze test results first\n",
    "test_summary = \"/content/drive/MyDrive/v1_night_opt_test/morning_summary.json\"\n",
    "print(\"\\nðŸ“Š TEST EXPERIMENT ANALYSIS:\")\n",
    "test_results = analyze_results(test_summary)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Analyze full experiment results\n",
    "full_summary = \"/content/drive/MyDrive/v1_night_opt/morning_summary.json\"\n",
    "print(\"\\nðŸ“Š FULL EXPERIMENT ANALYSIS:\")\n",
    "full_results = analyze_results(full_summary)\n",
    "\n",
    "print(\"\\nðŸŽ‰ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f96d0c",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Quick Reference & Troubleshooting\n",
    "\n",
    "Essential commands and troubleshooting tips for common issues.\n",
    "\n",
    "### ðŸ”§ Quick Commands\n",
    "- **Check progress**: Run the monitoring cell above\n",
    "- **Resume experiments**: Re-run the experiment command (it will skip completed ones)\n",
    "- **Clear test results**: `!rm -rf /content/drive/MyDrive/v1_night_opt_test`\n",
    "\n",
    "### ðŸš¨ Troubleshooting\n",
    "- **Out of Memory**: Reduce `total_shards` to 2 or 3\n",
    "- **Disconnection**: The shard system automatically resumes from where it left off\n",
    "- **No GPU**: Check that you've selected a GPU runtime in Colab settings\n",
    "- **Drive full**: Clean up old experiment directories\n",
    "\n",
    "### ðŸ“Š Decision Thresholds\n",
    "- **ðŸŸ¢ GO**: 95% CI lower bound > 0 AND improvement > 0.01\n",
    "- **ðŸŸ¡ CAUTION**: 95% CI lower bound > 0 AND improvement < 0.01  \n",
    "- **ðŸ”´ NO_GO**: 95% CI includes 0 OR negative improvement\n",
    "\n",
    "### ðŸ’¾ File Structure\n",
    "```\n",
    "/content/drive/MyDrive/v1_night_opt/\n",
    "â”œâ”€â”€ morning_summary.json       # Main results\n",
    "â”œâ”€â”€ progress_*.json           # Progress tracking\n",
    "â”œâ”€â”€ shards/                   # Data splits\n",
    "â””â”€â”€ shard_*_mmr_*/           # Individual experiments\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
